{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34d88abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 16:32:20.892988: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-22 16:32:21.129836: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-22 16:32:21.129860: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-22 16:32:22.438918: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-22 16:32:22.438985: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-22 16:32:22.438992: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# train with fewer data. ideal data\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from sklearn import preprocessing\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop, SGD, Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.callbacks import ModelCheckpoint, Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8014ba94",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_data = pd.read_csv(\"data.csv\")\n",
    "label = pd.read_csv(\"properity.csv\")\n",
    "\n",
    "conditions = [\"materials\", \"color\", \"distance\", \"mode\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20cbfd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#r_data = r_data.drop(columns = conditions)\n",
    "#r_data = pd.concat([label, r_data], axis = 1)\n",
    "\n",
    "e_data = e_data.drop(columns = conditions)\n",
    "e_data = pd.concat([label, e_data], axis = 1)\n",
    "\n",
    "e_data = e_data.drop(columns = [\"Hardness\", \"Density\", \"Strength\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be607259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rigidity</th>\n",
       "      <th>names</th>\n",
       "      <th>spectrum_0</th>\n",
       "      <th>spectrum_1</th>\n",
       "      <th>spectrum_2</th>\n",
       "      <th>spectrum_3</th>\n",
       "      <th>spectrum_4</th>\n",
       "      <th>spectrum_5</th>\n",
       "      <th>spectrum_6</th>\n",
       "      <th>spectrum_7</th>\n",
       "      <th>...</th>\n",
       "      <th>spectrum_321</th>\n",
       "      <th>spectrum_322</th>\n",
       "      <th>spectrum_323</th>\n",
       "      <th>spectrum_324</th>\n",
       "      <th>spectrum_325</th>\n",
       "      <th>spectrum_326</th>\n",
       "      <th>spectrum_327</th>\n",
       "      <th>spectrum_328</th>\n",
       "      <th>spectrum_329</th>\n",
       "      <th>spectrum_330</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>Cardboard</td>\n",
       "      <td>0.526403</td>\n",
       "      <td>0.527891</td>\n",
       "      <td>0.529310</td>\n",
       "      <td>0.530688</td>\n",
       "      <td>0.532068</td>\n",
       "      <td>0.533471</td>\n",
       "      <td>0.534901</td>\n",
       "      <td>0.536361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670099</td>\n",
       "      <td>0.670870</td>\n",
       "      <td>0.671219</td>\n",
       "      <td>0.671284</td>\n",
       "      <td>0.671310</td>\n",
       "      <td>0.671274</td>\n",
       "      <td>0.671686</td>\n",
       "      <td>0.672272</td>\n",
       "      <td>0.672768</td>\n",
       "      <td>0.672819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>Cardboard</td>\n",
       "      <td>0.542235</td>\n",
       "      <td>0.543597</td>\n",
       "      <td>0.544961</td>\n",
       "      <td>0.546345</td>\n",
       "      <td>0.547773</td>\n",
       "      <td>0.549250</td>\n",
       "      <td>0.550766</td>\n",
       "      <td>0.552315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.685934</td>\n",
       "      <td>0.686723</td>\n",
       "      <td>0.687080</td>\n",
       "      <td>0.687148</td>\n",
       "      <td>0.687176</td>\n",
       "      <td>0.687140</td>\n",
       "      <td>0.687564</td>\n",
       "      <td>0.688165</td>\n",
       "      <td>0.688675</td>\n",
       "      <td>0.688728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0</td>\n",
       "      <td>Cardboard</td>\n",
       "      <td>0.536953</td>\n",
       "      <td>0.538290</td>\n",
       "      <td>0.539612</td>\n",
       "      <td>0.540949</td>\n",
       "      <td>0.542335</td>\n",
       "      <td>0.543779</td>\n",
       "      <td>0.545277</td>\n",
       "      <td>0.546822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.679368</td>\n",
       "      <td>0.680120</td>\n",
       "      <td>0.680447</td>\n",
       "      <td>0.680490</td>\n",
       "      <td>0.680496</td>\n",
       "      <td>0.680442</td>\n",
       "      <td>0.680844</td>\n",
       "      <td>0.681425</td>\n",
       "      <td>0.681916</td>\n",
       "      <td>0.681958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>Cardboard</td>\n",
       "      <td>0.543379</td>\n",
       "      <td>0.544370</td>\n",
       "      <td>0.545400</td>\n",
       "      <td>0.546501</td>\n",
       "      <td>0.547699</td>\n",
       "      <td>0.549000</td>\n",
       "      <td>0.550391</td>\n",
       "      <td>0.551859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686358</td>\n",
       "      <td>0.687150</td>\n",
       "      <td>0.687509</td>\n",
       "      <td>0.687577</td>\n",
       "      <td>0.687605</td>\n",
       "      <td>0.687568</td>\n",
       "      <td>0.687990</td>\n",
       "      <td>0.688591</td>\n",
       "      <td>0.689099</td>\n",
       "      <td>0.689151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>Cardboard</td>\n",
       "      <td>0.523413</td>\n",
       "      <td>0.524326</td>\n",
       "      <td>0.525328</td>\n",
       "      <td>0.526431</td>\n",
       "      <td>0.527640</td>\n",
       "      <td>0.528946</td>\n",
       "      <td>0.530326</td>\n",
       "      <td>0.531762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661900</td>\n",
       "      <td>0.662690</td>\n",
       "      <td>0.663060</td>\n",
       "      <td>0.663147</td>\n",
       "      <td>0.663193</td>\n",
       "      <td>0.663175</td>\n",
       "      <td>0.663598</td>\n",
       "      <td>0.664191</td>\n",
       "      <td>0.664694</td>\n",
       "      <td>0.664755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>13.0</td>\n",
       "      <td>Wood</td>\n",
       "      <td>0.501132</td>\n",
       "      <td>0.501212</td>\n",
       "      <td>0.501278</td>\n",
       "      <td>0.501364</td>\n",
       "      <td>0.501494</td>\n",
       "      <td>0.501661</td>\n",
       "      <td>0.501850</td>\n",
       "      <td>0.502045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543924</td>\n",
       "      <td>0.544602</td>\n",
       "      <td>0.544929</td>\n",
       "      <td>0.545019</td>\n",
       "      <td>0.545072</td>\n",
       "      <td>0.545068</td>\n",
       "      <td>0.545425</td>\n",
       "      <td>0.545920</td>\n",
       "      <td>0.546338</td>\n",
       "      <td>0.546392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>13.0</td>\n",
       "      <td>Wood</td>\n",
       "      <td>0.462299</td>\n",
       "      <td>0.462222</td>\n",
       "      <td>0.462148</td>\n",
       "      <td>0.462112</td>\n",
       "      <td>0.462131</td>\n",
       "      <td>0.462201</td>\n",
       "      <td>0.462306</td>\n",
       "      <td>0.462434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500846</td>\n",
       "      <td>0.501468</td>\n",
       "      <td>0.501766</td>\n",
       "      <td>0.501847</td>\n",
       "      <td>0.501893</td>\n",
       "      <td>0.501888</td>\n",
       "      <td>0.502214</td>\n",
       "      <td>0.502668</td>\n",
       "      <td>0.503051</td>\n",
       "      <td>0.503099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>13.0</td>\n",
       "      <td>Wood</td>\n",
       "      <td>0.197083</td>\n",
       "      <td>0.197172</td>\n",
       "      <td>0.197252</td>\n",
       "      <td>0.197331</td>\n",
       "      <td>0.197412</td>\n",
       "      <td>0.197492</td>\n",
       "      <td>0.197564</td>\n",
       "      <td>0.197624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216179</td>\n",
       "      <td>0.216449</td>\n",
       "      <td>0.216579</td>\n",
       "      <td>0.216614</td>\n",
       "      <td>0.216634</td>\n",
       "      <td>0.216632</td>\n",
       "      <td>0.216773</td>\n",
       "      <td>0.216968</td>\n",
       "      <td>0.217133</td>\n",
       "      <td>0.217154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>13.0</td>\n",
       "      <td>Wood</td>\n",
       "      <td>0.183714</td>\n",
       "      <td>0.183832</td>\n",
       "      <td>0.183919</td>\n",
       "      <td>0.183990</td>\n",
       "      <td>0.184056</td>\n",
       "      <td>0.184118</td>\n",
       "      <td>0.184174</td>\n",
       "      <td>0.184224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200452</td>\n",
       "      <td>0.200693</td>\n",
       "      <td>0.200805</td>\n",
       "      <td>0.200831</td>\n",
       "      <td>0.200843</td>\n",
       "      <td>0.200835</td>\n",
       "      <td>0.200960</td>\n",
       "      <td>0.201136</td>\n",
       "      <td>0.201285</td>\n",
       "      <td>0.201301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>13.0</td>\n",
       "      <td>Wood</td>\n",
       "      <td>0.177628</td>\n",
       "      <td>0.177632</td>\n",
       "      <td>0.177647</td>\n",
       "      <td>0.177677</td>\n",
       "      <td>0.177724</td>\n",
       "      <td>0.177783</td>\n",
       "      <td>0.177844</td>\n",
       "      <td>0.177903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193133</td>\n",
       "      <td>0.193387</td>\n",
       "      <td>0.193515</td>\n",
       "      <td>0.193558</td>\n",
       "      <td>0.193585</td>\n",
       "      <td>0.193592</td>\n",
       "      <td>0.193726</td>\n",
       "      <td>0.193907</td>\n",
       "      <td>0.194060</td>\n",
       "      <td>0.194083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1260 rows × 333 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rigidity      names  spectrum_0  spectrum_1  spectrum_2  spectrum_3  \\\n",
       "0         20.0  Cardboard    0.526403    0.527891    0.529310    0.530688   \n",
       "1         20.0  Cardboard    0.542235    0.543597    0.544961    0.546345   \n",
       "2         20.0  Cardboard    0.536953    0.538290    0.539612    0.540949   \n",
       "3         20.0  Cardboard    0.543379    0.544370    0.545400    0.546501   \n",
       "4         20.0  Cardboard    0.523413    0.524326    0.525328    0.526431   \n",
       "...        ...        ...         ...         ...         ...         ...   \n",
       "1255      13.0       Wood    0.501132    0.501212    0.501278    0.501364   \n",
       "1256      13.0       Wood    0.462299    0.462222    0.462148    0.462112   \n",
       "1257      13.0       Wood    0.197083    0.197172    0.197252    0.197331   \n",
       "1258      13.0       Wood    0.183714    0.183832    0.183919    0.183990   \n",
       "1259      13.0       Wood    0.177628    0.177632    0.177647    0.177677   \n",
       "\n",
       "      spectrum_4  spectrum_5  spectrum_6  spectrum_7  ...  spectrum_321  \\\n",
       "0       0.532068    0.533471    0.534901    0.536361  ...      0.670099   \n",
       "1       0.547773    0.549250    0.550766    0.552315  ...      0.685934   \n",
       "2       0.542335    0.543779    0.545277    0.546822  ...      0.679368   \n",
       "3       0.547699    0.549000    0.550391    0.551859  ...      0.686358   \n",
       "4       0.527640    0.528946    0.530326    0.531762  ...      0.661900   \n",
       "...          ...         ...         ...         ...  ...           ...   \n",
       "1255    0.501494    0.501661    0.501850    0.502045  ...      0.543924   \n",
       "1256    0.462131    0.462201    0.462306    0.462434  ...      0.500846   \n",
       "1257    0.197412    0.197492    0.197564    0.197624  ...      0.216179   \n",
       "1258    0.184056    0.184118    0.184174    0.184224  ...      0.200452   \n",
       "1259    0.177724    0.177783    0.177844    0.177903  ...      0.193133   \n",
       "\n",
       "      spectrum_322  spectrum_323  spectrum_324  spectrum_325  spectrum_326  \\\n",
       "0         0.670870      0.671219      0.671284      0.671310      0.671274   \n",
       "1         0.686723      0.687080      0.687148      0.687176      0.687140   \n",
       "2         0.680120      0.680447      0.680490      0.680496      0.680442   \n",
       "3         0.687150      0.687509      0.687577      0.687605      0.687568   \n",
       "4         0.662690      0.663060      0.663147      0.663193      0.663175   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "1255      0.544602      0.544929      0.545019      0.545072      0.545068   \n",
       "1256      0.501468      0.501766      0.501847      0.501893      0.501888   \n",
       "1257      0.216449      0.216579      0.216614      0.216634      0.216632   \n",
       "1258      0.200693      0.200805      0.200831      0.200843      0.200835   \n",
       "1259      0.193387      0.193515      0.193558      0.193585      0.193592   \n",
       "\n",
       "      spectrum_327  spectrum_328  spectrum_329  spectrum_330  \n",
       "0         0.671686      0.672272      0.672768      0.672819  \n",
       "1         0.687564      0.688165      0.688675      0.688728  \n",
       "2         0.680844      0.681425      0.681916      0.681958  \n",
       "3         0.687990      0.688591      0.689099      0.689151  \n",
       "4         0.663598      0.664191      0.664694      0.664755  \n",
       "...            ...           ...           ...           ...  \n",
       "1255      0.545425      0.545920      0.546338      0.546392  \n",
       "1256      0.502214      0.502668      0.503051      0.503099  \n",
       "1257      0.216773      0.216968      0.217133      0.217154  \n",
       "1258      0.200960      0.201136      0.201285      0.201301  \n",
       "1259      0.193726      0.193907      0.194060      0.194083  \n",
       "\n",
       "[1260 rows x 333 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ee87d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rigidity</th>\n",
       "      <th>names</th>\n",
       "      <th>spectrum_0</th>\n",
       "      <th>spectrum_1</th>\n",
       "      <th>spectrum_2</th>\n",
       "      <th>spectrum_3</th>\n",
       "      <th>spectrum_4</th>\n",
       "      <th>spectrum_5</th>\n",
       "      <th>spectrum_6</th>\n",
       "      <th>spectrum_7</th>\n",
       "      <th>...</th>\n",
       "      <th>spectrum_321</th>\n",
       "      <th>spectrum_322</th>\n",
       "      <th>spectrum_323</th>\n",
       "      <th>spectrum_324</th>\n",
       "      <th>spectrum_325</th>\n",
       "      <th>spectrum_326</th>\n",
       "      <th>spectrum_327</th>\n",
       "      <th>spectrum_328</th>\n",
       "      <th>spectrum_329</th>\n",
       "      <th>spectrum_330</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>Cardboard1</td>\n",
       "      <td>0.498519</td>\n",
       "      <td>0.499507</td>\n",
       "      <td>0.500530</td>\n",
       "      <td>0.501614</td>\n",
       "      <td>0.502779</td>\n",
       "      <td>0.504029</td>\n",
       "      <td>0.505348</td>\n",
       "      <td>0.506724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.682611</td>\n",
       "      <td>0.683413</td>\n",
       "      <td>0.683782</td>\n",
       "      <td>0.683859</td>\n",
       "      <td>0.683894</td>\n",
       "      <td>0.683864</td>\n",
       "      <td>0.684290</td>\n",
       "      <td>0.684892</td>\n",
       "      <td>0.685401</td>\n",
       "      <td>0.685456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>Cardboard1</td>\n",
       "      <td>0.509502</td>\n",
       "      <td>0.510808</td>\n",
       "      <td>0.512076</td>\n",
       "      <td>0.513333</td>\n",
       "      <td>0.514611</td>\n",
       "      <td>0.515924</td>\n",
       "      <td>0.517265</td>\n",
       "      <td>0.518631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697970</td>\n",
       "      <td>0.698810</td>\n",
       "      <td>0.699204</td>\n",
       "      <td>0.699299</td>\n",
       "      <td>0.699351</td>\n",
       "      <td>0.699333</td>\n",
       "      <td>0.699781</td>\n",
       "      <td>0.700407</td>\n",
       "      <td>0.700937</td>\n",
       "      <td>0.701002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0</td>\n",
       "      <td>Cardboard1</td>\n",
       "      <td>0.519962</td>\n",
       "      <td>0.521413</td>\n",
       "      <td>0.522803</td>\n",
       "      <td>0.524161</td>\n",
       "      <td>0.525525</td>\n",
       "      <td>0.526909</td>\n",
       "      <td>0.528308</td>\n",
       "      <td>0.529719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.712986</td>\n",
       "      <td>0.713827</td>\n",
       "      <td>0.714216</td>\n",
       "      <td>0.714301</td>\n",
       "      <td>0.714342</td>\n",
       "      <td>0.714314</td>\n",
       "      <td>0.714762</td>\n",
       "      <td>0.715393</td>\n",
       "      <td>0.715928</td>\n",
       "      <td>0.715988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>Cardboard1</td>\n",
       "      <td>0.358695</td>\n",
       "      <td>0.359356</td>\n",
       "      <td>0.360053</td>\n",
       "      <td>0.360802</td>\n",
       "      <td>0.361616</td>\n",
       "      <td>0.362493</td>\n",
       "      <td>0.363422</td>\n",
       "      <td>0.364390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.494860</td>\n",
       "      <td>0.495505</td>\n",
       "      <td>0.495830</td>\n",
       "      <td>0.495938</td>\n",
       "      <td>0.496010</td>\n",
       "      <td>0.496030</td>\n",
       "      <td>0.496376</td>\n",
       "      <td>0.496845</td>\n",
       "      <td>0.497243</td>\n",
       "      <td>0.497307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>Cardboard1</td>\n",
       "      <td>0.320341</td>\n",
       "      <td>0.321052</td>\n",
       "      <td>0.321762</td>\n",
       "      <td>0.322486</td>\n",
       "      <td>0.323239</td>\n",
       "      <td>0.324026</td>\n",
       "      <td>0.324838</td>\n",
       "      <td>0.325670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.441703</td>\n",
       "      <td>0.442274</td>\n",
       "      <td>0.442559</td>\n",
       "      <td>0.442650</td>\n",
       "      <td>0.442709</td>\n",
       "      <td>0.442722</td>\n",
       "      <td>0.443026</td>\n",
       "      <td>0.443441</td>\n",
       "      <td>0.443792</td>\n",
       "      <td>0.443845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Rock1</td>\n",
       "      <td>0.504634</td>\n",
       "      <td>0.504748</td>\n",
       "      <td>0.504816</td>\n",
       "      <td>0.504873</td>\n",
       "      <td>0.504945</td>\n",
       "      <td>0.505031</td>\n",
       "      <td>0.505118</td>\n",
       "      <td>0.505199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556106</td>\n",
       "      <td>0.556746</td>\n",
       "      <td>0.557034</td>\n",
       "      <td>0.557083</td>\n",
       "      <td>0.557099</td>\n",
       "      <td>0.557062</td>\n",
       "      <td>0.557397</td>\n",
       "      <td>0.557875</td>\n",
       "      <td>0.558279</td>\n",
       "      <td>0.558315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Rock1</td>\n",
       "      <td>0.502295</td>\n",
       "      <td>0.502457</td>\n",
       "      <td>0.502547</td>\n",
       "      <td>0.502603</td>\n",
       "      <td>0.502659</td>\n",
       "      <td>0.502717</td>\n",
       "      <td>0.502771</td>\n",
       "      <td>0.502816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.552833</td>\n",
       "      <td>0.553468</td>\n",
       "      <td>0.553752</td>\n",
       "      <td>0.553801</td>\n",
       "      <td>0.553817</td>\n",
       "      <td>0.553781</td>\n",
       "      <td>0.554114</td>\n",
       "      <td>0.554591</td>\n",
       "      <td>0.554994</td>\n",
       "      <td>0.555031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Rock1</td>\n",
       "      <td>0.187622</td>\n",
       "      <td>0.187569</td>\n",
       "      <td>0.187514</td>\n",
       "      <td>0.187471</td>\n",
       "      <td>0.187448</td>\n",
       "      <td>0.187442</td>\n",
       "      <td>0.187447</td>\n",
       "      <td>0.187459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206032</td>\n",
       "      <td>0.206278</td>\n",
       "      <td>0.206391</td>\n",
       "      <td>0.206415</td>\n",
       "      <td>0.206426</td>\n",
       "      <td>0.206416</td>\n",
       "      <td>0.206543</td>\n",
       "      <td>0.206723</td>\n",
       "      <td>0.206875</td>\n",
       "      <td>0.206889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Rock1</td>\n",
       "      <td>0.182502</td>\n",
       "      <td>0.182406</td>\n",
       "      <td>0.182348</td>\n",
       "      <td>0.182331</td>\n",
       "      <td>0.182350</td>\n",
       "      <td>0.182391</td>\n",
       "      <td>0.182441</td>\n",
       "      <td>0.182489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200462</td>\n",
       "      <td>0.200704</td>\n",
       "      <td>0.200819</td>\n",
       "      <td>0.200847</td>\n",
       "      <td>0.200862</td>\n",
       "      <td>0.200857</td>\n",
       "      <td>0.200985</td>\n",
       "      <td>0.201165</td>\n",
       "      <td>0.201317</td>\n",
       "      <td>0.201335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Rock1</td>\n",
       "      <td>0.186977</td>\n",
       "      <td>0.187030</td>\n",
       "      <td>0.187048</td>\n",
       "      <td>0.187049</td>\n",
       "      <td>0.187049</td>\n",
       "      <td>0.187052</td>\n",
       "      <td>0.187056</td>\n",
       "      <td>0.187060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206346</td>\n",
       "      <td>0.206606</td>\n",
       "      <td>0.206734</td>\n",
       "      <td>0.206770</td>\n",
       "      <td>0.206793</td>\n",
       "      <td>0.206793</td>\n",
       "      <td>0.206930</td>\n",
       "      <td>0.207120</td>\n",
       "      <td>0.207279</td>\n",
       "      <td>0.207301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows × 333 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rigidity       names  spectrum_0  spectrum_1  spectrum_2  spectrum_3  \\\n",
       "0        20.0  Cardboard1    0.498519    0.499507    0.500530    0.501614   \n",
       "1        20.0  Cardboard1    0.509502    0.510808    0.512076    0.513333   \n",
       "2        20.0  Cardboard1    0.519962    0.521413    0.522803    0.524161   \n",
       "3        20.0  Cardboard1    0.358695    0.359356    0.360053    0.360802   \n",
       "4        20.0  Cardboard1    0.320341    0.321052    0.321762    0.322486   \n",
       "..        ...         ...         ...         ...         ...         ...   \n",
       "445       1.0       Rock1    0.504634    0.504748    0.504816    0.504873   \n",
       "446       1.0       Rock1    0.502295    0.502457    0.502547    0.502603   \n",
       "447       1.0       Rock1    0.187622    0.187569    0.187514    0.187471   \n",
       "448       1.0       Rock1    0.182502    0.182406    0.182348    0.182331   \n",
       "449       1.0       Rock1    0.186977    0.187030    0.187048    0.187049   \n",
       "\n",
       "     spectrum_4  spectrum_5  spectrum_6  spectrum_7  ...  spectrum_321  \\\n",
       "0      0.502779    0.504029    0.505348    0.506724  ...      0.682611   \n",
       "1      0.514611    0.515924    0.517265    0.518631  ...      0.697970   \n",
       "2      0.525525    0.526909    0.528308    0.529719  ...      0.712986   \n",
       "3      0.361616    0.362493    0.363422    0.364390  ...      0.494860   \n",
       "4      0.323239    0.324026    0.324838    0.325670  ...      0.441703   \n",
       "..          ...         ...         ...         ...  ...           ...   \n",
       "445    0.504945    0.505031    0.505118    0.505199  ...      0.556106   \n",
       "446    0.502659    0.502717    0.502771    0.502816  ...      0.552833   \n",
       "447    0.187448    0.187442    0.187447    0.187459  ...      0.206032   \n",
       "448    0.182350    0.182391    0.182441    0.182489  ...      0.200462   \n",
       "449    0.187049    0.187052    0.187056    0.187060  ...      0.206346   \n",
       "\n",
       "     spectrum_322  spectrum_323  spectrum_324  spectrum_325  spectrum_326  \\\n",
       "0        0.683413      0.683782      0.683859      0.683894      0.683864   \n",
       "1        0.698810      0.699204      0.699299      0.699351      0.699333   \n",
       "2        0.713827      0.714216      0.714301      0.714342      0.714314   \n",
       "3        0.495505      0.495830      0.495938      0.496010      0.496030   \n",
       "4        0.442274      0.442559      0.442650      0.442709      0.442722   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "445      0.556746      0.557034      0.557083      0.557099      0.557062   \n",
       "446      0.553468      0.553752      0.553801      0.553817      0.553781   \n",
       "447      0.206278      0.206391      0.206415      0.206426      0.206416   \n",
       "448      0.200704      0.200819      0.200847      0.200862      0.200857   \n",
       "449      0.206606      0.206734      0.206770      0.206793      0.206793   \n",
       "\n",
       "     spectrum_327  spectrum_328  spectrum_329  spectrum_330  \n",
       "0        0.684290      0.684892      0.685401      0.685456  \n",
       "1        0.699781      0.700407      0.700937      0.701002  \n",
       "2        0.714762      0.715393      0.715928      0.715988  \n",
       "3        0.496376      0.496845      0.497243      0.497307  \n",
       "4        0.443026      0.443441      0.443792      0.443845  \n",
       "..            ...           ...           ...           ...  \n",
       "445      0.557397      0.557875      0.558279      0.558315  \n",
       "446      0.554114      0.554591      0.554994      0.555031  \n",
       "447      0.206543      0.206723      0.206875      0.206889  \n",
       "448      0.200985      0.201165      0.201317      0.201335  \n",
       "449      0.206930      0.207120      0.207279      0.207301  \n",
       "\n",
       "[450 rows x 333 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list = [\"Cardboard1\", \"Ceramic1\", \"Glass1\", \"Plastic1\", \"Rock1\"]\n",
    "e_test = e_data[(e_data[\"names\"]==\"Cardboard1\" )|(e_data[\"names\"]==\"Ceramic1\" )|(e_data[\"names\"]==\"Glass1\") |(e_data[\"names\"]==\"Plastic1\") |(e_data[\"names\"]==\"Rock1\")].reset_index(drop=True)\n",
    "e_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34ff2945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rigidity</th>\n",
       "      <th>names</th>\n",
       "      <th>spectrum_0</th>\n",
       "      <th>spectrum_1</th>\n",
       "      <th>spectrum_2</th>\n",
       "      <th>spectrum_3</th>\n",
       "      <th>spectrum_4</th>\n",
       "      <th>spectrum_5</th>\n",
       "      <th>spectrum_6</th>\n",
       "      <th>spectrum_7</th>\n",
       "      <th>...</th>\n",
       "      <th>spectrum_321</th>\n",
       "      <th>spectrum_322</th>\n",
       "      <th>spectrum_323</th>\n",
       "      <th>spectrum_324</th>\n",
       "      <th>spectrum_325</th>\n",
       "      <th>spectrum_326</th>\n",
       "      <th>spectrum_327</th>\n",
       "      <th>spectrum_328</th>\n",
       "      <th>spectrum_329</th>\n",
       "      <th>spectrum_330</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>Cardboard</td>\n",
       "      <td>0.526403</td>\n",
       "      <td>0.527891</td>\n",
       "      <td>0.529310</td>\n",
       "      <td>0.530688</td>\n",
       "      <td>0.532068</td>\n",
       "      <td>0.533471</td>\n",
       "      <td>0.534901</td>\n",
       "      <td>0.536361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670099</td>\n",
       "      <td>0.670870</td>\n",
       "      <td>0.671219</td>\n",
       "      <td>0.671284</td>\n",
       "      <td>0.671310</td>\n",
       "      <td>0.671274</td>\n",
       "      <td>0.671686</td>\n",
       "      <td>0.672272</td>\n",
       "      <td>0.672768</td>\n",
       "      <td>0.672819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>Cardboard</td>\n",
       "      <td>0.542235</td>\n",
       "      <td>0.543597</td>\n",
       "      <td>0.544961</td>\n",
       "      <td>0.546345</td>\n",
       "      <td>0.547773</td>\n",
       "      <td>0.549250</td>\n",
       "      <td>0.550766</td>\n",
       "      <td>0.552315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.685934</td>\n",
       "      <td>0.686723</td>\n",
       "      <td>0.687080</td>\n",
       "      <td>0.687148</td>\n",
       "      <td>0.687176</td>\n",
       "      <td>0.687140</td>\n",
       "      <td>0.687564</td>\n",
       "      <td>0.688165</td>\n",
       "      <td>0.688675</td>\n",
       "      <td>0.688728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0</td>\n",
       "      <td>Cardboard</td>\n",
       "      <td>0.536953</td>\n",
       "      <td>0.538290</td>\n",
       "      <td>0.539612</td>\n",
       "      <td>0.540949</td>\n",
       "      <td>0.542335</td>\n",
       "      <td>0.543779</td>\n",
       "      <td>0.545277</td>\n",
       "      <td>0.546822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.679368</td>\n",
       "      <td>0.680120</td>\n",
       "      <td>0.680447</td>\n",
       "      <td>0.680490</td>\n",
       "      <td>0.680496</td>\n",
       "      <td>0.680442</td>\n",
       "      <td>0.680844</td>\n",
       "      <td>0.681425</td>\n",
       "      <td>0.681916</td>\n",
       "      <td>0.681958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>Cardboard</td>\n",
       "      <td>0.543379</td>\n",
       "      <td>0.544370</td>\n",
       "      <td>0.545400</td>\n",
       "      <td>0.546501</td>\n",
       "      <td>0.547699</td>\n",
       "      <td>0.549000</td>\n",
       "      <td>0.550391</td>\n",
       "      <td>0.551859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686358</td>\n",
       "      <td>0.687150</td>\n",
       "      <td>0.687509</td>\n",
       "      <td>0.687577</td>\n",
       "      <td>0.687605</td>\n",
       "      <td>0.687568</td>\n",
       "      <td>0.687990</td>\n",
       "      <td>0.688591</td>\n",
       "      <td>0.689099</td>\n",
       "      <td>0.689151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>Cardboard</td>\n",
       "      <td>0.523413</td>\n",
       "      <td>0.524326</td>\n",
       "      <td>0.525328</td>\n",
       "      <td>0.526431</td>\n",
       "      <td>0.527640</td>\n",
       "      <td>0.528946</td>\n",
       "      <td>0.530326</td>\n",
       "      <td>0.531762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661900</td>\n",
       "      <td>0.662690</td>\n",
       "      <td>0.663060</td>\n",
       "      <td>0.663147</td>\n",
       "      <td>0.663193</td>\n",
       "      <td>0.663175</td>\n",
       "      <td>0.663598</td>\n",
       "      <td>0.664191</td>\n",
       "      <td>0.664694</td>\n",
       "      <td>0.664755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>13.0</td>\n",
       "      <td>Wood</td>\n",
       "      <td>0.501132</td>\n",
       "      <td>0.501212</td>\n",
       "      <td>0.501278</td>\n",
       "      <td>0.501364</td>\n",
       "      <td>0.501494</td>\n",
       "      <td>0.501661</td>\n",
       "      <td>0.501850</td>\n",
       "      <td>0.502045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543924</td>\n",
       "      <td>0.544602</td>\n",
       "      <td>0.544929</td>\n",
       "      <td>0.545019</td>\n",
       "      <td>0.545072</td>\n",
       "      <td>0.545068</td>\n",
       "      <td>0.545425</td>\n",
       "      <td>0.545920</td>\n",
       "      <td>0.546338</td>\n",
       "      <td>0.546392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>13.0</td>\n",
       "      <td>Wood</td>\n",
       "      <td>0.462299</td>\n",
       "      <td>0.462222</td>\n",
       "      <td>0.462148</td>\n",
       "      <td>0.462112</td>\n",
       "      <td>0.462131</td>\n",
       "      <td>0.462201</td>\n",
       "      <td>0.462306</td>\n",
       "      <td>0.462434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500846</td>\n",
       "      <td>0.501468</td>\n",
       "      <td>0.501766</td>\n",
       "      <td>0.501847</td>\n",
       "      <td>0.501893</td>\n",
       "      <td>0.501888</td>\n",
       "      <td>0.502214</td>\n",
       "      <td>0.502668</td>\n",
       "      <td>0.503051</td>\n",
       "      <td>0.503099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>13.0</td>\n",
       "      <td>Wood</td>\n",
       "      <td>0.197083</td>\n",
       "      <td>0.197172</td>\n",
       "      <td>0.197252</td>\n",
       "      <td>0.197331</td>\n",
       "      <td>0.197412</td>\n",
       "      <td>0.197492</td>\n",
       "      <td>0.197564</td>\n",
       "      <td>0.197624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216179</td>\n",
       "      <td>0.216449</td>\n",
       "      <td>0.216579</td>\n",
       "      <td>0.216614</td>\n",
       "      <td>0.216634</td>\n",
       "      <td>0.216632</td>\n",
       "      <td>0.216773</td>\n",
       "      <td>0.216968</td>\n",
       "      <td>0.217133</td>\n",
       "      <td>0.217154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>13.0</td>\n",
       "      <td>Wood</td>\n",
       "      <td>0.183714</td>\n",
       "      <td>0.183832</td>\n",
       "      <td>0.183919</td>\n",
       "      <td>0.183990</td>\n",
       "      <td>0.184056</td>\n",
       "      <td>0.184118</td>\n",
       "      <td>0.184174</td>\n",
       "      <td>0.184224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200452</td>\n",
       "      <td>0.200693</td>\n",
       "      <td>0.200805</td>\n",
       "      <td>0.200831</td>\n",
       "      <td>0.200843</td>\n",
       "      <td>0.200835</td>\n",
       "      <td>0.200960</td>\n",
       "      <td>0.201136</td>\n",
       "      <td>0.201285</td>\n",
       "      <td>0.201301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>13.0</td>\n",
       "      <td>Wood</td>\n",
       "      <td>0.177628</td>\n",
       "      <td>0.177632</td>\n",
       "      <td>0.177647</td>\n",
       "      <td>0.177677</td>\n",
       "      <td>0.177724</td>\n",
       "      <td>0.177783</td>\n",
       "      <td>0.177844</td>\n",
       "      <td>0.177903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193133</td>\n",
       "      <td>0.193387</td>\n",
       "      <td>0.193515</td>\n",
       "      <td>0.193558</td>\n",
       "      <td>0.193585</td>\n",
       "      <td>0.193592</td>\n",
       "      <td>0.193726</td>\n",
       "      <td>0.193907</td>\n",
       "      <td>0.194060</td>\n",
       "      <td>0.194083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>810 rows × 333 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rigidity      names  spectrum_0  spectrum_1  spectrum_2  spectrum_3  \\\n",
       "0        20.0  Cardboard    0.526403    0.527891    0.529310    0.530688   \n",
       "1        20.0  Cardboard    0.542235    0.543597    0.544961    0.546345   \n",
       "2        20.0  Cardboard    0.536953    0.538290    0.539612    0.540949   \n",
       "3        20.0  Cardboard    0.543379    0.544370    0.545400    0.546501   \n",
       "4        20.0  Cardboard    0.523413    0.524326    0.525328    0.526431   \n",
       "..        ...        ...         ...         ...         ...         ...   \n",
       "805      13.0       Wood    0.501132    0.501212    0.501278    0.501364   \n",
       "806      13.0       Wood    0.462299    0.462222    0.462148    0.462112   \n",
       "807      13.0       Wood    0.197083    0.197172    0.197252    0.197331   \n",
       "808      13.0       Wood    0.183714    0.183832    0.183919    0.183990   \n",
       "809      13.0       Wood    0.177628    0.177632    0.177647    0.177677   \n",
       "\n",
       "     spectrum_4  spectrum_5  spectrum_6  spectrum_7  ...  spectrum_321  \\\n",
       "0      0.532068    0.533471    0.534901    0.536361  ...      0.670099   \n",
       "1      0.547773    0.549250    0.550766    0.552315  ...      0.685934   \n",
       "2      0.542335    0.543779    0.545277    0.546822  ...      0.679368   \n",
       "3      0.547699    0.549000    0.550391    0.551859  ...      0.686358   \n",
       "4      0.527640    0.528946    0.530326    0.531762  ...      0.661900   \n",
       "..          ...         ...         ...         ...  ...           ...   \n",
       "805    0.501494    0.501661    0.501850    0.502045  ...      0.543924   \n",
       "806    0.462131    0.462201    0.462306    0.462434  ...      0.500846   \n",
       "807    0.197412    0.197492    0.197564    0.197624  ...      0.216179   \n",
       "808    0.184056    0.184118    0.184174    0.184224  ...      0.200452   \n",
       "809    0.177724    0.177783    0.177844    0.177903  ...      0.193133   \n",
       "\n",
       "     spectrum_322  spectrum_323  spectrum_324  spectrum_325  spectrum_326  \\\n",
       "0        0.670870      0.671219      0.671284      0.671310      0.671274   \n",
       "1        0.686723      0.687080      0.687148      0.687176      0.687140   \n",
       "2        0.680120      0.680447      0.680490      0.680496      0.680442   \n",
       "3        0.687150      0.687509      0.687577      0.687605      0.687568   \n",
       "4        0.662690      0.663060      0.663147      0.663193      0.663175   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "805      0.544602      0.544929      0.545019      0.545072      0.545068   \n",
       "806      0.501468      0.501766      0.501847      0.501893      0.501888   \n",
       "807      0.216449      0.216579      0.216614      0.216634      0.216632   \n",
       "808      0.200693      0.200805      0.200831      0.200843      0.200835   \n",
       "809      0.193387      0.193515      0.193558      0.193585      0.193592   \n",
       "\n",
       "     spectrum_327  spectrum_328  spectrum_329  spectrum_330  \n",
       "0        0.671686      0.672272      0.672768      0.672819  \n",
       "1        0.687564      0.688165      0.688675      0.688728  \n",
       "2        0.680844      0.681425      0.681916      0.681958  \n",
       "3        0.687990      0.688591      0.689099      0.689151  \n",
       "4        0.663598      0.664191      0.664694      0.664755  \n",
       "..            ...           ...           ...           ...  \n",
       "805      0.545425      0.545920      0.546338      0.546392  \n",
       "806      0.502214      0.502668      0.503051      0.503099  \n",
       "807      0.216773      0.216968      0.217133      0.217154  \n",
       "808      0.200960      0.201136      0.201285      0.201301  \n",
       "809      0.193726      0.193907      0.194060      0.194083  \n",
       "\n",
       "[810 rows x 333 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_train = e_data[(e_data[\"names\"]!=\"Cardboard1\" )&(e_data[\"names\"]!=\"Ceramic1\" )&(e_data[\"names\"]!=\"Glass1\")&(e_data[\"names\"]!=\"Plastic1\") &(e_data[\"names\"]!=\"Rock1\")].reset_index(drop=True)\n",
    "e_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fca8859",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_test_name = e_test[\"names\"].to_numpy()\n",
    "e_test = e_test.drop(columns = [\"names\"])\n",
    "e_train = e_train.drop(columns = [\"names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbb9e429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rigidity</th>\n",
       "      <th>spectrum_0</th>\n",
       "      <th>spectrum_1</th>\n",
       "      <th>spectrum_2</th>\n",
       "      <th>spectrum_3</th>\n",
       "      <th>spectrum_4</th>\n",
       "      <th>spectrum_5</th>\n",
       "      <th>spectrum_6</th>\n",
       "      <th>spectrum_7</th>\n",
       "      <th>spectrum_8</th>\n",
       "      <th>...</th>\n",
       "      <th>spectrum_321</th>\n",
       "      <th>spectrum_322</th>\n",
       "      <th>spectrum_323</th>\n",
       "      <th>spectrum_324</th>\n",
       "      <th>spectrum_325</th>\n",
       "      <th>spectrum_326</th>\n",
       "      <th>spectrum_327</th>\n",
       "      <th>spectrum_328</th>\n",
       "      <th>spectrum_329</th>\n",
       "      <th>spectrum_330</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.498519</td>\n",
       "      <td>0.499507</td>\n",
       "      <td>0.500530</td>\n",
       "      <td>0.501614</td>\n",
       "      <td>0.502779</td>\n",
       "      <td>0.504029</td>\n",
       "      <td>0.505348</td>\n",
       "      <td>0.506724</td>\n",
       "      <td>0.508142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.682611</td>\n",
       "      <td>0.683413</td>\n",
       "      <td>0.683782</td>\n",
       "      <td>0.683859</td>\n",
       "      <td>0.683894</td>\n",
       "      <td>0.683864</td>\n",
       "      <td>0.684290</td>\n",
       "      <td>0.684892</td>\n",
       "      <td>0.685401</td>\n",
       "      <td>0.685456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.509502</td>\n",
       "      <td>0.510808</td>\n",
       "      <td>0.512076</td>\n",
       "      <td>0.513333</td>\n",
       "      <td>0.514611</td>\n",
       "      <td>0.515924</td>\n",
       "      <td>0.517265</td>\n",
       "      <td>0.518631</td>\n",
       "      <td>0.520019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697970</td>\n",
       "      <td>0.698810</td>\n",
       "      <td>0.699204</td>\n",
       "      <td>0.699299</td>\n",
       "      <td>0.699351</td>\n",
       "      <td>0.699333</td>\n",
       "      <td>0.699781</td>\n",
       "      <td>0.700407</td>\n",
       "      <td>0.700937</td>\n",
       "      <td>0.701002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.519962</td>\n",
       "      <td>0.521413</td>\n",
       "      <td>0.522803</td>\n",
       "      <td>0.524161</td>\n",
       "      <td>0.525525</td>\n",
       "      <td>0.526909</td>\n",
       "      <td>0.528308</td>\n",
       "      <td>0.529719</td>\n",
       "      <td>0.531137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.712986</td>\n",
       "      <td>0.713827</td>\n",
       "      <td>0.714216</td>\n",
       "      <td>0.714301</td>\n",
       "      <td>0.714342</td>\n",
       "      <td>0.714314</td>\n",
       "      <td>0.714762</td>\n",
       "      <td>0.715393</td>\n",
       "      <td>0.715928</td>\n",
       "      <td>0.715988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.358695</td>\n",
       "      <td>0.359356</td>\n",
       "      <td>0.360053</td>\n",
       "      <td>0.360802</td>\n",
       "      <td>0.361616</td>\n",
       "      <td>0.362493</td>\n",
       "      <td>0.363422</td>\n",
       "      <td>0.364390</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.494860</td>\n",
       "      <td>0.495505</td>\n",
       "      <td>0.495830</td>\n",
       "      <td>0.495938</td>\n",
       "      <td>0.496010</td>\n",
       "      <td>0.496030</td>\n",
       "      <td>0.496376</td>\n",
       "      <td>0.496845</td>\n",
       "      <td>0.497243</td>\n",
       "      <td>0.497307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.320341</td>\n",
       "      <td>0.321052</td>\n",
       "      <td>0.321762</td>\n",
       "      <td>0.322486</td>\n",
       "      <td>0.323239</td>\n",
       "      <td>0.324026</td>\n",
       "      <td>0.324838</td>\n",
       "      <td>0.325670</td>\n",
       "      <td>0.326519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.441703</td>\n",
       "      <td>0.442274</td>\n",
       "      <td>0.442559</td>\n",
       "      <td>0.442650</td>\n",
       "      <td>0.442709</td>\n",
       "      <td>0.442722</td>\n",
       "      <td>0.443026</td>\n",
       "      <td>0.443441</td>\n",
       "      <td>0.443792</td>\n",
       "      <td>0.443845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.504634</td>\n",
       "      <td>0.504748</td>\n",
       "      <td>0.504816</td>\n",
       "      <td>0.504873</td>\n",
       "      <td>0.504945</td>\n",
       "      <td>0.505031</td>\n",
       "      <td>0.505118</td>\n",
       "      <td>0.505199</td>\n",
       "      <td>0.505267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556106</td>\n",
       "      <td>0.556746</td>\n",
       "      <td>0.557034</td>\n",
       "      <td>0.557083</td>\n",
       "      <td>0.557099</td>\n",
       "      <td>0.557062</td>\n",
       "      <td>0.557397</td>\n",
       "      <td>0.557875</td>\n",
       "      <td>0.558279</td>\n",
       "      <td>0.558315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.502295</td>\n",
       "      <td>0.502457</td>\n",
       "      <td>0.502547</td>\n",
       "      <td>0.502603</td>\n",
       "      <td>0.502659</td>\n",
       "      <td>0.502717</td>\n",
       "      <td>0.502771</td>\n",
       "      <td>0.502816</td>\n",
       "      <td>0.502850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.552833</td>\n",
       "      <td>0.553468</td>\n",
       "      <td>0.553752</td>\n",
       "      <td>0.553801</td>\n",
       "      <td>0.553817</td>\n",
       "      <td>0.553781</td>\n",
       "      <td>0.554114</td>\n",
       "      <td>0.554591</td>\n",
       "      <td>0.554994</td>\n",
       "      <td>0.555031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.187622</td>\n",
       "      <td>0.187569</td>\n",
       "      <td>0.187514</td>\n",
       "      <td>0.187471</td>\n",
       "      <td>0.187448</td>\n",
       "      <td>0.187442</td>\n",
       "      <td>0.187447</td>\n",
       "      <td>0.187459</td>\n",
       "      <td>0.187474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206032</td>\n",
       "      <td>0.206278</td>\n",
       "      <td>0.206391</td>\n",
       "      <td>0.206415</td>\n",
       "      <td>0.206426</td>\n",
       "      <td>0.206416</td>\n",
       "      <td>0.206543</td>\n",
       "      <td>0.206723</td>\n",
       "      <td>0.206875</td>\n",
       "      <td>0.206889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.182502</td>\n",
       "      <td>0.182406</td>\n",
       "      <td>0.182348</td>\n",
       "      <td>0.182331</td>\n",
       "      <td>0.182350</td>\n",
       "      <td>0.182391</td>\n",
       "      <td>0.182441</td>\n",
       "      <td>0.182489</td>\n",
       "      <td>0.182526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200462</td>\n",
       "      <td>0.200704</td>\n",
       "      <td>0.200819</td>\n",
       "      <td>0.200847</td>\n",
       "      <td>0.200862</td>\n",
       "      <td>0.200857</td>\n",
       "      <td>0.200985</td>\n",
       "      <td>0.201165</td>\n",
       "      <td>0.201317</td>\n",
       "      <td>0.201335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.186977</td>\n",
       "      <td>0.187030</td>\n",
       "      <td>0.187048</td>\n",
       "      <td>0.187049</td>\n",
       "      <td>0.187049</td>\n",
       "      <td>0.187052</td>\n",
       "      <td>0.187056</td>\n",
       "      <td>0.187060</td>\n",
       "      <td>0.187063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206346</td>\n",
       "      <td>0.206606</td>\n",
       "      <td>0.206734</td>\n",
       "      <td>0.206770</td>\n",
       "      <td>0.206793</td>\n",
       "      <td>0.206793</td>\n",
       "      <td>0.206930</td>\n",
       "      <td>0.207120</td>\n",
       "      <td>0.207279</td>\n",
       "      <td>0.207301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows × 332 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rigidity  spectrum_0  spectrum_1  spectrum_2  spectrum_3  spectrum_4  \\\n",
       "0        20.0    0.498519    0.499507    0.500530    0.501614    0.502779   \n",
       "1        20.0    0.509502    0.510808    0.512076    0.513333    0.514611   \n",
       "2        20.0    0.519962    0.521413    0.522803    0.524161    0.525525   \n",
       "3        20.0    0.358695    0.359356    0.360053    0.360802    0.361616   \n",
       "4        20.0    0.320341    0.321052    0.321762    0.322486    0.323239   \n",
       "..        ...         ...         ...         ...         ...         ...   \n",
       "445       1.0    0.504634    0.504748    0.504816    0.504873    0.504945   \n",
       "446       1.0    0.502295    0.502457    0.502547    0.502603    0.502659   \n",
       "447       1.0    0.187622    0.187569    0.187514    0.187471    0.187448   \n",
       "448       1.0    0.182502    0.182406    0.182348    0.182331    0.182350   \n",
       "449       1.0    0.186977    0.187030    0.187048    0.187049    0.187049   \n",
       "\n",
       "     spectrum_5  spectrum_6  spectrum_7  spectrum_8  ...  spectrum_321  \\\n",
       "0      0.504029    0.505348    0.506724    0.508142  ...      0.682611   \n",
       "1      0.515924    0.517265    0.518631    0.520019  ...      0.697970   \n",
       "2      0.526909    0.528308    0.529719    0.531137  ...      0.712986   \n",
       "3      0.362493    0.363422    0.364390    0.365385  ...      0.494860   \n",
       "4      0.324026    0.324838    0.325670    0.326519  ...      0.441703   \n",
       "..          ...         ...         ...         ...  ...           ...   \n",
       "445    0.505031    0.505118    0.505199    0.505267  ...      0.556106   \n",
       "446    0.502717    0.502771    0.502816    0.502850  ...      0.552833   \n",
       "447    0.187442    0.187447    0.187459    0.187474  ...      0.206032   \n",
       "448    0.182391    0.182441    0.182489    0.182526  ...      0.200462   \n",
       "449    0.187052    0.187056    0.187060    0.187063  ...      0.206346   \n",
       "\n",
       "     spectrum_322  spectrum_323  spectrum_324  spectrum_325  spectrum_326  \\\n",
       "0        0.683413      0.683782      0.683859      0.683894      0.683864   \n",
       "1        0.698810      0.699204      0.699299      0.699351      0.699333   \n",
       "2        0.713827      0.714216      0.714301      0.714342      0.714314   \n",
       "3        0.495505      0.495830      0.495938      0.496010      0.496030   \n",
       "4        0.442274      0.442559      0.442650      0.442709      0.442722   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "445      0.556746      0.557034      0.557083      0.557099      0.557062   \n",
       "446      0.553468      0.553752      0.553801      0.553817      0.553781   \n",
       "447      0.206278      0.206391      0.206415      0.206426      0.206416   \n",
       "448      0.200704      0.200819      0.200847      0.200862      0.200857   \n",
       "449      0.206606      0.206734      0.206770      0.206793      0.206793   \n",
       "\n",
       "     spectrum_327  spectrum_328  spectrum_329  spectrum_330  \n",
       "0        0.684290      0.684892      0.685401      0.685456  \n",
       "1        0.699781      0.700407      0.700937      0.701002  \n",
       "2        0.714762      0.715393      0.715928      0.715988  \n",
       "3        0.496376      0.496845      0.497243      0.497307  \n",
       "4        0.443026      0.443441      0.443792      0.443845  \n",
       "..            ...           ...           ...           ...  \n",
       "445      0.557397      0.557875      0.558279      0.558315  \n",
       "446      0.554114      0.554591      0.554994      0.555031  \n",
       "447      0.206543      0.206723      0.206875      0.206889  \n",
       "448      0.200985      0.201165      0.201317      0.201335  \n",
       "449      0.206930      0.207120      0.207279      0.207301  \n",
       "\n",
       "[450 rows x 332 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ad2f4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_test_y = e_test[\"Rigidity\"]\n",
    "e_test_x = e_test.drop(columns = [\"Rigidity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9c13ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_train_y = e_train[\"Rigidity\"]\n",
    "e_train_x = e_train.drop(columns = [\"Rigidity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f85fbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tra, x_val, y_tra, y_val = train_test_split(e_train_x, e_train_y, test_size=0.15, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b29dd58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prior weight distribution as Normal of mean=0 and stddev=1.\n",
    "# Note that, in this example, the we prior distribution is not trainable,\n",
    "# as we fix its parameters.\n",
    "def prior(kernel_size, bias_size, dtype=None):\n",
    "    n = kernel_size + bias_size\n",
    "    prior_model = keras.Sequential(\n",
    "        [\n",
    "            tfp.layers.DistributionLambda(\n",
    "                lambda t: tfp.distributions.MultivariateNormalDiag(\n",
    "                    loc=tf.zeros(n), scale_diag=tf.ones(n)\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    return prior_model\n",
    "\n",
    "\n",
    "# Define variational posterior weight distribution as multivariate Gaussian.\n",
    "# Note that the learnable parameters for this distribution are the means,\n",
    "# variances, and covariances.\n",
    "def posterior(kernel_size, bias_size, dtype=None):\n",
    "    n = kernel_size + bias_size\n",
    "    posterior_model = keras.Sequential(\n",
    "        [\n",
    "            tfp.layers.VariableLayer(\n",
    "                tfp.layers.MultivariateNormalTriL.params_size(n), dtype=dtype\n",
    "            ),\n",
    "            tfp.layers.MultivariateNormalTriL(n),\n",
    "        ]\n",
    "    )\n",
    "    return posterior_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "257a0fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 200\n",
    "learning_rate = 0.001\n",
    "encoding_dim = 331\n",
    "\n",
    "def bnn():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(encoding_dim, input_shape=(encoding_dim,)))\n",
    "    model.add(Dense(512, activation='sigmoid'))\n",
    "    model.add(Dense(128, activation='sigmoid'))\n",
    "    model.add(Dense(32, activation='sigmoid'))\n",
    "    model.add(Dense(16, activation='sigmoid'))\n",
    "    model.add(Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b359c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 16:32:26.133881: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-22 16:32:26.133905: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-22 16:32:26.133946: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (WH-330-3053-R05): /proc/driver/nvidia/version does not exist\n",
      "2023-02-22 16:32:26.134589: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = bnn()\n",
    "loss = keras.losses.MeanSquaredError()\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "    loss=loss,\n",
    "    metrics=[keras.metrics.RootMeanSquaredError()],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc542bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStoppingByLossVal(Callback):\n",
    "    def __init__(self, monitor='val_loss', value=0.2, verbose=0):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "\n",
    "        if current < self.value:\n",
    "            if self.verbose > 0:\n",
    "                print(\"Epoch %05d: early stopping THR\" % epoch)\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1413cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStoppingByLossVal(monitor='val_loss', value=0.1, verbose=1),\n",
    "    # EarlyStopping(monitor='val_loss', patience=2, verbose=0),\n",
    "    ModelCheckpoint(\"\" ,monitor='val_loss', save_best_only=True, verbose=0),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e92893e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "22/22 [==============================] - 2s 24ms/step - loss: 16989.4336 - root_mean_squared_error: 130.3435 - val_loss: 13375.7949 - val_root_mean_squared_error: 115.6538\n",
      "Epoch 2/200\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 16888.4629 - root_mean_squared_error: 129.9556 - val_loss: 13316.8057 - val_root_mean_squared_error: 115.3985\n",
      "Epoch 3/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 16826.6738 - root_mean_squared_error: 129.7177 - val_loss: 13271.3184 - val_root_mean_squared_error: 115.2012\n",
      "Epoch 4/200\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 16776.9941 - root_mean_squared_error: 129.5260 - val_loss: 13235.4414 - val_root_mean_squared_error: 115.0454\n",
      "Epoch 5/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 16737.0156 - root_mean_squared_error: 129.3716 - val_loss: 13205.3564 - val_root_mean_squared_error: 114.9146\n",
      "Epoch 6/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 16704.1250 - root_mean_squared_error: 129.2444 - val_loss: 13180.9717 - val_root_mean_squared_error: 114.8084\n",
      "Epoch 7/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 16676.5781 - root_mean_squared_error: 129.1378 - val_loss: 13159.1953 - val_root_mean_squared_error: 114.7135\n",
      "Epoch 8/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 16649.6719 - root_mean_squared_error: 129.0336 - val_loss: 13136.9814 - val_root_mean_squared_error: 114.6167\n",
      "Epoch 9/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 16622.8398 - root_mean_squared_error: 128.9296 - val_loss: 13114.4160 - val_root_mean_squared_error: 114.5182\n",
      "Epoch 10/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 16596.3125 - root_mean_squared_error: 128.8267 - val_loss: 13093.5586 - val_root_mean_squared_error: 114.4271\n",
      "Epoch 11/200\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 16569.3965 - root_mean_squared_error: 128.7222 - val_loss: 13070.5859 - val_root_mean_squared_error: 114.3267\n",
      "Epoch 12/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 16544.0801 - root_mean_squared_error: 128.6238 - val_loss: 13050.9834 - val_root_mean_squared_error: 114.2409\n",
      "Epoch 13/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 16519.6074 - root_mean_squared_error: 128.5286 - val_loss: 13030.9795 - val_root_mean_squared_error: 114.1533\n",
      "Epoch 14/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 16495.3184 - root_mean_squared_error: 128.4341 - val_loss: 13011.3867 - val_root_mean_squared_error: 114.0675\n",
      "Epoch 15/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 16471.0879 - root_mean_squared_error: 128.3397 - val_loss: 12991.1533 - val_root_mean_squared_error: 113.9787\n",
      "Epoch 16/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 16446.7754 - root_mean_squared_error: 128.2450 - val_loss: 12970.1885 - val_root_mean_squared_error: 113.8867\n",
      "Epoch 17/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 16418.1172 - root_mean_squared_error: 128.1332 - val_loss: 12944.6631 - val_root_mean_squared_error: 113.7746\n",
      "Epoch 18/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 16387.6953 - root_mean_squared_error: 128.0144 - val_loss: 12921.0225 - val_root_mean_squared_error: 113.6707\n",
      "Epoch 19/200\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 16359.8281 - root_mean_squared_error: 127.9055 - val_loss: 12898.0508 - val_root_mean_squared_error: 113.5696\n",
      "Epoch 20/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 16329.8789 - root_mean_squared_error: 127.7884 - val_loss: 12872.0068 - val_root_mean_squared_error: 113.4549\n",
      "Epoch 21/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 16296.3516 - root_mean_squared_error: 127.6572 - val_loss: 12843.5283 - val_root_mean_squared_error: 113.3293\n",
      "Epoch 22/200\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 16261.1396 - root_mean_squared_error: 127.5192 - val_loss: 12814.7031 - val_root_mean_squared_error: 113.2020\n",
      "Epoch 23/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 16226.0352 - root_mean_squared_error: 127.3815 - val_loss: 12785.2539 - val_root_mean_squared_error: 113.0719\n",
      "Epoch 24/200\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 16188.7920 - root_mean_squared_error: 127.2352 - val_loss: 12754.2070 - val_root_mean_squared_error: 112.9345\n",
      "Epoch 25/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 16151.6514 - root_mean_squared_error: 127.0891 - val_loss: 12724.7861 - val_root_mean_squared_error: 112.8042\n",
      "Epoch 26/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 16115.0000 - root_mean_squared_error: 126.9449 - val_loss: 12694.3564 - val_root_mean_squared_error: 112.6692\n",
      "Epoch 27/200\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 16076.0615 - root_mean_squared_error: 126.7914 - val_loss: 12662.7236 - val_root_mean_squared_error: 112.5288\n",
      "Epoch 28/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 16039.1553 - root_mean_squared_error: 126.6458 - val_loss: 12633.5244 - val_root_mean_squared_error: 112.3989\n",
      "Epoch 29/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 16003.5625 - root_mean_squared_error: 126.5052 - val_loss: 12605.2852 - val_root_mean_squared_error: 112.2733\n",
      "Epoch 30/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 15967.5088 - root_mean_squared_error: 126.3626 - val_loss: 12575.7324 - val_root_mean_squared_error: 112.1416\n",
      "Epoch 31/200\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 15933.5723 - root_mean_squared_error: 126.2283 - val_loss: 12549.1660 - val_root_mean_squared_error: 112.0231\n",
      "Epoch 32/200\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 15900.5566 - root_mean_squared_error: 126.0974 - val_loss: 12522.7109 - val_root_mean_squared_error: 111.9049\n",
      "Epoch 33/200\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 15866.7861 - root_mean_squared_error: 125.9634 - val_loss: 12494.6025 - val_root_mean_squared_error: 111.7793\n",
      "Epoch 34/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 15832.8574 - root_mean_squared_error: 125.8287 - val_loss: 12467.0020 - val_root_mean_squared_error: 111.6557\n",
      "Epoch 35/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 15797.6367 - root_mean_squared_error: 125.6887 - val_loss: 12437.7666 - val_root_mean_squared_error: 111.5247\n",
      "Epoch 36/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 15758.4707 - root_mean_squared_error: 125.5327 - val_loss: 12403.9346 - val_root_mean_squared_error: 111.3730\n",
      "Epoch 37/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 15714.1250 - root_mean_squared_error: 125.3560 - val_loss: 12365.4639 - val_root_mean_squared_error: 111.2001\n",
      "Epoch 38/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 15664.6260 - root_mean_squared_error: 125.1584 - val_loss: 12324.7402 - val_root_mean_squared_error: 111.0168\n",
      "Epoch 39/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 15613.2354 - root_mean_squared_error: 124.9529 - val_loss: 12283.8447 - val_root_mean_squared_error: 110.8325\n",
      "Epoch 40/200\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 15559.7910 - root_mean_squared_error: 124.7389 - val_loss: 12239.5469 - val_root_mean_squared_error: 110.6325\n",
      "Epoch 41/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 15505.7861 - root_mean_squared_error: 124.5222 - val_loss: 12196.5869 - val_root_mean_squared_error: 110.4382\n",
      "Epoch 42/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 15449.5625 - root_mean_squared_error: 124.2963 - val_loss: 12149.3398 - val_root_mean_squared_error: 110.2240\n",
      "Epoch 43/200\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 15393.6465 - root_mean_squared_error: 124.0711 - val_loss: 12107.4385 - val_root_mean_squared_error: 110.0338\n",
      "Epoch 44/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 15342.7148 - root_mean_squared_error: 123.8657 - val_loss: 12070.5635 - val_root_mean_squared_error: 109.8661\n",
      "Epoch 45/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 11ms/step - loss: 15295.7910 - root_mean_squared_error: 123.6762 - val_loss: 12033.5859 - val_root_mean_squared_error: 109.6977\n",
      "Epoch 46/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 15249.0332 - root_mean_squared_error: 123.4870 - val_loss: 11995.2520 - val_root_mean_squared_error: 109.5228\n",
      "Epoch 47/200\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 15203.1660 - root_mean_squared_error: 123.3011 - val_loss: 11959.9336 - val_root_mean_squared_error: 109.3615\n",
      "Epoch 48/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 15155.7744 - root_mean_squared_error: 123.1088 - val_loss: 11922.8164 - val_root_mean_squared_error: 109.1917\n",
      "Epoch 49/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 15110.7051 - root_mean_squared_error: 122.9256 - val_loss: 11888.1650 - val_root_mean_squared_error: 109.0329\n",
      "Epoch 50/200\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 15065.5684 - root_mean_squared_error: 122.7419 - val_loss: 11852.0293 - val_root_mean_squared_error: 108.8670\n",
      "Epoch 51/200\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 15020.7920 - root_mean_squared_error: 122.5593 - val_loss: 11817.1719 - val_root_mean_squared_error: 108.7068\n",
      "Epoch 52/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 14975.1348 - root_mean_squared_error: 122.3729 - val_loss: 11781.8906 - val_root_mean_squared_error: 108.5444\n",
      "Epoch 53/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 14930.7910 - root_mean_squared_error: 122.1916 - val_loss: 11748.2998 - val_root_mean_squared_error: 108.3896\n",
      "Epoch 54/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 14889.1191 - root_mean_squared_error: 122.0210 - val_loss: 11715.9668 - val_root_mean_squared_error: 108.2403\n",
      "Epoch 55/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 14847.9521 - root_mean_squared_error: 121.8522 - val_loss: 11685.7354 - val_root_mean_squared_error: 108.1006\n",
      "Epoch 56/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 14808.7148 - root_mean_squared_error: 121.6911 - val_loss: 11654.5039 - val_root_mean_squared_error: 107.9560\n",
      "Epoch 57/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 14767.6309 - root_mean_squared_error: 121.5221 - val_loss: 11623.0820 - val_root_mean_squared_error: 107.8104\n",
      "Epoch 58/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 14728.4912 - root_mean_squared_error: 121.3610 - val_loss: 11593.2285 - val_root_mean_squared_error: 107.6719\n",
      "Epoch 59/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 14690.9668 - root_mean_squared_error: 121.2063 - val_loss: 11564.1807 - val_root_mean_squared_error: 107.5369\n",
      "Epoch 60/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 14654.3750 - root_mean_squared_error: 121.0553 - val_loss: 11536.9492 - val_root_mean_squared_error: 107.4102\n",
      "Epoch 61/200\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 14618.9785 - root_mean_squared_error: 120.9090 - val_loss: 11510.7109 - val_root_mean_squared_error: 107.2880\n",
      "Epoch 62/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 14583.2617 - root_mean_squared_error: 120.7612 - val_loss: 11482.1572 - val_root_mean_squared_error: 107.1548\n",
      "Epoch 63/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 14548.6133 - root_mean_squared_error: 120.6176 - val_loss: 11457.2969 - val_root_mean_squared_error: 107.0388\n",
      "Epoch 64/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 14513.5117 - root_mean_squared_error: 120.4720 - val_loss: 11429.3574 - val_root_mean_squared_error: 106.9082\n",
      "Epoch 65/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 14478.2090 - root_mean_squared_error: 120.3254 - val_loss: 11403.0537 - val_root_mean_squared_error: 106.7851\n",
      "Epoch 66/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 14442.9014 - root_mean_squared_error: 120.1786 - val_loss: 11376.4561 - val_root_mean_squared_error: 106.6605\n",
      "Epoch 67/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 14407.7559 - root_mean_squared_error: 120.0323 - val_loss: 11349.5840 - val_root_mean_squared_error: 106.5344\n",
      "Epoch 68/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 14373.3486 - root_mean_squared_error: 119.8889 - val_loss: 11323.9971 - val_root_mean_squared_error: 106.4143\n",
      "Epoch 69/200\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 14340.2793 - root_mean_squared_error: 119.7509 - val_loss: 11299.3340 - val_root_mean_squared_error: 106.2983\n",
      "Epoch 70/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 14306.1426 - root_mean_squared_error: 119.6083 - val_loss: 11273.3369 - val_root_mean_squared_error: 106.1760\n",
      "Epoch 71/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 14272.9414 - root_mean_squared_error: 119.4694 - val_loss: 11248.0430 - val_root_mean_squared_error: 106.0568\n",
      "Epoch 72/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 14239.7354 - root_mean_squared_error: 119.3304 - val_loss: 11223.9316 - val_root_mean_squared_error: 105.9431\n",
      "Epoch 73/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 14207.0742 - root_mean_squared_error: 119.1934 - val_loss: 11199.7217 - val_root_mean_squared_error: 105.8287\n",
      "Epoch 74/200\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 14173.3135 - root_mean_squared_error: 119.0517 - val_loss: 11173.7217 - val_root_mean_squared_error: 105.7058\n",
      "Epoch 75/200\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 14141.3193 - root_mean_squared_error: 118.9173 - val_loss: 11151.7686 - val_root_mean_squared_error: 105.6019\n",
      "Epoch 76/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 14109.8740 - root_mean_squared_error: 118.7850 - val_loss: 11126.9834 - val_root_mean_squared_error: 105.4845\n",
      "Epoch 77/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 14077.8574 - root_mean_squared_error: 118.6501 - val_loss: 11104.2012 - val_root_mean_squared_error: 105.3765\n",
      "Epoch 78/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 14046.1602 - root_mean_squared_error: 118.5165 - val_loss: 11080.6543 - val_root_mean_squared_error: 105.2647\n",
      "Epoch 79/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 14014.1250 - root_mean_squared_error: 118.3813 - val_loss: 11057.4287 - val_root_mean_squared_error: 105.1543\n",
      "Epoch 80/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 13982.7236 - root_mean_squared_error: 118.2486 - val_loss: 11034.0264 - val_root_mean_squared_error: 105.0430\n",
      "Epoch 81/200\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 13951.4873 - root_mean_squared_error: 118.1164 - val_loss: 11011.5693 - val_root_mean_squared_error: 104.9360\n",
      "Epoch 82/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 13921.2598 - root_mean_squared_error: 117.9884 - val_loss: 10989.8242 - val_root_mean_squared_error: 104.8324\n",
      "Epoch 83/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 13890.7803 - root_mean_squared_error: 117.8592 - val_loss: 10967.4297 - val_root_mean_squared_error: 104.7255\n",
      "Epoch 84/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 13860.3340 - root_mean_squared_error: 117.7299 - val_loss: 10945.8936 - val_root_mean_squared_error: 104.6226\n",
      "Epoch 85/200\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 13830.8057 - root_mean_squared_error: 117.6044 - val_loss: 10924.7402 - val_root_mean_squared_error: 104.5215\n",
      "Epoch 86/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 13801.7383 - root_mean_squared_error: 117.4808 - val_loss: 10904.0371 - val_root_mean_squared_error: 104.4224\n",
      "Epoch 87/200\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 13773.9219 - root_mean_squared_error: 117.3624 - val_loss: 10883.5820 - val_root_mean_squared_error: 104.3244\n",
      "Epoch 88/200\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 13745.0898 - root_mean_squared_error: 117.2395 - val_loss: 10863.1338 - val_root_mean_squared_error: 104.2264\n",
      "Epoch 89/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 10ms/step - loss: 13716.2656 - root_mean_squared_error: 117.1165 - val_loss: 10842.5596 - val_root_mean_squared_error: 104.1276\n",
      "Epoch 90/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 13686.3760 - root_mean_squared_error: 116.9888 - val_loss: 10820.6777 - val_root_mean_squared_error: 104.0225\n",
      "Epoch 91/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 13657.0264 - root_mean_squared_error: 116.8633 - val_loss: 10800.7725 - val_root_mean_squared_error: 103.9268\n",
      "Epoch 92/200\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 13628.6016 - root_mean_squared_error: 116.7416 - val_loss: 10780.5352 - val_root_mean_squared_error: 103.8294\n",
      "Epoch 93/200\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 13600.0244 - root_mean_squared_error: 116.6191 - val_loss: 10759.6621 - val_root_mean_squared_error: 103.7288\n",
      "Epoch 94/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 13572.5098 - root_mean_squared_error: 116.5011 - val_loss: 10741.9717 - val_root_mean_squared_error: 103.6435\n",
      "Epoch 95/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 13546.5332 - root_mean_squared_error: 116.3896 - val_loss: 10723.3008 - val_root_mean_squared_error: 103.5534\n",
      "Epoch 96/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 13518.9492 - root_mean_squared_error: 116.2710 - val_loss: 10703.2861 - val_root_mean_squared_error: 103.4567\n",
      "Epoch 97/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 13491.2881 - root_mean_squared_error: 116.1520 - val_loss: 10685.2373 - val_root_mean_squared_error: 103.3694\n",
      "Epoch 98/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 13465.6729 - root_mean_squared_error: 116.0417 - val_loss: 10667.3418 - val_root_mean_squared_error: 103.2828\n",
      "Epoch 99/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 13439.5176 - root_mean_squared_error: 115.9289 - val_loss: 10648.6973 - val_root_mean_squared_error: 103.1925\n",
      "Epoch 100/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 13413.8604 - root_mean_squared_error: 115.8182 - val_loss: 10632.1475 - val_root_mean_squared_error: 103.1123\n",
      "Epoch 101/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 13389.0889 - root_mean_squared_error: 115.7112 - val_loss: 10615.0000 - val_root_mean_squared_error: 103.0291\n",
      "Epoch 102/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 13363.6602 - root_mean_squared_error: 115.6013 - val_loss: 10597.9014 - val_root_mean_squared_error: 102.9461\n",
      "Epoch 103/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 13338.8564 - root_mean_squared_error: 115.4940 - val_loss: 10580.6973 - val_root_mean_squared_error: 102.8625\n",
      "Epoch 104/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 13313.5684 - root_mean_squared_error: 115.3844 - val_loss: 10564.4492 - val_root_mean_squared_error: 102.7835\n",
      "Epoch 105/200\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 13289.2598 - root_mean_squared_error: 115.2791 - val_loss: 10547.9570 - val_root_mean_squared_error: 102.7032\n",
      "Epoch 106/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 13263.8955 - root_mean_squared_error: 115.1690 - val_loss: 10530.2354 - val_root_mean_squared_error: 102.6169\n",
      "Epoch 107/200\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 13238.5869 - root_mean_squared_error: 115.0591 - val_loss: 10513.8008 - val_root_mean_squared_error: 102.5368\n",
      "Epoch 108/200\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 13214.3691 - root_mean_squared_error: 114.9538 - val_loss: 10498.3789 - val_root_mean_squared_error: 102.4616\n",
      "Epoch 109/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 13190.9756 - root_mean_squared_error: 114.8520 - val_loss: 10482.8154 - val_root_mean_squared_error: 102.3856\n",
      "Epoch 110/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 13167.3867 - root_mean_squared_error: 114.7492 - val_loss: 10467.2422 - val_root_mean_squared_error: 102.3095\n",
      "Epoch 111/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 13144.6123 - root_mean_squared_error: 114.6500 - val_loss: 10452.5527 - val_root_mean_squared_error: 102.2377\n",
      "Epoch 112/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 13121.3760 - root_mean_squared_error: 114.5486 - val_loss: 10437.1230 - val_root_mean_squared_error: 102.1622\n",
      "Epoch 113/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 13099.3574 - root_mean_squared_error: 114.4524 - val_loss: 10423.6211 - val_root_mean_squared_error: 102.0961\n",
      "Epoch 114/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 13077.2266 - root_mean_squared_error: 114.3557 - val_loss: 10409.4912 - val_root_mean_squared_error: 102.0269\n",
      "Epoch 115/200\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 13057.2256 - root_mean_squared_error: 114.2682 - val_loss: 10396.7168 - val_root_mean_squared_error: 101.9643\n",
      "Epoch 116/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 13036.1045 - root_mean_squared_error: 114.1758 - val_loss: 10382.9346 - val_root_mean_squared_error: 101.8967\n",
      "Epoch 117/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 13015.2471 - root_mean_squared_error: 114.0844 - val_loss: 10370.1846 - val_root_mean_squared_error: 101.8341\n",
      "Epoch 118/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 12993.8164 - root_mean_squared_error: 113.9904 - val_loss: 10356.2578 - val_root_mean_squared_error: 101.7657\n",
      "Epoch 119/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 12972.7715 - root_mean_squared_error: 113.8981 - val_loss: 10343.6025 - val_root_mean_squared_error: 101.7035\n",
      "Epoch 120/200\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 12952.1191 - root_mean_squared_error: 113.8074 - val_loss: 10329.8457 - val_root_mean_squared_error: 101.6358\n",
      "Epoch 121/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 12930.3965 - root_mean_squared_error: 113.7119 - val_loss: 10317.0088 - val_root_mean_squared_error: 101.5727\n",
      "Epoch 122/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 12910.4785 - root_mean_squared_error: 113.6243 - val_loss: 10304.9854 - val_root_mean_squared_error: 101.5135\n",
      "Epoch 123/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 12890.9912 - root_mean_squared_error: 113.5385 - val_loss: 10293.0850 - val_root_mean_squared_error: 101.4548\n",
      "Epoch 124/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 12871.6660 - root_mean_squared_error: 113.4534 - val_loss: 10281.4473 - val_root_mean_squared_error: 101.3975\n",
      "Epoch 125/200\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 12852.7676 - root_mean_squared_error: 113.3700 - val_loss: 10270.2783 - val_root_mean_squared_error: 101.3424\n",
      "Epoch 126/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 12834.1074 - root_mean_squared_error: 113.2877 - val_loss: 10258.8740 - val_root_mean_squared_error: 101.2861\n",
      "Epoch 127/200\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 12815.5928 - root_mean_squared_error: 113.2060 - val_loss: 10248.4023 - val_root_mean_squared_error: 101.2344\n",
      "Epoch 128/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 12797.6377 - root_mean_squared_error: 113.1266 - val_loss: 10237.2764 - val_root_mean_squared_error: 101.1794\n",
      "Epoch 129/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 12777.7227 - root_mean_squared_error: 113.0386 - val_loss: 10225.7598 - val_root_mean_squared_error: 101.1225\n",
      "Epoch 130/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 12759.9463 - root_mean_squared_error: 112.9599 - val_loss: 10216.1289 - val_root_mean_squared_error: 101.0749\n",
      "Epoch 131/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 12742.6758 - root_mean_squared_error: 112.8835 - val_loss: 10205.4463 - val_root_mean_squared_error: 101.0220\n",
      "Epoch 132/200\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 12724.9795 - root_mean_squared_error: 112.8051 - val_loss: 10195.8174 - val_root_mean_squared_error: 100.9743\n",
      "Epoch 133/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 9ms/step - loss: 12707.7324 - root_mean_squared_error: 112.7286 - val_loss: 10186.2969 - val_root_mean_squared_error: 100.9272\n",
      "Epoch 134/200\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 12691.6074 - root_mean_squared_error: 112.6570 - val_loss: 10177.4580 - val_root_mean_squared_error: 100.8834\n",
      "Epoch 135/200\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 12675.9277 - root_mean_squared_error: 112.5874 - val_loss: 10168.2852 - val_root_mean_squared_error: 100.8379\n",
      "Epoch 136/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 12659.3896 - root_mean_squared_error: 112.5140 - val_loss: 10159.2002 - val_root_mean_squared_error: 100.7929\n",
      "Epoch 137/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 12643.6260 - root_mean_squared_error: 112.4439 - val_loss: 10151.1064 - val_root_mean_squared_error: 100.7527\n",
      "Epoch 138/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 12629.5918 - root_mean_squared_error: 112.3815 - val_loss: 10143.2305 - val_root_mean_squared_error: 100.7136\n",
      "Epoch 139/200\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 12614.5186 - root_mean_squared_error: 112.3144 - val_loss: 10134.6553 - val_root_mean_squared_error: 100.6710\n",
      "Epoch 140/200\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 12598.3057 - root_mean_squared_error: 112.2422 - val_loss: 10126.5049 - val_root_mean_squared_error: 100.6305\n",
      "Epoch 141/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 12583.5303 - root_mean_squared_error: 112.1763 - val_loss: 10118.0098 - val_root_mean_squared_error: 100.5883\n",
      "Epoch 142/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 12568.0420 - root_mean_squared_error: 112.1073 - val_loss: 10110.9258 - val_root_mean_squared_error: 100.5531\n",
      "Epoch 143/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 12554.3193 - root_mean_squared_error: 112.0461 - val_loss: 10103.2314 - val_root_mean_squared_error: 100.5148\n",
      "Epoch 144/200\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 12538.8135 - root_mean_squared_error: 111.9768 - val_loss: 10095.1777 - val_root_mean_squared_error: 100.4748\n",
      "Epoch 145/200\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 12524.3779 - root_mean_squared_error: 111.9124 - val_loss: 10088.4424 - val_root_mean_squared_error: 100.4412\n",
      "Epoch 146/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 12509.9766 - root_mean_squared_error: 111.8480 - val_loss: 10080.6680 - val_root_mean_squared_error: 100.4025\n",
      "Epoch 147/200\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 12496.5303 - root_mean_squared_error: 111.7879 - val_loss: 10074.8672 - val_root_mean_squared_error: 100.3736\n",
      "Epoch 148/200\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 12484.9365 - root_mean_squared_error: 111.7360 - val_loss: 10068.8242 - val_root_mean_squared_error: 100.3435\n",
      "Epoch 149/200\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 12472.5010 - root_mean_squared_error: 111.6804 - val_loss: 10062.6924 - val_root_mean_squared_error: 100.3130\n",
      "Epoch 150/200\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 12459.6602 - root_mean_squared_error: 111.6228 - val_loss: 10056.7598 - val_root_mean_squared_error: 100.2834\n",
      "Epoch 151/200\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 12446.8135 - root_mean_squared_error: 111.5653 - val_loss: 10050.1201 - val_root_mean_squared_error: 100.2503\n",
      "Epoch 152/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 12432.6436 - root_mean_squared_error: 111.5018 - val_loss: 10043.9043 - val_root_mean_squared_error: 100.2193\n",
      "Epoch 153/200\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 12419.3721 - root_mean_squared_error: 111.4422 - val_loss: 10037.8242 - val_root_mean_squared_error: 100.1889\n",
      "Epoch 154/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 12407.6377 - root_mean_squared_error: 111.3896 - val_loss: 10033.0166 - val_root_mean_squared_error: 100.1649\n",
      "Epoch 155/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 12395.7354 - root_mean_squared_error: 111.3361 - val_loss: 10027.0898 - val_root_mean_squared_error: 100.1354\n",
      "Epoch 156/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 12382.6777 - root_mean_squared_error: 111.2775 - val_loss: 10021.7041 - val_root_mean_squared_error: 100.1085\n",
      "Epoch 157/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 12371.1396 - root_mean_squared_error: 111.2256 - val_loss: 10017.1211 - val_root_mean_squared_error: 100.0856\n",
      "Epoch 158/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 12360.2461 - root_mean_squared_error: 111.1766 - val_loss: 10012.1211 - val_root_mean_squared_error: 100.0606\n",
      "Epoch 159/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 12349.3398 - root_mean_squared_error: 111.1276 - val_loss: 10007.9756 - val_root_mean_squared_error: 100.0399\n",
      "Epoch 160/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 12338.0293 - root_mean_squared_error: 111.0767 - val_loss: 10003.2598 - val_root_mean_squared_error: 100.0163\n",
      "Epoch 161/200\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 12327.5205 - root_mean_squared_error: 111.0294 - val_loss: 9999.1436 - val_root_mean_squared_error: 99.9957\n",
      "Epoch 162/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 12316.6426 - root_mean_squared_error: 110.9804 - val_loss: 9994.8418 - val_root_mean_squared_error: 99.9742\n",
      "Epoch 163/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 12305.9170 - root_mean_squared_error: 110.9320 - val_loss: 9990.6807 - val_root_mean_squared_error: 99.9534\n",
      "Epoch 164/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 12295.2383 - root_mean_squared_error: 110.8839 - val_loss: 9986.8086 - val_root_mean_squared_error: 99.9340\n",
      "Epoch 165/200\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 12285.7148 - root_mean_squared_error: 110.8409 - val_loss: 9983.3691 - val_root_mean_squared_error: 99.9168\n",
      "Epoch 166/200\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 12276.0000 - root_mean_squared_error: 110.7971 - val_loss: 9979.8242 - val_root_mean_squared_error: 99.8991\n",
      "Epoch 167/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 12265.8242 - root_mean_squared_error: 110.7512 - val_loss: 9976.1602 - val_root_mean_squared_error: 99.8807\n",
      "Epoch 168/200\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 12255.7852 - root_mean_squared_error: 110.7058 - val_loss: 9972.8330 - val_root_mean_squared_error: 99.8641\n",
      "Epoch 169/200\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 12246.3691 - root_mean_squared_error: 110.6633 - val_loss: 9969.9736 - val_root_mean_squared_error: 99.8498\n",
      "Epoch 170/200\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 12237.5234 - root_mean_squared_error: 110.6233 - val_loss: 9967.1338 - val_root_mean_squared_error: 99.8355\n",
      "Epoch 171/200\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 12228.3242 - root_mean_squared_error: 110.5818 - val_loss: 9964.0967 - val_root_mean_squared_error: 99.8203\n",
      "Epoch 172/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 12218.5449 - root_mean_squared_error: 110.5375 - val_loss: 9961.3486 - val_root_mean_squared_error: 99.8066\n",
      "Epoch 173/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 12209.6074 - root_mean_squared_error: 110.4971 - val_loss: 9958.8584 - val_root_mean_squared_error: 99.7941\n",
      "Epoch 174/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 12201.7744 - root_mean_squared_error: 110.4616 - val_loss: 9956.5771 - val_root_mean_squared_error: 99.7826\n",
      "Epoch 175/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 12193.0322 - root_mean_squared_error: 110.4221 - val_loss: 9954.2021 - val_root_mean_squared_error: 99.7707\n",
      "Epoch 176/200\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 12184.9463 - root_mean_squared_error: 110.3854 - val_loss: 9952.3174 - val_root_mean_squared_error: 99.7613\n",
      "Epoch 177/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 13ms/step - loss: 12177.1377 - root_mean_squared_error: 110.3501 - val_loss: 9950.3174 - val_root_mean_squared_error: 99.7513\n",
      "Epoch 178/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 12169.5117 - root_mean_squared_error: 110.3155 - val_loss: 9948.7070 - val_root_mean_squared_error: 99.7432\n",
      "Epoch 179/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 12162.3252 - root_mean_squared_error: 110.2829 - val_loss: 9947.0693 - val_root_mean_squared_error: 99.7350\n",
      "Epoch 180/200\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 12155.2061 - root_mean_squared_error: 110.2506 - val_loss: 9945.4551 - val_root_mean_squared_error: 99.7269\n",
      "Epoch 181/200\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 12148.1406 - root_mean_squared_error: 110.2186 - val_loss: 9944.2236 - val_root_mean_squared_error: 99.7207\n",
      "Epoch 182/200\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 12141.7402 - root_mean_squared_error: 110.1896 - val_loss: 9942.9736 - val_root_mean_squared_error: 99.7145\n",
      "Epoch 183/200\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 12135.2539 - root_mean_squared_error: 110.1601 - val_loss: 9941.9141 - val_root_mean_squared_error: 99.7091\n",
      "Epoch 184/200\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 12128.5420 - root_mean_squared_error: 110.1297 - val_loss: 9940.7314 - val_root_mean_squared_error: 99.7032\n",
      "Epoch 185/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 12121.5020 - root_mean_squared_error: 110.0977 - val_loss: 9939.6504 - val_root_mean_squared_error: 99.6978\n",
      "Epoch 186/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 12113.8906 - root_mean_squared_error: 110.0631 - val_loss: 9938.6738 - val_root_mean_squared_error: 99.6929\n",
      "Epoch 187/200\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 12108.0527 - root_mean_squared_error: 110.0366 - val_loss: 9938.0742 - val_root_mean_squared_error: 99.6899\n",
      "Epoch 188/200\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 12102.4590 - root_mean_squared_error: 110.0112 - val_loss: 9937.5205 - val_root_mean_squared_error: 99.6871\n",
      "Epoch 189/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 12097.2178 - root_mean_squared_error: 109.9874 - val_loss: 9936.9736 - val_root_mean_squared_error: 99.6844\n",
      "Epoch 190/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 12091.7393 - root_mean_squared_error: 109.9624 - val_loss: 9936.5762 - val_root_mean_squared_error: 99.6824\n",
      "Epoch 191/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 12087.0840 - root_mean_squared_error: 109.9413 - val_loss: 9936.3193 - val_root_mean_squared_error: 99.6811\n",
      "Epoch 192/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 12082.4131 - root_mean_squared_error: 109.9200 - val_loss: 9936.0771 - val_root_mean_squared_error: 99.6799\n",
      "Epoch 193/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 12077.9580 - root_mean_squared_error: 109.8998 - val_loss: 9935.9014 - val_root_mean_squared_error: 99.6790\n",
      "Epoch 194/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 12073.0322 - root_mean_squared_error: 109.8773 - val_loss: 9935.7930 - val_root_mean_squared_error: 99.6785\n",
      "Epoch 195/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 12067.8115 - root_mean_squared_error: 109.8536 - val_loss: 9935.7559 - val_root_mean_squared_error: 99.6783\n",
      "Epoch 196/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 12063.0977 - root_mean_squared_error: 109.8321 - val_loss: 9935.8076 - val_root_mean_squared_error: 99.6785\n",
      "Epoch 197/200\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 12058.6094 - root_mean_squared_error: 109.8117 - val_loss: 9935.9082 - val_root_mean_squared_error: 99.6790\n",
      "Epoch 198/200\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 12054.4580 - root_mean_squared_error: 109.7928 - val_loss: 9936.0723 - val_root_mean_squared_error: 99.6798\n",
      "Epoch 199/200\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 12050.7998 - root_mean_squared_error: 109.7761 - val_loss: 9936.2910 - val_root_mean_squared_error: 99.6809\n",
      "Epoch 200/200\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 12047.2598 - root_mean_squared_error: 109.7600 - val_loss: 9936.5537 - val_root_mean_squared_error: 99.6823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb5ed742490>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_tra, y_tra, epochs=EPOCHS, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b73f312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n",
      "Predicted: 59.7 - Actual: 190.0\n",
      "Predicted: 59.7 - Actual: 3.0\n",
      "Predicted: 59.7 - Actual: 20.0\n",
      "Predicted: 59.7 - Actual: 0.3\n",
      "Predicted: 59.7 - Actual: 3.0\n",
      "Predicted: 59.7 - Actual: 3.0\n",
      "Predicted: 59.7 - Actual: 1.0\n",
      "Predicted: 59.7 - Actual: 190.0\n",
      "Predicted: 59.7 - Actual: 1.0\n",
      "Predicted: 59.7 - Actual: 29.0\n",
      "Predicted: 59.7 - Actual: 13.0\n",
      "Predicted: 59.7 - Actual: 29.0\n",
      "Predicted: 59.7 - Actual: 35.0\n",
      "Predicted: 59.7 - Actual: 29.0\n",
      "Predicted: 59.7 - Actual: 0.3\n",
      "Predicted: 59.7 - Actual: 29.0\n",
      "Predicted: 59.7 - Actual: 35.0\n",
      "Predicted: 59.7 - Actual: 330.0\n",
      "Predicted: 59.7 - Actual: 330.0\n",
      "Predicted: 59.7 - Actual: 35.0\n",
      "Predicted: 59.7 - Actual: 190.0\n",
      "Predicted: 59.7 - Actual: 190.0\n",
      "Predicted: 59.7 - Actual: 13.0\n",
      "Predicted: 59.7 - Actual: 35.0\n",
      "Predicted: 59.7 - Actual: 0.3\n",
      "Predicted: 59.7 - Actual: 13.0\n",
      "Predicted: 59.7 - Actual: 1.0\n",
      "Predicted: 59.7 - Actual: 13.0\n",
      "Predicted: 59.7 - Actual: 35.0\n",
      "Predicted: 59.7 - Actual: 20.0\n",
      "Predicted: 59.7 - Actual: 20.0\n",
      "Predicted: 59.7 - Actual: 190.0\n",
      "Predicted: 59.7 - Actual: 0.3\n",
      "Predicted: 59.7 - Actual: 20.0\n",
      "Predicted: 59.7 - Actual: 190.0\n",
      "Predicted: 59.7 - Actual: 1.0\n",
      "Predicted: 59.7 - Actual: 20.0\n",
      "Predicted: 59.7 - Actual: 190.0\n",
      "Predicted: 59.7 - Actual: 0.3\n",
      "Predicted: 59.7 - Actual: 3.0\n",
      "Predicted: 59.7 - Actual: 1.0\n",
      "Predicted: 59.7 - Actual: 330.0\n",
      "Predicted: 59.7 - Actual: 35.0\n",
      "Predicted: 59.7 - Actual: 1.0\n",
      "Predicted: 59.7 - Actual: 1.0\n",
      "Predicted: 59.7 - Actual: 0.3\n",
      "Predicted: 59.7 - Actual: 20.0\n",
      "Predicted: 59.7 - Actual: 3.0\n",
      "Predicted: 59.7 - Actual: 13.0\n",
      "Predicted: 59.7 - Actual: 35.0\n",
      "Predicted: 59.7 - Actual: 20.0\n",
      "Predicted: 59.7 - Actual: 29.0\n",
      "Predicted: 59.7 - Actual: 20.0\n",
      "Predicted: 59.7 - Actual: 0.3\n",
      "Predicted: 59.7 - Actual: 190.0\n",
      "Predicted: 59.7 - Actual: 1.0\n",
      "Predicted: 59.7 - Actual: 20.0\n",
      "Predicted: 59.7 - Actual: 35.0\n",
      "Predicted: 59.7 - Actual: 0.3\n",
      "Predicted: 59.7 - Actual: 3.0\n",
      "Predicted: 59.7 - Actual: 1.0\n",
      "Predicted: 59.7 - Actual: 20.0\n",
      "Predicted: 59.7 - Actual: 0.3\n",
      "Predicted: 59.7 - Actual: 13.0\n",
      "Predicted: 59.7 - Actual: 20.0\n",
      "Predicted: 59.7 - Actual: 3.0\n",
      "Predicted: 59.7 - Actual: 35.0\n",
      "Predicted: 59.7 - Actual: 3.0\n",
      "Predicted: 59.7 - Actual: 29.0\n",
      "Predicted: 59.7 - Actual: 35.0\n",
      "Predicted: 59.7 - Actual: 330.0\n",
      "Predicted: 59.7 - Actual: 0.3\n",
      "Predicted: 59.7 - Actual: 35.0\n",
      "Predicted: 59.7 - Actual: 3.0\n",
      "Predicted: 59.7 - Actual: 29.0\n",
      "Predicted: 59.7 - Actual: 1.0\n",
      "Predicted: 59.7 - Actual: 29.0\n",
      "Predicted: 59.7 - Actual: 1.0\n",
      "Predicted: 59.7 - Actual: 35.0\n",
      "Predicted: 59.7 - Actual: 13.0\n",
      "Predicted: 59.7 - Actual: 0.3\n",
      "Predicted: 59.7 - Actual: 190.0\n",
      "Predicted: 59.7 - Actual: 35.0\n",
      "Predicted: 59.7 - Actual: 190.0\n",
      "Predicted: 59.7 - Actual: 330.0\n",
      "Predicted: 59.7 - Actual: 29.0\n",
      "Predicted: 59.7 - Actual: 3.0\n",
      "Predicted: 59.7 - Actual: 29.0\n",
      "Predicted: 59.7 - Actual: 0.3\n",
      "Predicted: 59.7 - Actual: 3.0\n",
      "Predicted: 59.7 - Actual: 330.0\n",
      "Predicted: 59.7 - Actual: 3.0\n",
      "Predicted: 59.7 - Actual: 13.0\n",
      "Predicted: 59.7 - Actual: 3.0\n",
      "Predicted: 59.7 - Actual: 190.0\n",
      "Predicted: 59.7 - Actual: 1.0\n",
      "Predicted: 59.7 - Actual: 13.0\n",
      "Predicted: 59.7 - Actual: 29.0\n",
      "Predicted: 59.7 - Actual: 20.0\n",
      "Predicted: 59.7 - Actual: 330.0\n",
      "Predicted: 59.7 - Actual: 330.0\n",
      "Predicted: 59.7 - Actual: 0.3\n",
      "Predicted: 59.7 - Actual: 3.0\n",
      "Predicted: 59.7 - Actual: 0.3\n",
      "Predicted: 59.7 - Actual: 35.0\n",
      "Predicted: 59.7 - Actual: 35.0\n",
      "Predicted: 59.7 - Actual: 330.0\n",
      "Predicted: 59.7 - Actual: 3.0\n",
      "Predicted: 59.7 - Actual: 20.0\n",
      "Predicted: 59.7 - Actual: 330.0\n",
      "Predicted: 59.7 - Actual: 3.0\n",
      "Predicted: 59.7 - Actual: 20.0\n",
      "Predicted: 59.7 - Actual: 3.0\n",
      "Predicted: 59.7 - Actual: 0.3\n",
      "Predicted: 59.7 - Actual: 13.0\n",
      "Predicted: 59.7 - Actual: 20.0\n",
      "Predicted: 59.7 - Actual: 20.0\n",
      "Predicted: 59.7 - Actual: 0.3\n",
      "Predicted: 59.7 - Actual: 29.0\n",
      "Predicted: 59.7 - Actual: 29.0\n",
      "Predicted: 59.7 - Actual: 29.0\n",
      "Predicted: 59.7 - Actual: 330.0\n"
     ]
    }
   ],
   "source": [
    "pred_val = model.predict(x_val)\n",
    "for i in range(len(pred_val)):\n",
    "    print(f\"Predicted: {round(float(pred_val[i][0]), 1)} - Actual: {y_val.to_numpy()[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58263a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Cardboard1 Predicted: 59.7 - Actual: 20.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Ceramic1 Predicted: 59.7 - Actual: 330.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Glass1 Predicted: 59.7 - Actual: 35.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Plastic1 Predicted: 59.7 - Actual: 3.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n",
      "Rock1 Predicted: 59.7 - Actual: 1.0\n"
     ]
    }
   ],
   "source": [
    "pred_test = model.predict(e_test_x)\n",
    "for i in range(len(pred_test)):\n",
    "    print(e_test_name[i], f\"Predicted: {round(float(pred_test[i][0]), 1)} - Actual: {e_test_y.to_numpy()[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209a287b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af76ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761279c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
