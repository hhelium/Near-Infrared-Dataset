{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a621de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-02 14:55:28.706212: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-02 14:55:29.396457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-10.0/lib64:/home/rilab/DTran/.other/Cpp_libraries/librealsense-2.47.0/install/lib:/home/rilab/anaconda3/envs/huiEnv/lib/\n",
      "2023-03-02 14:55:29.396532: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-10.0/lib64:/home/rilab/DTran/.other/Cpp_libraries/librealsense-2.47.0/install/lib:/home/rilab/anaconda3/envs/huiEnv/lib/\n",
      "2023-03-02 14:55:29.396539: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# train with fewer data. ideal data\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from sklearn import preprocessing\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop, SGD, Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, Model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98db4224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7f9871d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>materials</th>\n",
       "      <th>names</th>\n",
       "      <th>spectrum_0</th>\n",
       "      <th>spectrum_1</th>\n",
       "      <th>spectrum_2</th>\n",
       "      <th>spectrum_3</th>\n",
       "      <th>spectrum_4</th>\n",
       "      <th>spectrum_5</th>\n",
       "      <th>spectrum_6</th>\n",
       "      <th>spectrum_7</th>\n",
       "      <th>...</th>\n",
       "      <th>spectrum_321</th>\n",
       "      <th>spectrum_322</th>\n",
       "      <th>spectrum_323</th>\n",
       "      <th>spectrum_324</th>\n",
       "      <th>spectrum_325</th>\n",
       "      <th>spectrum_326</th>\n",
       "      <th>spectrum_327</th>\n",
       "      <th>spectrum_328</th>\n",
       "      <th>spectrum_329</th>\n",
       "      <th>spectrum_330</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Cardboard</td>\n",
       "      <td>0.384066</td>\n",
       "      <td>0.384843</td>\n",
       "      <td>0.385626</td>\n",
       "      <td>0.386434</td>\n",
       "      <td>0.387287</td>\n",
       "      <td>0.388186</td>\n",
       "      <td>0.389121</td>\n",
       "      <td>0.390084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506651</td>\n",
       "      <td>0.507237</td>\n",
       "      <td>0.507503</td>\n",
       "      <td>0.507553</td>\n",
       "      <td>0.507573</td>\n",
       "      <td>0.507545</td>\n",
       "      <td>0.507856</td>\n",
       "      <td>0.508297</td>\n",
       "      <td>0.508671</td>\n",
       "      <td>0.508708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Cardboard</td>\n",
       "      <td>0.384066</td>\n",
       "      <td>0.384843</td>\n",
       "      <td>0.385626</td>\n",
       "      <td>0.386434</td>\n",
       "      <td>0.387287</td>\n",
       "      <td>0.388186</td>\n",
       "      <td>0.389121</td>\n",
       "      <td>0.390084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506651</td>\n",
       "      <td>0.507237</td>\n",
       "      <td>0.507503</td>\n",
       "      <td>0.507553</td>\n",
       "      <td>0.507573</td>\n",
       "      <td>0.507545</td>\n",
       "      <td>0.507856</td>\n",
       "      <td>0.508297</td>\n",
       "      <td>0.508671</td>\n",
       "      <td>0.508708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Cardboard</td>\n",
       "      <td>0.384066</td>\n",
       "      <td>0.384843</td>\n",
       "      <td>0.385626</td>\n",
       "      <td>0.386434</td>\n",
       "      <td>0.387287</td>\n",
       "      <td>0.388186</td>\n",
       "      <td>0.389121</td>\n",
       "      <td>0.390084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506651</td>\n",
       "      <td>0.507237</td>\n",
       "      <td>0.507503</td>\n",
       "      <td>0.507553</td>\n",
       "      <td>0.507573</td>\n",
       "      <td>0.507545</td>\n",
       "      <td>0.507856</td>\n",
       "      <td>0.508297</td>\n",
       "      <td>0.508671</td>\n",
       "      <td>0.508708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Cardboard</td>\n",
       "      <td>0.384066</td>\n",
       "      <td>0.384843</td>\n",
       "      <td>0.385626</td>\n",
       "      <td>0.386434</td>\n",
       "      <td>0.387287</td>\n",
       "      <td>0.388186</td>\n",
       "      <td>0.389121</td>\n",
       "      <td>0.390084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506651</td>\n",
       "      <td>0.507237</td>\n",
       "      <td>0.507503</td>\n",
       "      <td>0.507553</td>\n",
       "      <td>0.507573</td>\n",
       "      <td>0.507545</td>\n",
       "      <td>0.507856</td>\n",
       "      <td>0.508297</td>\n",
       "      <td>0.508671</td>\n",
       "      <td>0.508708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Cardboard</td>\n",
       "      <td>0.384066</td>\n",
       "      <td>0.384843</td>\n",
       "      <td>0.385626</td>\n",
       "      <td>0.386434</td>\n",
       "      <td>0.387287</td>\n",
       "      <td>0.388186</td>\n",
       "      <td>0.389121</td>\n",
       "      <td>0.390084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506651</td>\n",
       "      <td>0.507237</td>\n",
       "      <td>0.507503</td>\n",
       "      <td>0.507553</td>\n",
       "      <td>0.507573</td>\n",
       "      <td>0.507545</td>\n",
       "      <td>0.507856</td>\n",
       "      <td>0.508297</td>\n",
       "      <td>0.508671</td>\n",
       "      <td>0.508708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>8</td>\n",
       "      <td>Wood</td>\n",
       "      <td>0.677472</td>\n",
       "      <td>0.677854</td>\n",
       "      <td>0.678184</td>\n",
       "      <td>0.678508</td>\n",
       "      <td>0.678866</td>\n",
       "      <td>0.679257</td>\n",
       "      <td>0.679667</td>\n",
       "      <td>0.680083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741037</td>\n",
       "      <td>0.741881</td>\n",
       "      <td>0.742257</td>\n",
       "      <td>0.742320</td>\n",
       "      <td>0.742340</td>\n",
       "      <td>0.742291</td>\n",
       "      <td>0.742738</td>\n",
       "      <td>0.743378</td>\n",
       "      <td>0.743919</td>\n",
       "      <td>0.743970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>8</td>\n",
       "      <td>Wood</td>\n",
       "      <td>0.677472</td>\n",
       "      <td>0.677854</td>\n",
       "      <td>0.678184</td>\n",
       "      <td>0.678508</td>\n",
       "      <td>0.678866</td>\n",
       "      <td>0.679257</td>\n",
       "      <td>0.679667</td>\n",
       "      <td>0.680083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741037</td>\n",
       "      <td>0.741881</td>\n",
       "      <td>0.742257</td>\n",
       "      <td>0.742320</td>\n",
       "      <td>0.742340</td>\n",
       "      <td>0.742291</td>\n",
       "      <td>0.742738</td>\n",
       "      <td>0.743378</td>\n",
       "      <td>0.743919</td>\n",
       "      <td>0.743970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>8</td>\n",
       "      <td>Wood</td>\n",
       "      <td>0.677472</td>\n",
       "      <td>0.677854</td>\n",
       "      <td>0.678184</td>\n",
       "      <td>0.678508</td>\n",
       "      <td>0.678866</td>\n",
       "      <td>0.679257</td>\n",
       "      <td>0.679667</td>\n",
       "      <td>0.680083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741037</td>\n",
       "      <td>0.741881</td>\n",
       "      <td>0.742257</td>\n",
       "      <td>0.742320</td>\n",
       "      <td>0.742340</td>\n",
       "      <td>0.742291</td>\n",
       "      <td>0.742738</td>\n",
       "      <td>0.743378</td>\n",
       "      <td>0.743919</td>\n",
       "      <td>0.743970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>8</td>\n",
       "      <td>Wood</td>\n",
       "      <td>0.677472</td>\n",
       "      <td>0.677854</td>\n",
       "      <td>0.678184</td>\n",
       "      <td>0.678508</td>\n",
       "      <td>0.678866</td>\n",
       "      <td>0.679257</td>\n",
       "      <td>0.679667</td>\n",
       "      <td>0.680083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741037</td>\n",
       "      <td>0.741881</td>\n",
       "      <td>0.742257</td>\n",
       "      <td>0.742320</td>\n",
       "      <td>0.742340</td>\n",
       "      <td>0.742291</td>\n",
       "      <td>0.742738</td>\n",
       "      <td>0.743378</td>\n",
       "      <td>0.743919</td>\n",
       "      <td>0.743970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>8</td>\n",
       "      <td>Wood</td>\n",
       "      <td>0.677472</td>\n",
       "      <td>0.677854</td>\n",
       "      <td>0.678184</td>\n",
       "      <td>0.678508</td>\n",
       "      <td>0.678866</td>\n",
       "      <td>0.679257</td>\n",
       "      <td>0.679667</td>\n",
       "      <td>0.680083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741037</td>\n",
       "      <td>0.741881</td>\n",
       "      <td>0.742257</td>\n",
       "      <td>0.742320</td>\n",
       "      <td>0.742340</td>\n",
       "      <td>0.742291</td>\n",
       "      <td>0.742738</td>\n",
       "      <td>0.743378</td>\n",
       "      <td>0.743919</td>\n",
       "      <td>0.743970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1260 rows × 333 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      materials      names  spectrum_0  spectrum_1  spectrum_2  spectrum_3  \\\n",
       "0             0  Cardboard    0.384066    0.384843    0.385626    0.386434   \n",
       "1             0  Cardboard    0.384066    0.384843    0.385626    0.386434   \n",
       "2             0  Cardboard    0.384066    0.384843    0.385626    0.386434   \n",
       "3             0  Cardboard    0.384066    0.384843    0.385626    0.386434   \n",
       "4             0  Cardboard    0.384066    0.384843    0.385626    0.386434   \n",
       "...         ...        ...         ...         ...         ...         ...   \n",
       "1255          8       Wood    0.677472    0.677854    0.678184    0.678508   \n",
       "1256          8       Wood    0.677472    0.677854    0.678184    0.678508   \n",
       "1257          8       Wood    0.677472    0.677854    0.678184    0.678508   \n",
       "1258          8       Wood    0.677472    0.677854    0.678184    0.678508   \n",
       "1259          8       Wood    0.677472    0.677854    0.678184    0.678508   \n",
       "\n",
       "      spectrum_4  spectrum_5  spectrum_6  spectrum_7  ...  spectrum_321  \\\n",
       "0       0.387287    0.388186    0.389121    0.390084  ...      0.506651   \n",
       "1       0.387287    0.388186    0.389121    0.390084  ...      0.506651   \n",
       "2       0.387287    0.388186    0.389121    0.390084  ...      0.506651   \n",
       "3       0.387287    0.388186    0.389121    0.390084  ...      0.506651   \n",
       "4       0.387287    0.388186    0.389121    0.390084  ...      0.506651   \n",
       "...          ...         ...         ...         ...  ...           ...   \n",
       "1255    0.678866    0.679257    0.679667    0.680083  ...      0.741037   \n",
       "1256    0.678866    0.679257    0.679667    0.680083  ...      0.741037   \n",
       "1257    0.678866    0.679257    0.679667    0.680083  ...      0.741037   \n",
       "1258    0.678866    0.679257    0.679667    0.680083  ...      0.741037   \n",
       "1259    0.678866    0.679257    0.679667    0.680083  ...      0.741037   \n",
       "\n",
       "      spectrum_322  spectrum_323  spectrum_324  spectrum_325  spectrum_326  \\\n",
       "0         0.507237      0.507503      0.507553      0.507573      0.507545   \n",
       "1         0.507237      0.507503      0.507553      0.507573      0.507545   \n",
       "2         0.507237      0.507503      0.507553      0.507573      0.507545   \n",
       "3         0.507237      0.507503      0.507553      0.507573      0.507545   \n",
       "4         0.507237      0.507503      0.507553      0.507573      0.507545   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "1255      0.741881      0.742257      0.742320      0.742340      0.742291   \n",
       "1256      0.741881      0.742257      0.742320      0.742340      0.742291   \n",
       "1257      0.741881      0.742257      0.742320      0.742340      0.742291   \n",
       "1258      0.741881      0.742257      0.742320      0.742340      0.742291   \n",
       "1259      0.741881      0.742257      0.742320      0.742340      0.742291   \n",
       "\n",
       "      spectrum_327  spectrum_328  spectrum_329  spectrum_330  \n",
       "0         0.507856      0.508297      0.508671      0.508708  \n",
       "1         0.507856      0.508297      0.508671      0.508708  \n",
       "2         0.507856      0.508297      0.508671      0.508708  \n",
       "3         0.507856      0.508297      0.508671      0.508708  \n",
       "4         0.507856      0.508297      0.508671      0.508708  \n",
       "...            ...           ...           ...           ...  \n",
       "1255      0.742738      0.743378      0.743919      0.743970  \n",
       "1256      0.742738      0.743378      0.743919      0.743970  \n",
       "1257      0.742738      0.743378      0.743919      0.743970  \n",
       "1258      0.742738      0.743378      0.743919      0.743970  \n",
       "1259      0.742738      0.743378      0.743919      0.743970  \n",
       "\n",
       "[1260 rows x 333 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dae_label = pd.read_csv(\"c_label.csv\")\n",
    "dae_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a038c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>materials</th>\n",
       "      <th>names</th>\n",
       "      <th>color</th>\n",
       "      <th>distance</th>\n",
       "      <th>mode</th>\n",
       "      <th>spectrum_0</th>\n",
       "      <th>spectrum_1</th>\n",
       "      <th>spectrum_2</th>\n",
       "      <th>spectrum_3</th>\n",
       "      <th>spectrum_4</th>\n",
       "      <th>...</th>\n",
       "      <th>spectrum_321</th>\n",
       "      <th>spectrum_322</th>\n",
       "      <th>spectrum_323</th>\n",
       "      <th>spectrum_324</th>\n",
       "      <th>spectrum_325</th>\n",
       "      <th>spectrum_326</th>\n",
       "      <th>spectrum_327</th>\n",
       "      <th>spectrum_328</th>\n",
       "      <th>spectrum_329</th>\n",
       "      <th>spectrum_330</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Cardboard</td>\n",
       "      <td>N</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.526403</td>\n",
       "      <td>0.527891</td>\n",
       "      <td>0.529310</td>\n",
       "      <td>0.530688</td>\n",
       "      <td>0.532068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670099</td>\n",
       "      <td>0.670870</td>\n",
       "      <td>0.671219</td>\n",
       "      <td>0.671284</td>\n",
       "      <td>0.671310</td>\n",
       "      <td>0.671274</td>\n",
       "      <td>0.671686</td>\n",
       "      <td>0.672272</td>\n",
       "      <td>0.672768</td>\n",
       "      <td>0.672819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Cardboard</td>\n",
       "      <td>N</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.542235</td>\n",
       "      <td>0.543597</td>\n",
       "      <td>0.544961</td>\n",
       "      <td>0.546345</td>\n",
       "      <td>0.547773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.685934</td>\n",
       "      <td>0.686723</td>\n",
       "      <td>0.687080</td>\n",
       "      <td>0.687148</td>\n",
       "      <td>0.687176</td>\n",
       "      <td>0.687140</td>\n",
       "      <td>0.687564</td>\n",
       "      <td>0.688165</td>\n",
       "      <td>0.688675</td>\n",
       "      <td>0.688728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Cardboard</td>\n",
       "      <td>N</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.536953</td>\n",
       "      <td>0.538290</td>\n",
       "      <td>0.539612</td>\n",
       "      <td>0.540949</td>\n",
       "      <td>0.542335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.679368</td>\n",
       "      <td>0.680120</td>\n",
       "      <td>0.680447</td>\n",
       "      <td>0.680490</td>\n",
       "      <td>0.680496</td>\n",
       "      <td>0.680442</td>\n",
       "      <td>0.680844</td>\n",
       "      <td>0.681425</td>\n",
       "      <td>0.681916</td>\n",
       "      <td>0.681958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Cardboard</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.543379</td>\n",
       "      <td>0.544370</td>\n",
       "      <td>0.545400</td>\n",
       "      <td>0.546501</td>\n",
       "      <td>0.547699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686358</td>\n",
       "      <td>0.687150</td>\n",
       "      <td>0.687509</td>\n",
       "      <td>0.687577</td>\n",
       "      <td>0.687605</td>\n",
       "      <td>0.687568</td>\n",
       "      <td>0.687990</td>\n",
       "      <td>0.688591</td>\n",
       "      <td>0.689099</td>\n",
       "      <td>0.689151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Cardboard</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.523413</td>\n",
       "      <td>0.524326</td>\n",
       "      <td>0.525328</td>\n",
       "      <td>0.526431</td>\n",
       "      <td>0.527640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661900</td>\n",
       "      <td>0.662690</td>\n",
       "      <td>0.663060</td>\n",
       "      <td>0.663147</td>\n",
       "      <td>0.663193</td>\n",
       "      <td>0.663175</td>\n",
       "      <td>0.663598</td>\n",
       "      <td>0.664191</td>\n",
       "      <td>0.664694</td>\n",
       "      <td>0.664755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>8</td>\n",
       "      <td>Wood</td>\n",
       "      <td>W</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.501132</td>\n",
       "      <td>0.501212</td>\n",
       "      <td>0.501278</td>\n",
       "      <td>0.501364</td>\n",
       "      <td>0.501494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543924</td>\n",
       "      <td>0.544602</td>\n",
       "      <td>0.544929</td>\n",
       "      <td>0.545019</td>\n",
       "      <td>0.545072</td>\n",
       "      <td>0.545068</td>\n",
       "      <td>0.545425</td>\n",
       "      <td>0.545920</td>\n",
       "      <td>0.546338</td>\n",
       "      <td>0.546392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>8</td>\n",
       "      <td>Wood</td>\n",
       "      <td>W</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.462299</td>\n",
       "      <td>0.462222</td>\n",
       "      <td>0.462148</td>\n",
       "      <td>0.462112</td>\n",
       "      <td>0.462131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500846</td>\n",
       "      <td>0.501468</td>\n",
       "      <td>0.501766</td>\n",
       "      <td>0.501847</td>\n",
       "      <td>0.501893</td>\n",
       "      <td>0.501888</td>\n",
       "      <td>0.502214</td>\n",
       "      <td>0.502668</td>\n",
       "      <td>0.503051</td>\n",
       "      <td>0.503099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>8</td>\n",
       "      <td>Wood</td>\n",
       "      <td>W</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.197083</td>\n",
       "      <td>0.197172</td>\n",
       "      <td>0.197252</td>\n",
       "      <td>0.197331</td>\n",
       "      <td>0.197412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216179</td>\n",
       "      <td>0.216449</td>\n",
       "      <td>0.216579</td>\n",
       "      <td>0.216614</td>\n",
       "      <td>0.216634</td>\n",
       "      <td>0.216632</td>\n",
       "      <td>0.216773</td>\n",
       "      <td>0.216968</td>\n",
       "      <td>0.217133</td>\n",
       "      <td>0.217154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>8</td>\n",
       "      <td>Wood</td>\n",
       "      <td>W</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.183714</td>\n",
       "      <td>0.183832</td>\n",
       "      <td>0.183919</td>\n",
       "      <td>0.183990</td>\n",
       "      <td>0.184056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200452</td>\n",
       "      <td>0.200693</td>\n",
       "      <td>0.200805</td>\n",
       "      <td>0.200831</td>\n",
       "      <td>0.200843</td>\n",
       "      <td>0.200835</td>\n",
       "      <td>0.200960</td>\n",
       "      <td>0.201136</td>\n",
       "      <td>0.201285</td>\n",
       "      <td>0.201301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>8</td>\n",
       "      <td>Wood</td>\n",
       "      <td>W</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.177628</td>\n",
       "      <td>0.177632</td>\n",
       "      <td>0.177647</td>\n",
       "      <td>0.177677</td>\n",
       "      <td>0.177724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193133</td>\n",
       "      <td>0.193387</td>\n",
       "      <td>0.193515</td>\n",
       "      <td>0.193558</td>\n",
       "      <td>0.193585</td>\n",
       "      <td>0.193592</td>\n",
       "      <td>0.193726</td>\n",
       "      <td>0.193907</td>\n",
       "      <td>0.194060</td>\n",
       "      <td>0.194083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1260 rows × 336 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      materials      names color  distance  mode  spectrum_0  spectrum_1  \\\n",
       "0             0  Cardboard     N       0.5     0    0.526403    0.527891   \n",
       "1             0  Cardboard     N       0.5     0    0.542235    0.543597   \n",
       "2             0  Cardboard     N       0.5     0    0.536953    0.538290   \n",
       "3             0  Cardboard     N       1.0     0    0.543379    0.544370   \n",
       "4             0  Cardboard     N       1.0     0    0.523413    0.524326   \n",
       "...         ...        ...   ...       ...   ...         ...         ...   \n",
       "1255          8       Wood     W       1.0     4    0.501132    0.501212   \n",
       "1256          8       Wood     W       1.0     4    0.462299    0.462222   \n",
       "1257          8       Wood     W       2.0     4    0.197083    0.197172   \n",
       "1258          8       Wood     W       2.0     4    0.183714    0.183832   \n",
       "1259          8       Wood     W       2.0     4    0.177628    0.177632   \n",
       "\n",
       "      spectrum_2  spectrum_3  spectrum_4  ...  spectrum_321  spectrum_322  \\\n",
       "0       0.529310    0.530688    0.532068  ...      0.670099      0.670870   \n",
       "1       0.544961    0.546345    0.547773  ...      0.685934      0.686723   \n",
       "2       0.539612    0.540949    0.542335  ...      0.679368      0.680120   \n",
       "3       0.545400    0.546501    0.547699  ...      0.686358      0.687150   \n",
       "4       0.525328    0.526431    0.527640  ...      0.661900      0.662690   \n",
       "...          ...         ...         ...  ...           ...           ...   \n",
       "1255    0.501278    0.501364    0.501494  ...      0.543924      0.544602   \n",
       "1256    0.462148    0.462112    0.462131  ...      0.500846      0.501468   \n",
       "1257    0.197252    0.197331    0.197412  ...      0.216179      0.216449   \n",
       "1258    0.183919    0.183990    0.184056  ...      0.200452      0.200693   \n",
       "1259    0.177647    0.177677    0.177724  ...      0.193133      0.193387   \n",
       "\n",
       "      spectrum_323  spectrum_324  spectrum_325  spectrum_326  spectrum_327  \\\n",
       "0         0.671219      0.671284      0.671310      0.671274      0.671686   \n",
       "1         0.687080      0.687148      0.687176      0.687140      0.687564   \n",
       "2         0.680447      0.680490      0.680496      0.680442      0.680844   \n",
       "3         0.687509      0.687577      0.687605      0.687568      0.687990   \n",
       "4         0.663060      0.663147      0.663193      0.663175      0.663598   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "1255      0.544929      0.545019      0.545072      0.545068      0.545425   \n",
       "1256      0.501766      0.501847      0.501893      0.501888      0.502214   \n",
       "1257      0.216579      0.216614      0.216634      0.216632      0.216773   \n",
       "1258      0.200805      0.200831      0.200843      0.200835      0.200960   \n",
       "1259      0.193515      0.193558      0.193585      0.193592      0.193726   \n",
       "\n",
       "      spectrum_328  spectrum_329  spectrum_330  \n",
       "0         0.672272      0.672768      0.672819  \n",
       "1         0.688165      0.688675      0.688728  \n",
       "2         0.681425      0.681916      0.681958  \n",
       "3         0.688591      0.689099      0.689151  \n",
       "4         0.664191      0.664694      0.664755  \n",
       "...            ...           ...           ...  \n",
       "1255      0.545920      0.546338      0.546392  \n",
       "1256      0.502668      0.503051      0.503099  \n",
       "1257      0.216968      0.217133      0.217154  \n",
       "1258      0.201136      0.201285      0.201301  \n",
       "1259      0.193907      0.194060      0.194083  \n",
       "\n",
       "[1260 rows x 336 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "data1 = data.copy()\n",
    "dae_train = data.copy()\n",
    "dae_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "839d727e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spectrum_0</th>\n",
       "      <th>spectrum_1</th>\n",
       "      <th>spectrum_2</th>\n",
       "      <th>spectrum_3</th>\n",
       "      <th>spectrum_4</th>\n",
       "      <th>spectrum_5</th>\n",
       "      <th>spectrum_6</th>\n",
       "      <th>spectrum_7</th>\n",
       "      <th>spectrum_8</th>\n",
       "      <th>spectrum_9</th>\n",
       "      <th>...</th>\n",
       "      <th>spectrum_321</th>\n",
       "      <th>spectrum_322</th>\n",
       "      <th>spectrum_323</th>\n",
       "      <th>spectrum_324</th>\n",
       "      <th>spectrum_325</th>\n",
       "      <th>spectrum_326</th>\n",
       "      <th>spectrum_327</th>\n",
       "      <th>spectrum_328</th>\n",
       "      <th>spectrum_329</th>\n",
       "      <th>spectrum_330</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.384066</td>\n",
       "      <td>0.384843</td>\n",
       "      <td>0.385626</td>\n",
       "      <td>0.386434</td>\n",
       "      <td>0.387287</td>\n",
       "      <td>0.388186</td>\n",
       "      <td>0.389121</td>\n",
       "      <td>0.390084</td>\n",
       "      <td>0.391064</td>\n",
       "      <td>0.392051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506651</td>\n",
       "      <td>0.507237</td>\n",
       "      <td>0.507503</td>\n",
       "      <td>0.507553</td>\n",
       "      <td>0.507573</td>\n",
       "      <td>0.507545</td>\n",
       "      <td>0.507856</td>\n",
       "      <td>0.508297</td>\n",
       "      <td>0.508671</td>\n",
       "      <td>0.508708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.384066</td>\n",
       "      <td>0.384843</td>\n",
       "      <td>0.385626</td>\n",
       "      <td>0.386434</td>\n",
       "      <td>0.387287</td>\n",
       "      <td>0.388186</td>\n",
       "      <td>0.389121</td>\n",
       "      <td>0.390084</td>\n",
       "      <td>0.391064</td>\n",
       "      <td>0.392051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506651</td>\n",
       "      <td>0.507237</td>\n",
       "      <td>0.507503</td>\n",
       "      <td>0.507553</td>\n",
       "      <td>0.507573</td>\n",
       "      <td>0.507545</td>\n",
       "      <td>0.507856</td>\n",
       "      <td>0.508297</td>\n",
       "      <td>0.508671</td>\n",
       "      <td>0.508708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.384066</td>\n",
       "      <td>0.384843</td>\n",
       "      <td>0.385626</td>\n",
       "      <td>0.386434</td>\n",
       "      <td>0.387287</td>\n",
       "      <td>0.388186</td>\n",
       "      <td>0.389121</td>\n",
       "      <td>0.390084</td>\n",
       "      <td>0.391064</td>\n",
       "      <td>0.392051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506651</td>\n",
       "      <td>0.507237</td>\n",
       "      <td>0.507503</td>\n",
       "      <td>0.507553</td>\n",
       "      <td>0.507573</td>\n",
       "      <td>0.507545</td>\n",
       "      <td>0.507856</td>\n",
       "      <td>0.508297</td>\n",
       "      <td>0.508671</td>\n",
       "      <td>0.508708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.384066</td>\n",
       "      <td>0.384843</td>\n",
       "      <td>0.385626</td>\n",
       "      <td>0.386434</td>\n",
       "      <td>0.387287</td>\n",
       "      <td>0.388186</td>\n",
       "      <td>0.389121</td>\n",
       "      <td>0.390084</td>\n",
       "      <td>0.391064</td>\n",
       "      <td>0.392051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506651</td>\n",
       "      <td>0.507237</td>\n",
       "      <td>0.507503</td>\n",
       "      <td>0.507553</td>\n",
       "      <td>0.507573</td>\n",
       "      <td>0.507545</td>\n",
       "      <td>0.507856</td>\n",
       "      <td>0.508297</td>\n",
       "      <td>0.508671</td>\n",
       "      <td>0.508708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.384066</td>\n",
       "      <td>0.384843</td>\n",
       "      <td>0.385626</td>\n",
       "      <td>0.386434</td>\n",
       "      <td>0.387287</td>\n",
       "      <td>0.388186</td>\n",
       "      <td>0.389121</td>\n",
       "      <td>0.390084</td>\n",
       "      <td>0.391064</td>\n",
       "      <td>0.392051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506651</td>\n",
       "      <td>0.507237</td>\n",
       "      <td>0.507503</td>\n",
       "      <td>0.507553</td>\n",
       "      <td>0.507573</td>\n",
       "      <td>0.507545</td>\n",
       "      <td>0.507856</td>\n",
       "      <td>0.508297</td>\n",
       "      <td>0.508671</td>\n",
       "      <td>0.508708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>0.677472</td>\n",
       "      <td>0.677854</td>\n",
       "      <td>0.678184</td>\n",
       "      <td>0.678508</td>\n",
       "      <td>0.678866</td>\n",
       "      <td>0.679257</td>\n",
       "      <td>0.679667</td>\n",
       "      <td>0.680083</td>\n",
       "      <td>0.680496</td>\n",
       "      <td>0.680889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741037</td>\n",
       "      <td>0.741881</td>\n",
       "      <td>0.742257</td>\n",
       "      <td>0.742320</td>\n",
       "      <td>0.742340</td>\n",
       "      <td>0.742291</td>\n",
       "      <td>0.742738</td>\n",
       "      <td>0.743378</td>\n",
       "      <td>0.743919</td>\n",
       "      <td>0.743970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>0.677472</td>\n",
       "      <td>0.677854</td>\n",
       "      <td>0.678184</td>\n",
       "      <td>0.678508</td>\n",
       "      <td>0.678866</td>\n",
       "      <td>0.679257</td>\n",
       "      <td>0.679667</td>\n",
       "      <td>0.680083</td>\n",
       "      <td>0.680496</td>\n",
       "      <td>0.680889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741037</td>\n",
       "      <td>0.741881</td>\n",
       "      <td>0.742257</td>\n",
       "      <td>0.742320</td>\n",
       "      <td>0.742340</td>\n",
       "      <td>0.742291</td>\n",
       "      <td>0.742738</td>\n",
       "      <td>0.743378</td>\n",
       "      <td>0.743919</td>\n",
       "      <td>0.743970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>0.677472</td>\n",
       "      <td>0.677854</td>\n",
       "      <td>0.678184</td>\n",
       "      <td>0.678508</td>\n",
       "      <td>0.678866</td>\n",
       "      <td>0.679257</td>\n",
       "      <td>0.679667</td>\n",
       "      <td>0.680083</td>\n",
       "      <td>0.680496</td>\n",
       "      <td>0.680889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741037</td>\n",
       "      <td>0.741881</td>\n",
       "      <td>0.742257</td>\n",
       "      <td>0.742320</td>\n",
       "      <td>0.742340</td>\n",
       "      <td>0.742291</td>\n",
       "      <td>0.742738</td>\n",
       "      <td>0.743378</td>\n",
       "      <td>0.743919</td>\n",
       "      <td>0.743970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>0.677472</td>\n",
       "      <td>0.677854</td>\n",
       "      <td>0.678184</td>\n",
       "      <td>0.678508</td>\n",
       "      <td>0.678866</td>\n",
       "      <td>0.679257</td>\n",
       "      <td>0.679667</td>\n",
       "      <td>0.680083</td>\n",
       "      <td>0.680496</td>\n",
       "      <td>0.680889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741037</td>\n",
       "      <td>0.741881</td>\n",
       "      <td>0.742257</td>\n",
       "      <td>0.742320</td>\n",
       "      <td>0.742340</td>\n",
       "      <td>0.742291</td>\n",
       "      <td>0.742738</td>\n",
       "      <td>0.743378</td>\n",
       "      <td>0.743919</td>\n",
       "      <td>0.743970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>0.677472</td>\n",
       "      <td>0.677854</td>\n",
       "      <td>0.678184</td>\n",
       "      <td>0.678508</td>\n",
       "      <td>0.678866</td>\n",
       "      <td>0.679257</td>\n",
       "      <td>0.679667</td>\n",
       "      <td>0.680083</td>\n",
       "      <td>0.680496</td>\n",
       "      <td>0.680889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741037</td>\n",
       "      <td>0.741881</td>\n",
       "      <td>0.742257</td>\n",
       "      <td>0.742320</td>\n",
       "      <td>0.742340</td>\n",
       "      <td>0.742291</td>\n",
       "      <td>0.742738</td>\n",
       "      <td>0.743378</td>\n",
       "      <td>0.743919</td>\n",
       "      <td>0.743970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1260 rows × 331 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      spectrum_0  spectrum_1  spectrum_2  spectrum_3  spectrum_4  spectrum_5  \\\n",
       "0       0.384066    0.384843    0.385626    0.386434    0.387287    0.388186   \n",
       "1       0.384066    0.384843    0.385626    0.386434    0.387287    0.388186   \n",
       "2       0.384066    0.384843    0.385626    0.386434    0.387287    0.388186   \n",
       "3       0.384066    0.384843    0.385626    0.386434    0.387287    0.388186   \n",
       "4       0.384066    0.384843    0.385626    0.386434    0.387287    0.388186   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1255    0.677472    0.677854    0.678184    0.678508    0.678866    0.679257   \n",
       "1256    0.677472    0.677854    0.678184    0.678508    0.678866    0.679257   \n",
       "1257    0.677472    0.677854    0.678184    0.678508    0.678866    0.679257   \n",
       "1258    0.677472    0.677854    0.678184    0.678508    0.678866    0.679257   \n",
       "1259    0.677472    0.677854    0.678184    0.678508    0.678866    0.679257   \n",
       "\n",
       "      spectrum_6  spectrum_7  spectrum_8  spectrum_9  ...  spectrum_321  \\\n",
       "0       0.389121    0.390084    0.391064    0.392051  ...      0.506651   \n",
       "1       0.389121    0.390084    0.391064    0.392051  ...      0.506651   \n",
       "2       0.389121    0.390084    0.391064    0.392051  ...      0.506651   \n",
       "3       0.389121    0.390084    0.391064    0.392051  ...      0.506651   \n",
       "4       0.389121    0.390084    0.391064    0.392051  ...      0.506651   \n",
       "...          ...         ...         ...         ...  ...           ...   \n",
       "1255    0.679667    0.680083    0.680496    0.680889  ...      0.741037   \n",
       "1256    0.679667    0.680083    0.680496    0.680889  ...      0.741037   \n",
       "1257    0.679667    0.680083    0.680496    0.680889  ...      0.741037   \n",
       "1258    0.679667    0.680083    0.680496    0.680889  ...      0.741037   \n",
       "1259    0.679667    0.680083    0.680496    0.680889  ...      0.741037   \n",
       "\n",
       "      spectrum_322  spectrum_323  spectrum_324  spectrum_325  spectrum_326  \\\n",
       "0         0.507237      0.507503      0.507553      0.507573      0.507545   \n",
       "1         0.507237      0.507503      0.507553      0.507573      0.507545   \n",
       "2         0.507237      0.507503      0.507553      0.507573      0.507545   \n",
       "3         0.507237      0.507503      0.507553      0.507573      0.507545   \n",
       "4         0.507237      0.507503      0.507553      0.507573      0.507545   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "1255      0.741881      0.742257      0.742320      0.742340      0.742291   \n",
       "1256      0.741881      0.742257      0.742320      0.742340      0.742291   \n",
       "1257      0.741881      0.742257      0.742320      0.742340      0.742291   \n",
       "1258      0.741881      0.742257      0.742320      0.742340      0.742291   \n",
       "1259      0.741881      0.742257      0.742320      0.742340      0.742291   \n",
       "\n",
       "      spectrum_327  spectrum_328  spectrum_329  spectrum_330  \n",
       "0         0.507856      0.508297      0.508671      0.508708  \n",
       "1         0.507856      0.508297      0.508671      0.508708  \n",
       "2         0.507856      0.508297      0.508671      0.508708  \n",
       "3         0.507856      0.508297      0.508671      0.508708  \n",
       "4         0.507856      0.508297      0.508671      0.508708  \n",
       "...            ...           ...           ...           ...  \n",
       "1255      0.742738      0.743378      0.743919      0.743970  \n",
       "1256      0.742738      0.743378      0.743919      0.743970  \n",
       "1257      0.742738      0.743378      0.743919      0.743970  \n",
       "1258      0.742738      0.743378      0.743919      0.743970  \n",
       "1259      0.742738      0.743378      0.743919      0.743970  \n",
       "\n",
       "[1260 rows x 331 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dae_label = dae_label.drop(columns = [\"materials\", \"names\", \"color\", \"distance\", \"mode\"])\n",
    "dae_label = dae_label.drop(columns = [\"materials\", \"names\"])\n",
    "\n",
    "dae_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff65926d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spectrum_0</th>\n",
       "      <th>spectrum_1</th>\n",
       "      <th>spectrum_2</th>\n",
       "      <th>spectrum_3</th>\n",
       "      <th>spectrum_4</th>\n",
       "      <th>spectrum_5</th>\n",
       "      <th>spectrum_6</th>\n",
       "      <th>spectrum_7</th>\n",
       "      <th>spectrum_8</th>\n",
       "      <th>spectrum_9</th>\n",
       "      <th>...</th>\n",
       "      <th>spectrum_321</th>\n",
       "      <th>spectrum_322</th>\n",
       "      <th>spectrum_323</th>\n",
       "      <th>spectrum_324</th>\n",
       "      <th>spectrum_325</th>\n",
       "      <th>spectrum_326</th>\n",
       "      <th>spectrum_327</th>\n",
       "      <th>spectrum_328</th>\n",
       "      <th>spectrum_329</th>\n",
       "      <th>spectrum_330</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.526403</td>\n",
       "      <td>0.527891</td>\n",
       "      <td>0.529310</td>\n",
       "      <td>0.530688</td>\n",
       "      <td>0.532068</td>\n",
       "      <td>0.533471</td>\n",
       "      <td>0.534901</td>\n",
       "      <td>0.536361</td>\n",
       "      <td>0.537855</td>\n",
       "      <td>0.539371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670099</td>\n",
       "      <td>0.670870</td>\n",
       "      <td>0.671219</td>\n",
       "      <td>0.671284</td>\n",
       "      <td>0.671310</td>\n",
       "      <td>0.671274</td>\n",
       "      <td>0.671686</td>\n",
       "      <td>0.672272</td>\n",
       "      <td>0.672768</td>\n",
       "      <td>0.672819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.542235</td>\n",
       "      <td>0.543597</td>\n",
       "      <td>0.544961</td>\n",
       "      <td>0.546345</td>\n",
       "      <td>0.547773</td>\n",
       "      <td>0.549250</td>\n",
       "      <td>0.550766</td>\n",
       "      <td>0.552315</td>\n",
       "      <td>0.553888</td>\n",
       "      <td>0.555468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.685934</td>\n",
       "      <td>0.686723</td>\n",
       "      <td>0.687080</td>\n",
       "      <td>0.687148</td>\n",
       "      <td>0.687176</td>\n",
       "      <td>0.687140</td>\n",
       "      <td>0.687564</td>\n",
       "      <td>0.688165</td>\n",
       "      <td>0.688675</td>\n",
       "      <td>0.688728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.536953</td>\n",
       "      <td>0.538290</td>\n",
       "      <td>0.539612</td>\n",
       "      <td>0.540949</td>\n",
       "      <td>0.542335</td>\n",
       "      <td>0.543779</td>\n",
       "      <td>0.545277</td>\n",
       "      <td>0.546822</td>\n",
       "      <td>0.548405</td>\n",
       "      <td>0.550009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.679368</td>\n",
       "      <td>0.680120</td>\n",
       "      <td>0.680447</td>\n",
       "      <td>0.680490</td>\n",
       "      <td>0.680496</td>\n",
       "      <td>0.680442</td>\n",
       "      <td>0.680844</td>\n",
       "      <td>0.681425</td>\n",
       "      <td>0.681916</td>\n",
       "      <td>0.681958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.543379</td>\n",
       "      <td>0.544370</td>\n",
       "      <td>0.545400</td>\n",
       "      <td>0.546501</td>\n",
       "      <td>0.547699</td>\n",
       "      <td>0.549000</td>\n",
       "      <td>0.550391</td>\n",
       "      <td>0.551859</td>\n",
       "      <td>0.553386</td>\n",
       "      <td>0.554947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686358</td>\n",
       "      <td>0.687150</td>\n",
       "      <td>0.687509</td>\n",
       "      <td>0.687577</td>\n",
       "      <td>0.687605</td>\n",
       "      <td>0.687568</td>\n",
       "      <td>0.687990</td>\n",
       "      <td>0.688591</td>\n",
       "      <td>0.689099</td>\n",
       "      <td>0.689151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.523413</td>\n",
       "      <td>0.524326</td>\n",
       "      <td>0.525328</td>\n",
       "      <td>0.526431</td>\n",
       "      <td>0.527640</td>\n",
       "      <td>0.528946</td>\n",
       "      <td>0.530326</td>\n",
       "      <td>0.531762</td>\n",
       "      <td>0.533235</td>\n",
       "      <td>0.534721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661900</td>\n",
       "      <td>0.662690</td>\n",
       "      <td>0.663060</td>\n",
       "      <td>0.663147</td>\n",
       "      <td>0.663193</td>\n",
       "      <td>0.663175</td>\n",
       "      <td>0.663598</td>\n",
       "      <td>0.664191</td>\n",
       "      <td>0.664694</td>\n",
       "      <td>0.664755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>0.501132</td>\n",
       "      <td>0.501212</td>\n",
       "      <td>0.501278</td>\n",
       "      <td>0.501364</td>\n",
       "      <td>0.501494</td>\n",
       "      <td>0.501661</td>\n",
       "      <td>0.501850</td>\n",
       "      <td>0.502045</td>\n",
       "      <td>0.502237</td>\n",
       "      <td>0.502413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543924</td>\n",
       "      <td>0.544602</td>\n",
       "      <td>0.544929</td>\n",
       "      <td>0.545019</td>\n",
       "      <td>0.545072</td>\n",
       "      <td>0.545068</td>\n",
       "      <td>0.545425</td>\n",
       "      <td>0.545920</td>\n",
       "      <td>0.546338</td>\n",
       "      <td>0.546392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>0.462299</td>\n",
       "      <td>0.462222</td>\n",
       "      <td>0.462148</td>\n",
       "      <td>0.462112</td>\n",
       "      <td>0.462131</td>\n",
       "      <td>0.462201</td>\n",
       "      <td>0.462306</td>\n",
       "      <td>0.462434</td>\n",
       "      <td>0.462574</td>\n",
       "      <td>0.462712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500846</td>\n",
       "      <td>0.501468</td>\n",
       "      <td>0.501766</td>\n",
       "      <td>0.501847</td>\n",
       "      <td>0.501893</td>\n",
       "      <td>0.501888</td>\n",
       "      <td>0.502214</td>\n",
       "      <td>0.502668</td>\n",
       "      <td>0.503051</td>\n",
       "      <td>0.503099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>0.197083</td>\n",
       "      <td>0.197172</td>\n",
       "      <td>0.197252</td>\n",
       "      <td>0.197331</td>\n",
       "      <td>0.197412</td>\n",
       "      <td>0.197492</td>\n",
       "      <td>0.197564</td>\n",
       "      <td>0.197624</td>\n",
       "      <td>0.197671</td>\n",
       "      <td>0.197703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216179</td>\n",
       "      <td>0.216449</td>\n",
       "      <td>0.216579</td>\n",
       "      <td>0.216614</td>\n",
       "      <td>0.216634</td>\n",
       "      <td>0.216632</td>\n",
       "      <td>0.216773</td>\n",
       "      <td>0.216968</td>\n",
       "      <td>0.217133</td>\n",
       "      <td>0.217154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>0.183714</td>\n",
       "      <td>0.183832</td>\n",
       "      <td>0.183919</td>\n",
       "      <td>0.183990</td>\n",
       "      <td>0.184056</td>\n",
       "      <td>0.184118</td>\n",
       "      <td>0.184174</td>\n",
       "      <td>0.184224</td>\n",
       "      <td>0.184265</td>\n",
       "      <td>0.184299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200452</td>\n",
       "      <td>0.200693</td>\n",
       "      <td>0.200805</td>\n",
       "      <td>0.200831</td>\n",
       "      <td>0.200843</td>\n",
       "      <td>0.200835</td>\n",
       "      <td>0.200960</td>\n",
       "      <td>0.201136</td>\n",
       "      <td>0.201285</td>\n",
       "      <td>0.201301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>0.177628</td>\n",
       "      <td>0.177632</td>\n",
       "      <td>0.177647</td>\n",
       "      <td>0.177677</td>\n",
       "      <td>0.177724</td>\n",
       "      <td>0.177783</td>\n",
       "      <td>0.177844</td>\n",
       "      <td>0.177903</td>\n",
       "      <td>0.177955</td>\n",
       "      <td>0.177997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193133</td>\n",
       "      <td>0.193387</td>\n",
       "      <td>0.193515</td>\n",
       "      <td>0.193558</td>\n",
       "      <td>0.193585</td>\n",
       "      <td>0.193592</td>\n",
       "      <td>0.193726</td>\n",
       "      <td>0.193907</td>\n",
       "      <td>0.194060</td>\n",
       "      <td>0.194083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1260 rows × 331 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      spectrum_0  spectrum_1  spectrum_2  spectrum_3  spectrum_4  spectrum_5  \\\n",
       "0       0.526403    0.527891    0.529310    0.530688    0.532068    0.533471   \n",
       "1       0.542235    0.543597    0.544961    0.546345    0.547773    0.549250   \n",
       "2       0.536953    0.538290    0.539612    0.540949    0.542335    0.543779   \n",
       "3       0.543379    0.544370    0.545400    0.546501    0.547699    0.549000   \n",
       "4       0.523413    0.524326    0.525328    0.526431    0.527640    0.528946   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1255    0.501132    0.501212    0.501278    0.501364    0.501494    0.501661   \n",
       "1256    0.462299    0.462222    0.462148    0.462112    0.462131    0.462201   \n",
       "1257    0.197083    0.197172    0.197252    0.197331    0.197412    0.197492   \n",
       "1258    0.183714    0.183832    0.183919    0.183990    0.184056    0.184118   \n",
       "1259    0.177628    0.177632    0.177647    0.177677    0.177724    0.177783   \n",
       "\n",
       "      spectrum_6  spectrum_7  spectrum_8  spectrum_9  ...  spectrum_321  \\\n",
       "0       0.534901    0.536361    0.537855    0.539371  ...      0.670099   \n",
       "1       0.550766    0.552315    0.553888    0.555468  ...      0.685934   \n",
       "2       0.545277    0.546822    0.548405    0.550009  ...      0.679368   \n",
       "3       0.550391    0.551859    0.553386    0.554947  ...      0.686358   \n",
       "4       0.530326    0.531762    0.533235    0.534721  ...      0.661900   \n",
       "...          ...         ...         ...         ...  ...           ...   \n",
       "1255    0.501850    0.502045    0.502237    0.502413  ...      0.543924   \n",
       "1256    0.462306    0.462434    0.462574    0.462712  ...      0.500846   \n",
       "1257    0.197564    0.197624    0.197671    0.197703  ...      0.216179   \n",
       "1258    0.184174    0.184224    0.184265    0.184299  ...      0.200452   \n",
       "1259    0.177844    0.177903    0.177955    0.177997  ...      0.193133   \n",
       "\n",
       "      spectrum_322  spectrum_323  spectrum_324  spectrum_325  spectrum_326  \\\n",
       "0         0.670870      0.671219      0.671284      0.671310      0.671274   \n",
       "1         0.686723      0.687080      0.687148      0.687176      0.687140   \n",
       "2         0.680120      0.680447      0.680490      0.680496      0.680442   \n",
       "3         0.687150      0.687509      0.687577      0.687605      0.687568   \n",
       "4         0.662690      0.663060      0.663147      0.663193      0.663175   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "1255      0.544602      0.544929      0.545019      0.545072      0.545068   \n",
       "1256      0.501468      0.501766      0.501847      0.501893      0.501888   \n",
       "1257      0.216449      0.216579      0.216614      0.216634      0.216632   \n",
       "1258      0.200693      0.200805      0.200831      0.200843      0.200835   \n",
       "1259      0.193387      0.193515      0.193558      0.193585      0.193592   \n",
       "\n",
       "      spectrum_327  spectrum_328  spectrum_329  spectrum_330  \n",
       "0         0.671686      0.672272      0.672768      0.672819  \n",
       "1         0.687564      0.688165      0.688675      0.688728  \n",
       "2         0.680844      0.681425      0.681916      0.681958  \n",
       "3         0.687990      0.688591      0.689099      0.689151  \n",
       "4         0.663598      0.664191      0.664694      0.664755  \n",
       "...            ...           ...           ...           ...  \n",
       "1255      0.545425      0.545920      0.546338      0.546392  \n",
       "1256      0.502214      0.502668      0.503051      0.503099  \n",
       "1257      0.216773      0.216968      0.217133      0.217154  \n",
       "1258      0.200960      0.201136      0.201285      0.201301  \n",
       "1259      0.193726      0.193907      0.194060      0.194083  \n",
       "\n",
       "[1260 rows x 331 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dae_train = dae_train.drop(columns = [\"materials\", \"names\" , \"color\", \"distance\", \"mode\"])\n",
    "#dae_train = dae_train.drop(columns = [\"materials\"])\n",
    "\n",
    "dae_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a7cdcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dae_tra, x_dae_val, y_dae_tra, y_dae_val = train_test_split(dae_train, dae_label, test_size=0.2, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a468370a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-02 14:55:30.695111: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-03-02 14:55:30.695153: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: rilab18\n",
      "2023-03-02 14:55:30.695163: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: rilab18\n",
      "2023-03-02 14:55:30.695271: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 470.57.2\n",
      "2023-03-02 14:55:30.695302: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 470.57.2\n",
      "2023-03-02 14:55:30.695311: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 470.57.2\n",
      "2023-03-02 14:55:30.695643: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# build DAE \n",
    "\n",
    "encoding_dim = 64\n",
    "input_data = keras.Input(shape=(331,))\n",
    "\n",
    "encoded = layers.Dense(256, activation='sigmoid',activity_regularizer=regularizers.l1(10e-5))(input_data)\n",
    "encoded = layers.Dense(128, activation='sigmoid',activity_regularizer=regularizers.l1(10e-5))(encoded)\n",
    "encoded = layers.Dense(encoding_dim, activation='sigmoid',activity_regularizer=regularizers.l1(10e-5))(encoded)\n",
    "\n",
    "decoded = layers.Dense(128, activation='sigmoid',activity_regularizer=regularizers.l1(10e-5))(encoded)\n",
    "decoded = layers.Dense(256, activation='sigmoid',activity_regularizer=regularizers.l1(10e-5))(decoded)\n",
    "decoded = layers.Dense(331, activation='sigmoid',activity_regularizer=regularizers.l1(10e-5))(decoded)\n",
    "\n",
    "autoencoder = keras.Model(input_data, decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c70faa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN DAE\n",
    "#adama = 0.0552"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9af29231",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = keras.Model(input_data, encoded)\n",
    "autoencoder.compile(optimizer='adam', loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a974327e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "126/126 [==============================] - 2s 6ms/step - loss: 0.0945 - val_loss: 0.0777\n",
      "Epoch 2/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0802 - val_loss: 0.0743\n",
      "Epoch 3/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0757 - val_loss: 0.0712\n",
      "Epoch 4/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0742 - val_loss: 0.0690\n",
      "Epoch 5/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0736 - val_loss: 0.0687\n",
      "Epoch 6/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0738 - val_loss: 0.0679\n",
      "Epoch 7/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0725 - val_loss: 0.0694\n",
      "Epoch 8/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0728 - val_loss: 0.0670\n",
      "Epoch 9/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0719 - val_loss: 0.0698\n",
      "Epoch 10/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0722 - val_loss: 0.0662\n",
      "Epoch 11/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0718 - val_loss: 0.0688\n",
      "Epoch 12/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0710 - val_loss: 0.0672\n",
      "Epoch 13/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0715 - val_loss: 0.0671\n",
      "Epoch 14/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0708 - val_loss: 0.0666\n",
      "Epoch 15/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0707 - val_loss: 0.0674\n",
      "Epoch 16/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0707 - val_loss: 0.0651\n",
      "Epoch 17/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0703 - val_loss: 0.0651\n",
      "Epoch 18/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0701 - val_loss: 0.0659\n",
      "Epoch 19/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0711 - val_loss: 0.0656\n",
      "Epoch 20/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0704 - val_loss: 0.0674\n",
      "Epoch 21/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0703 - val_loss: 0.0652\n",
      "Epoch 22/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0704 - val_loss: 0.0695\n",
      "Epoch 23/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0702 - val_loss: 0.0658\n",
      "Epoch 24/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0697 - val_loss: 0.0668\n",
      "Epoch 25/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0696 - val_loss: 0.0655\n",
      "Epoch 26/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0695 - val_loss: 0.0642\n",
      "Epoch 27/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0693 - val_loss: 0.0643\n",
      "Epoch 28/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0699 - val_loss: 0.0658\n",
      "Epoch 29/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0694 - val_loss: 0.0656\n",
      "Epoch 30/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0697 - val_loss: 0.0635\n",
      "Epoch 31/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0693 - val_loss: 0.0642\n",
      "Epoch 32/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0698 - val_loss: 0.0640\n",
      "Epoch 33/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0693 - val_loss: 0.0636\n",
      "Epoch 34/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0694 - val_loss: 0.0657\n",
      "Epoch 35/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0689 - val_loss: 0.0637\n",
      "Epoch 36/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0690 - val_loss: 0.0636\n",
      "Epoch 37/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0690 - val_loss: 0.0648\n",
      "Epoch 38/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0688 - val_loss: 0.0652\n",
      "Epoch 39/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0690 - val_loss: 0.0633\n",
      "Epoch 40/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0687 - val_loss: 0.0650\n",
      "Epoch 41/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0689 - val_loss: 0.0644\n",
      "Epoch 42/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0685 - val_loss: 0.0640\n",
      "Epoch 43/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0687 - val_loss: 0.0643\n",
      "Epoch 44/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0684 - val_loss: 0.0626\n",
      "Epoch 45/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0686 - val_loss: 0.0632\n",
      "Epoch 46/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0687 - val_loss: 0.0625\n",
      "Epoch 47/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0685 - val_loss: 0.0632\n",
      "Epoch 48/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0687 - val_loss: 0.0628\n",
      "Epoch 49/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0681 - val_loss: 0.0624\n",
      "Epoch 50/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0684 - val_loss: 0.0647\n",
      "Epoch 51/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0684 - val_loss: 0.0629\n",
      "Epoch 52/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0682 - val_loss: 0.0622\n",
      "Epoch 53/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0679 - val_loss: 0.0653\n",
      "Epoch 54/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0682 - val_loss: 0.0630\n",
      "Epoch 55/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0683 - val_loss: 0.0624\n",
      "Epoch 56/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0680 - val_loss: 0.0620\n",
      "Epoch 57/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0682 - val_loss: 0.0631\n",
      "Epoch 58/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0679 - val_loss: 0.0626\n",
      "Epoch 59/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0678 - val_loss: 0.0642\n",
      "Epoch 60/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0678 - val_loss: 0.0624\n",
      "Epoch 61/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0674 - val_loss: 0.0620\n",
      "Epoch 62/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0678 - val_loss: 0.0616\n",
      "Epoch 63/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0677 - val_loss: 0.0632\n",
      "Epoch 64/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0676 - val_loss: 0.0632\n",
      "Epoch 65/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0675 - val_loss: 0.0634\n",
      "Epoch 66/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0678 - val_loss: 0.0619\n",
      "Epoch 67/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0676 - val_loss: 0.0647\n",
      "Epoch 68/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0674 - val_loss: 0.0614\n",
      "Epoch 69/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0671 - val_loss: 0.0628\n",
      "Epoch 70/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0670 - val_loss: 0.0621\n",
      "Epoch 71/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0672 - val_loss: 0.0634\n",
      "Epoch 72/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0673 - val_loss: 0.0638\n",
      "Epoch 73/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0678 - val_loss: 0.0616\n",
      "Epoch 74/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0680 - val_loss: 0.0613\n",
      "Epoch 75/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0674 - val_loss: 0.0623\n",
      "Epoch 76/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0669 - val_loss: 0.0647\n",
      "Epoch 77/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0671 - val_loss: 0.0627\n",
      "Epoch 78/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0673 - val_loss: 0.0633\n",
      "Epoch 79/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0669 - val_loss: 0.0611\n",
      "Epoch 80/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0672 - val_loss: 0.0619\n",
      "Epoch 81/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0672 - val_loss: 0.0612\n",
      "Epoch 82/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0672 - val_loss: 0.0609\n",
      "Epoch 83/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0666 - val_loss: 0.0618\n",
      "Epoch 84/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0671 - val_loss: 0.0616\n",
      "Epoch 85/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0670 - val_loss: 0.0651\n",
      "Epoch 86/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0675 - val_loss: 0.0622\n",
      "Epoch 87/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0673 - val_loss: 0.0629\n",
      "Epoch 88/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0672 - val_loss: 0.0619\n",
      "Epoch 89/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0673 - val_loss: 0.0620\n",
      "Epoch 90/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0672 - val_loss: 0.0619\n",
      "Epoch 91/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0670 - val_loss: 0.0610\n",
      "Epoch 92/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0668 - val_loss: 0.0610\n",
      "Epoch 93/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0671 - val_loss: 0.0626\n",
      "Epoch 94/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0668 - val_loss: 0.0623\n",
      "Epoch 95/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0672 - val_loss: 0.0617\n",
      "Epoch 96/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0669 - val_loss: 0.0620\n",
      "Epoch 97/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0671 - val_loss: 0.0617\n",
      "Epoch 98/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0664 - val_loss: 0.0617\n",
      "Epoch 99/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0664 - val_loss: 0.0628\n",
      "Epoch 100/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0671 - val_loss: 0.0637\n",
      "Epoch 101/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0665 - val_loss: 0.0612\n",
      "Epoch 102/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0669 - val_loss: 0.0620\n",
      "Epoch 103/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0670 - val_loss: 0.0608\n",
      "Epoch 104/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0672 - val_loss: 0.0616\n",
      "Epoch 105/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0666 - val_loss: 0.0643\n",
      "Epoch 106/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0667 - val_loss: 0.0630\n",
      "Epoch 107/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0664 - val_loss: 0.0621\n",
      "Epoch 108/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0667 - val_loss: 0.0644\n",
      "Epoch 109/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0664 - val_loss: 0.0656\n",
      "Epoch 110/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0674 - val_loss: 0.0633\n",
      "Epoch 111/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0663 - val_loss: 0.0639\n",
      "Epoch 112/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0665 - val_loss: 0.0620\n",
      "Epoch 113/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0666 - val_loss: 0.0617\n",
      "Epoch 114/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0667 - val_loss: 0.0631\n",
      "Epoch 115/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0664 - val_loss: 0.0608\n",
      "Epoch 116/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0664 - val_loss: 0.0616\n",
      "Epoch 117/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0664 - val_loss: 0.0636\n",
      "Epoch 118/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0666 - val_loss: 0.0641\n",
      "Epoch 119/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0662 - val_loss: 0.0606\n",
      "Epoch 120/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0662 - val_loss: 0.0611\n",
      "Epoch 121/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0665 - val_loss: 0.0622\n",
      "Epoch 122/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0662 - val_loss: 0.0637\n",
      "Epoch 123/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0665 - val_loss: 0.0626\n",
      "Epoch 124/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0663 - val_loss: 0.0601\n",
      "Epoch 125/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0660 - val_loss: 0.0630\n",
      "Epoch 126/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0660 - val_loss: 0.0604\n",
      "Epoch 127/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0657 - val_loss: 0.0603\n",
      "Epoch 128/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0661 - val_loss: 0.0603\n",
      "Epoch 129/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0664 - val_loss: 0.0603\n",
      "Epoch 130/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0660 - val_loss: 0.0618\n",
      "Epoch 131/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0658 - val_loss: 0.0608\n",
      "Epoch 132/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0655 - val_loss: 0.0633\n",
      "Epoch 133/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0661 - val_loss: 0.0613\n",
      "Epoch 134/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0661 - val_loss: 0.0612\n",
      "Epoch 135/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0662 - val_loss: 0.0611\n",
      "Epoch 136/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0657 - val_loss: 0.0610\n",
      "Epoch 137/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0666 - val_loss: 0.0623\n",
      "Epoch 138/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0661 - val_loss: 0.0602\n",
      "Epoch 139/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0663 - val_loss: 0.0602\n",
      "Epoch 140/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0656 - val_loss: 0.0608\n",
      "Epoch 141/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0656 - val_loss: 0.0606\n",
      "Epoch 142/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0656 - val_loss: 0.0598\n",
      "Epoch 143/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0655 - val_loss: 0.0598\n",
      "Epoch 144/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0656 - val_loss: 0.0608\n",
      "Epoch 145/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0653 - val_loss: 0.0597\n",
      "Epoch 146/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0659 - val_loss: 0.0618\n",
      "Epoch 147/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0658 - val_loss: 0.0620\n",
      "Epoch 148/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0652 - val_loss: 0.0608\n",
      "Epoch 149/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0655 - val_loss: 0.0599\n",
      "Epoch 150/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0649 - val_loss: 0.0600\n",
      "Epoch 151/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0656 - val_loss: 0.0628\n",
      "Epoch 152/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0654 - val_loss: 0.0601\n",
      "Epoch 153/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0650 - val_loss: 0.0615\n",
      "Epoch 154/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0657 - val_loss: 0.0615\n",
      "Epoch 155/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0654 - val_loss: 0.0618\n",
      "Epoch 156/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0653 - val_loss: 0.0633\n",
      "Epoch 157/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0652 - val_loss: 0.0597\n",
      "Epoch 158/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0657 - val_loss: 0.0597\n",
      "Epoch 159/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0656 - val_loss: 0.0600\n",
      "Epoch 160/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0649 - val_loss: 0.0623\n",
      "Epoch 161/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0658 - val_loss: 0.0597\n",
      "Epoch 162/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0655 - val_loss: 0.0601\n",
      "Epoch 163/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0651 - val_loss: 0.0596\n",
      "Epoch 164/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0651 - val_loss: 0.0607\n",
      "Epoch 165/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0649 - val_loss: 0.0602\n",
      "Epoch 166/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0648 - val_loss: 0.0602\n",
      "Epoch 167/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0646 - val_loss: 0.0630\n",
      "Epoch 168/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0656 - val_loss: 0.0625\n",
      "Epoch 169/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0653 - val_loss: 0.0592\n",
      "Epoch 170/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0653 - val_loss: 0.0601\n",
      "Epoch 171/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0654 - val_loss: 0.0593\n",
      "Epoch 172/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0651 - val_loss: 0.0595\n",
      "Epoch 173/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0650 - val_loss: 0.0589\n",
      "Epoch 174/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0649 - val_loss: 0.0597\n",
      "Epoch 175/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0651 - val_loss: 0.0598\n",
      "Epoch 176/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0655 - val_loss: 0.0613\n",
      "Epoch 177/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0654 - val_loss: 0.0601\n",
      "Epoch 178/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0650 - val_loss: 0.0627\n",
      "Epoch 179/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0660 - val_loss: 0.0636\n",
      "Epoch 180/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0647 - val_loss: 0.0597\n",
      "Epoch 181/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0652 - val_loss: 0.0644\n",
      "Epoch 182/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0647 - val_loss: 0.0589\n",
      "Epoch 183/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0645 - val_loss: 0.0616\n",
      "Epoch 184/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0652 - val_loss: 0.0587\n",
      "Epoch 185/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0651 - val_loss: 0.0589\n",
      "Epoch 186/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0651 - val_loss: 0.0604\n",
      "Epoch 187/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0651 - val_loss: 0.0598\n",
      "Epoch 188/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0641 - val_loss: 0.0596\n",
      "Epoch 189/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0645 - val_loss: 0.0594\n",
      "Epoch 190/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0650 - val_loss: 0.0593\n",
      "Epoch 191/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0650 - val_loss: 0.0617\n",
      "Epoch 192/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0650 - val_loss: 0.0613\n",
      "Epoch 193/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0649 - val_loss: 0.0636\n",
      "Epoch 194/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0648 - val_loss: 0.0592\n",
      "Epoch 195/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0645 - val_loss: 0.0604\n",
      "Epoch 196/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0646 - val_loss: 0.0614\n",
      "Epoch 197/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0655 - val_loss: 0.0599\n",
      "Epoch 198/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0644 - val_loss: 0.0597\n",
      "Epoch 199/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0652 - val_loss: 0.0588\n",
      "Epoch 200/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0657 - val_loss: 0.0611\n",
      "Epoch 201/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0647 - val_loss: 0.0595\n",
      "Epoch 202/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0642 - val_loss: 0.0607\n",
      "Epoch 203/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0647 - val_loss: 0.0600\n",
      "Epoch 204/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0643 - val_loss: 0.0587\n",
      "Epoch 205/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0649 - val_loss: 0.0600\n",
      "Epoch 206/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0647 - val_loss: 0.0588\n",
      "Epoch 207/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0647 - val_loss: 0.0599\n",
      "Epoch 208/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0652 - val_loss: 0.0585\n",
      "Epoch 209/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0643 - val_loss: 0.0587\n",
      "Epoch 210/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0637 - val_loss: 0.0634\n",
      "Epoch 211/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0644 - val_loss: 0.0590\n",
      "Epoch 212/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0647 - val_loss: 0.0596\n",
      "Epoch 213/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0647 - val_loss: 0.0608\n",
      "Epoch 214/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0644 - val_loss: 0.0581\n",
      "Epoch 215/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0646 - val_loss: 0.0591\n",
      "Epoch 216/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0645 - val_loss: 0.0611\n",
      "Epoch 217/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0637 - val_loss: 0.0615\n",
      "Epoch 218/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0641 - val_loss: 0.0593\n",
      "Epoch 219/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0640 - val_loss: 0.0609\n",
      "Epoch 220/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0637 - val_loss: 0.0595\n",
      "Epoch 221/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0639 - val_loss: 0.0628\n",
      "Epoch 222/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0650 - val_loss: 0.0582\n",
      "Epoch 223/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0642 - val_loss: 0.0611\n",
      "Epoch 224/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0648 - val_loss: 0.0614\n",
      "Epoch 225/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0644 - val_loss: 0.0582\n",
      "Epoch 226/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0643 - val_loss: 0.0620\n",
      "Epoch 227/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0649 - val_loss: 0.0587\n",
      "Epoch 228/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0641 - val_loss: 0.0598\n",
      "Epoch 229/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0649 - val_loss: 0.0637\n",
      "Epoch 230/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0644 - val_loss: 0.0631\n",
      "Epoch 231/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0648 - val_loss: 0.0598\n",
      "Epoch 232/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0638 - val_loss: 0.0582\n",
      "Epoch 233/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0649 - val_loss: 0.0592\n",
      "Epoch 234/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0639 - val_loss: 0.0586\n",
      "Epoch 235/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0639 - val_loss: 0.0605\n",
      "Epoch 236/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0650 - val_loss: 0.0587\n",
      "Epoch 237/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0637 - val_loss: 0.0582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0642 - val_loss: 0.0585\n",
      "Epoch 239/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0636 - val_loss: 0.0591\n",
      "Epoch 240/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0635 - val_loss: 0.0586\n",
      "Epoch 241/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0644 - val_loss: 0.0583\n",
      "Epoch 242/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0631 - val_loss: 0.0577\n",
      "Epoch 243/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0651 - val_loss: 0.0622\n",
      "Epoch 244/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0645 - val_loss: 0.0580\n",
      "Epoch 245/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0640 - val_loss: 0.0589\n",
      "Epoch 246/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0636 - val_loss: 0.0594\n",
      "Epoch 247/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0631 - val_loss: 0.0575\n",
      "Epoch 248/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0633 - val_loss: 0.0595\n",
      "Epoch 249/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0640 - val_loss: 0.0684\n",
      "Epoch 250/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0638 - val_loss: 0.0593\n",
      "Epoch 251/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0642 - val_loss: 0.0575\n",
      "Epoch 252/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0632 - val_loss: 0.0574\n",
      "Epoch 253/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0625 - val_loss: 0.0582\n",
      "Epoch 254/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0630 - val_loss: 0.0578\n",
      "Epoch 255/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0642 - val_loss: 0.0578\n",
      "Epoch 256/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0628 - val_loss: 0.0654\n",
      "Epoch 257/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0639 - val_loss: 0.0573\n",
      "Epoch 258/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0623 - val_loss: 0.0600\n",
      "Epoch 259/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0642 - val_loss: 0.0584\n",
      "Epoch 260/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0635 - val_loss: 0.0594\n",
      "Epoch 261/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0631 - val_loss: 0.0590\n",
      "Epoch 262/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0639 - val_loss: 0.0596\n",
      "Epoch 263/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0640 - val_loss: 0.0601\n",
      "Epoch 264/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0631 - val_loss: 0.0571\n",
      "Epoch 265/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0637 - val_loss: 0.0585\n",
      "Epoch 266/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0634 - val_loss: 0.0631\n",
      "Epoch 267/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0648 - val_loss: 0.0581\n",
      "Epoch 268/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0633 - val_loss: 0.0622\n",
      "Epoch 269/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0643 - val_loss: 0.0585\n",
      "Epoch 270/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0630 - val_loss: 0.0577\n",
      "Epoch 271/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0626 - val_loss: 0.0586\n",
      "Epoch 272/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0631 - val_loss: 0.0648\n",
      "Epoch 273/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0636 - val_loss: 0.0577\n",
      "Epoch 274/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0632 - val_loss: 0.0571\n",
      "Epoch 275/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0629 - val_loss: 0.0607\n",
      "Epoch 276/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0635 - val_loss: 0.0621\n",
      "Epoch 277/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0636 - val_loss: 0.0623\n",
      "Epoch 278/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0633 - val_loss: 0.0586\n",
      "Epoch 279/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0620 - val_loss: 0.0577\n",
      "Epoch 280/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0639 - val_loss: 0.0597\n",
      "Epoch 281/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0628 - val_loss: 0.0580\n",
      "Epoch 282/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0628 - val_loss: 0.0585\n",
      "Epoch 283/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0648 - val_loss: 0.0580\n",
      "Epoch 284/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0618 - val_loss: 0.0604\n",
      "Epoch 285/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0658 - val_loss: 0.0575\n",
      "Epoch 286/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0621 - val_loss: 0.0572\n",
      "Epoch 287/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0618 - val_loss: 0.0603\n",
      "Epoch 288/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0618 - val_loss: 0.0611\n",
      "Epoch 289/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0629 - val_loss: 0.0579\n",
      "Epoch 290/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0631 - val_loss: 0.0565\n",
      "Epoch 291/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0626 - val_loss: 0.0573\n",
      "Epoch 292/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0622 - val_loss: 0.0562\n",
      "Epoch 293/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0632 - val_loss: 0.0581\n",
      "Epoch 294/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0623 - val_loss: 0.0572\n",
      "Epoch 295/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0630 - val_loss: 0.0584\n",
      "Epoch 296/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0622 - val_loss: 0.0571\n",
      "Epoch 297/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0624 - val_loss: 0.0612\n",
      "Epoch 298/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0641 - val_loss: 0.0585\n",
      "Epoch 299/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0620 - val_loss: 0.0581\n",
      "Epoch 300/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0622 - val_loss: 0.0575\n",
      "Epoch 301/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0620 - val_loss: 0.0572\n",
      "Epoch 302/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0616 - val_loss: 0.0619\n",
      "Epoch 303/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0642 - val_loss: 0.0568\n",
      "Epoch 304/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0621 - val_loss: 0.0566\n",
      "Epoch 305/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0612 - val_loss: 0.0625\n",
      "Epoch 306/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0646 - val_loss: 0.0683\n",
      "Epoch 307/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0657 - val_loss: 0.0608\n",
      "Epoch 308/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0639 - val_loss: 0.0592\n",
      "Epoch 309/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0625 - val_loss: 0.0589\n",
      "Epoch 310/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0625 - val_loss: 0.0600\n",
      "Epoch 311/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0648 - val_loss: 0.0599\n",
      "Epoch 312/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0621 - val_loss: 0.0580\n",
      "Epoch 313/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0612 - val_loss: 0.0587\n",
      "Epoch 314/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0618 - val_loss: 0.0626\n",
      "Epoch 315/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0620 - val_loss: 0.0564\n",
      "Epoch 316/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0618 - val_loss: 0.0576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 317/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0615 - val_loss: 0.0567\n",
      "Epoch 318/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0627 - val_loss: 0.0561\n",
      "Epoch 319/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0613 - val_loss: 0.0628\n",
      "Epoch 320/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0627 - val_loss: 0.0581\n",
      "Epoch 321/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0616 - val_loss: 0.0573\n",
      "Epoch 322/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0625 - val_loss: 0.0587\n",
      "Epoch 323/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0645 - val_loss: 0.0561\n",
      "Epoch 324/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0619 - val_loss: 0.0559\n",
      "Epoch 325/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0611 - val_loss: 0.0564\n",
      "Epoch 326/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0609 - val_loss: 0.0566\n",
      "Epoch 327/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0607 - val_loss: 0.0564\n",
      "Epoch 328/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0601 - val_loss: 0.0561\n",
      "Epoch 329/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0623 - val_loss: 0.0617\n",
      "Epoch 330/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0662 - val_loss: 0.0556\n",
      "Epoch 331/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0609 - val_loss: 0.0585\n",
      "Epoch 332/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0613 - val_loss: 0.0623\n",
      "Epoch 333/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0623 - val_loss: 0.0617\n",
      "Epoch 334/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0601 - val_loss: 0.0592\n",
      "Epoch 335/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0610 - val_loss: 0.0556\n",
      "Epoch 336/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0624 - val_loss: 0.0567\n",
      "Epoch 337/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0602 - val_loss: 0.0578\n",
      "Epoch 338/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0614 - val_loss: 0.0553\n",
      "Epoch 339/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0626 - val_loss: 0.0634\n",
      "Epoch 340/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0614 - val_loss: 0.0664\n",
      "Epoch 341/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0600 - val_loss: 0.0549\n",
      "Epoch 342/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0604 - val_loss: 0.0553\n",
      "Epoch 343/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0617 - val_loss: 0.0583\n",
      "Epoch 344/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0601 - val_loss: 0.0553\n",
      "Epoch 345/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0601 - val_loss: 0.0569\n",
      "Epoch 346/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0621 - val_loss: 0.0565\n",
      "Epoch 347/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0610 - val_loss: 0.0575\n",
      "Epoch 348/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0608 - val_loss: 0.0551\n",
      "Epoch 349/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0592 - val_loss: 0.0596\n",
      "Epoch 350/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0599 - val_loss: 0.0553\n",
      "Epoch 351/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0622 - val_loss: 0.0609\n",
      "Epoch 352/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0600 - val_loss: 0.0573\n",
      "Epoch 353/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0600 - val_loss: 0.0552\n",
      "Epoch 354/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0600 - val_loss: 0.0553\n",
      "Epoch 355/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0602 - val_loss: 0.0599\n",
      "Epoch 356/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0593 - val_loss: 0.0552\n",
      "Epoch 357/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0599 - val_loss: 0.0553\n",
      "Epoch 358/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0624 - val_loss: 0.0624\n",
      "Epoch 359/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0660 - val_loss: 0.0591\n",
      "Epoch 360/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0649 - val_loss: 0.0603\n",
      "Epoch 361/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0647 - val_loss: 0.0549\n",
      "Epoch 362/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0602 - val_loss: 0.0610\n",
      "Epoch 363/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0598 - val_loss: 0.0559\n",
      "Epoch 364/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0606 - val_loss: 0.0582\n",
      "Epoch 365/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0619 - val_loss: 0.0555\n",
      "Epoch 366/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0601 - val_loss: 0.0549\n",
      "Epoch 367/2000\n",
      "126/126 [==============================] - 0s 4ms/step - loss: 0.0607 - val_loss: 0.0563\n",
      "Epoch 368/2000\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0595 - val_loss: 0.0556\n",
      "Epoch 369/2000\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0601 - val_loss: 0.0547\n",
      "Epoch 370/2000\n",
      "126/126 [==============================] - 0s 3ms/step - loss: 0.0619 - val_loss: 0.0545\n",
      "Epoch 371/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0589 - val_loss: 0.0567\n",
      "Epoch 372/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0619 - val_loss: 0.0547\n",
      "Epoch 373/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0596 - val_loss: 0.0557\n",
      "Epoch 374/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0610 - val_loss: 0.0547\n",
      "Epoch 375/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0628 - val_loss: 0.0568\n",
      "Epoch 376/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0604 - val_loss: 0.0653\n",
      "Epoch 377/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0628 - val_loss: 0.0606\n",
      "Epoch 378/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0594 - val_loss: 0.0668\n",
      "Epoch 379/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0634 - val_loss: 0.0574\n",
      "Epoch 380/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0604 - val_loss: 0.0553\n",
      "Epoch 381/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0597 - val_loss: 0.0569\n",
      "Epoch 382/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0607 - val_loss: 0.0584\n",
      "Epoch 383/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0603 - val_loss: 0.0586\n",
      "Epoch 384/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0638 - val_loss: 0.0580\n",
      "Epoch 385/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0599 - val_loss: 0.0561\n",
      "Epoch 386/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0587 - val_loss: 0.0543\n",
      "Epoch 387/2000\n",
      "126/126 [==============================] - 0s 4ms/step - loss: 0.0601 - val_loss: 0.0568\n",
      "Epoch 388/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0592 - val_loss: 0.0551\n",
      "Epoch 389/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0637 - val_loss: 0.0545\n",
      "Epoch 390/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0582 - val_loss: 0.0587\n",
      "Epoch 391/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0610 - val_loss: 0.0570\n",
      "Epoch 392/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0604 - val_loss: 0.0547\n",
      "Epoch 393/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0598 - val_loss: 0.0566\n",
      "Epoch 394/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0592 - val_loss: 0.0547\n",
      "Epoch 395/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0614 - val_loss: 0.0707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0654 - val_loss: 0.0671\n",
      "Epoch 397/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0657 - val_loss: 0.0571\n",
      "Epoch 398/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0597 - val_loss: 0.0548\n",
      "Epoch 399/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0599 - val_loss: 0.0543\n",
      "Epoch 400/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0602 - val_loss: 0.0542\n",
      "Epoch 401/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0600 - val_loss: 0.0593\n",
      "Epoch 402/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0638 - val_loss: 0.0558\n",
      "Epoch 403/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0603 - val_loss: 0.0576\n",
      "Epoch 404/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0597 - val_loss: 0.0585\n",
      "Epoch 405/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0590 - val_loss: 0.0539\n",
      "Epoch 406/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0597 - val_loss: 0.0589\n",
      "Epoch 407/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0605 - val_loss: 0.0562\n",
      "Epoch 408/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0594 - val_loss: 0.0583\n",
      "Epoch 409/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0595 - val_loss: 0.0551\n",
      "Epoch 410/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0596 - val_loss: 0.0557\n",
      "Epoch 411/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0594 - val_loss: 0.0587\n",
      "Epoch 412/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0627 - val_loss: 0.0581\n",
      "Epoch 413/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0597 - val_loss: 0.0540\n",
      "Epoch 414/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0618 - val_loss: 0.0573\n",
      "Epoch 415/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0620 - val_loss: 0.0547\n",
      "Epoch 416/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0597 - val_loss: 0.0571\n",
      "Epoch 417/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0593 - val_loss: 0.0560\n",
      "Epoch 418/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0595 - val_loss: 0.0579\n",
      "Epoch 419/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0593 - val_loss: 0.0544\n",
      "Epoch 420/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0582 - val_loss: 0.0556\n",
      "Epoch 421/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0593 - val_loss: 0.0544\n",
      "Epoch 422/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0598 - val_loss: 0.0545\n",
      "Epoch 423/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0585 - val_loss: 0.0563\n",
      "Epoch 424/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0583 - val_loss: 0.0555\n",
      "Epoch 425/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0594 - val_loss: 0.0588\n",
      "Epoch 426/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0600 - val_loss: 0.0548\n",
      "Epoch 427/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0587 - val_loss: 0.0550\n",
      "Epoch 428/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0577 - val_loss: 0.0541\n",
      "Epoch 429/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0583 - val_loss: 0.0544\n",
      "Epoch 430/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0602 - val_loss: 0.0565\n",
      "Epoch 431/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0583 - val_loss: 0.0556\n",
      "Epoch 432/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0588 - val_loss: 0.0611\n",
      "Epoch 433/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0638 - val_loss: 0.0642\n",
      "Epoch 434/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0655 - val_loss: 0.0593\n",
      "Epoch 435/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0648 - val_loss: 0.0616\n",
      "Epoch 436/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0650 - val_loss: 0.0617\n",
      "Epoch 437/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0646 - val_loss: 0.0584\n",
      "Epoch 438/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0644 - val_loss: 0.0627\n",
      "Epoch 439/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0644 - val_loss: 0.0617\n",
      "Epoch 440/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0638 - val_loss: 0.0588\n",
      "Epoch 441/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0644 - val_loss: 0.0606\n",
      "Epoch 442/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0641 - val_loss: 0.0593\n",
      "Epoch 443/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0641 - val_loss: 0.0589\n",
      "Epoch 444/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0636 - val_loss: 0.0551\n",
      "Epoch 445/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0612 - val_loss: 0.0547\n",
      "Epoch 446/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0593 - val_loss: 0.0549\n",
      "Epoch 447/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0601 - val_loss: 0.0548\n",
      "Epoch 448/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0602 - val_loss: 0.0541\n",
      "Epoch 449/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0619 - val_loss: 0.0541\n",
      "Epoch 450/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0612 - val_loss: 0.0631\n",
      "Epoch 451/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0647 - val_loss: 0.0595\n",
      "Epoch 452/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0648 - val_loss: 0.0608\n",
      "Epoch 453/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0644 - val_loss: 0.0622\n",
      "Epoch 454/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0627 - val_loss: 0.0559\n",
      "Epoch 455/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0622 - val_loss: 0.0587\n",
      "Epoch 456/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0610 - val_loss: 0.0548\n",
      "Epoch 457/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0591 - val_loss: 0.0599\n",
      "Epoch 458/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0616 - val_loss: 0.0562\n",
      "Epoch 459/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0595 - val_loss: 0.0551\n",
      "Epoch 460/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0606 - val_loss: 0.0548\n",
      "Epoch 461/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0595 - val_loss: 0.0618\n",
      "Epoch 462/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0618 - val_loss: 0.0568\n",
      "Epoch 463/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0601 - val_loss: 0.0556\n",
      "Epoch 464/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0619 - val_loss: 0.0553\n",
      "Epoch 465/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0593 - val_loss: 0.0546\n",
      "Epoch 466/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0587 - val_loss: 0.0545\n",
      "Epoch 467/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0605 - val_loss: 0.0610\n",
      "Epoch 468/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0611 - val_loss: 0.0540\n",
      "Epoch 469/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0628 - val_loss: 0.0555\n",
      "Epoch 470/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0632 - val_loss: 0.0625\n",
      "Epoch 471/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0605 - val_loss: 0.0549\n",
      "Epoch 472/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0599 - val_loss: 0.0544\n",
      "Epoch 473/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0590 - val_loss: 0.0545\n",
      "Epoch 474/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0596 - val_loss: 0.0580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0604 - val_loss: 0.0542\n",
      "Epoch 476/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0586 - val_loss: 0.0556\n",
      "Epoch 477/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0605 - val_loss: 0.0653\n",
      "Epoch 478/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0607 - val_loss: 0.0572\n",
      "Epoch 479/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0595 - val_loss: 0.0545\n",
      "Epoch 480/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0585 - val_loss: 0.0546\n",
      "Epoch 481/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0597 - val_loss: 0.0546\n",
      "Epoch 482/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0592 - val_loss: 0.0544\n",
      "Epoch 483/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0597 - val_loss: 0.0579\n",
      "Epoch 484/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0586 - val_loss: 0.0537\n",
      "Epoch 485/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0596 - val_loss: 0.0567\n",
      "Epoch 486/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0587 - val_loss: 0.0570\n",
      "Epoch 487/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0593 - val_loss: 0.0553\n",
      "Epoch 488/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0598 - val_loss: 0.0561\n",
      "Epoch 489/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0576 - val_loss: 0.0554\n",
      "Epoch 490/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0588 - val_loss: 0.0542\n",
      "Epoch 491/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0586 - val_loss: 0.0570\n",
      "Epoch 492/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0601 - val_loss: 0.0552\n",
      "Epoch 493/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0579 - val_loss: 0.0555\n",
      "Epoch 494/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0598 - val_loss: 0.0573\n",
      "Epoch 495/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0580 - val_loss: 0.0553\n",
      "Epoch 496/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0607 - val_loss: 0.0547\n",
      "Epoch 497/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0577 - val_loss: 0.0538\n",
      "Epoch 498/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0581 - val_loss: 0.0575\n",
      "Epoch 499/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0579 - val_loss: 0.0565\n",
      "Epoch 500/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0582 - val_loss: 0.0537\n",
      "Epoch 501/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0579 - val_loss: 0.0544\n",
      "Epoch 502/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0603 - val_loss: 0.0576\n",
      "Epoch 503/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0593 - val_loss: 0.0548\n",
      "Epoch 504/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0575 - val_loss: 0.0657\n",
      "Epoch 505/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0589 - val_loss: 0.0544\n",
      "Epoch 506/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0586 - val_loss: 0.0542\n",
      "Epoch 507/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0584 - val_loss: 0.0546\n",
      "Epoch 508/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0584 - val_loss: 0.0544\n",
      "Epoch 509/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0583 - val_loss: 0.0542\n",
      "Epoch 510/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0580 - val_loss: 0.0722\n",
      "Epoch 511/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0592 - val_loss: 0.0538\n",
      "Epoch 512/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0580 - val_loss: 0.0537\n",
      "Epoch 513/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0584 - val_loss: 0.0558\n",
      "Epoch 514/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0584 - val_loss: 0.0543\n",
      "Epoch 515/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0577 - val_loss: 0.0563\n",
      "Epoch 516/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0578 - val_loss: 0.0548\n",
      "Epoch 517/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0573 - val_loss: 0.0540\n",
      "Epoch 518/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0585 - val_loss: 0.0543\n",
      "Epoch 519/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0585 - val_loss: 0.0540\n",
      "Epoch 520/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0581 - val_loss: 0.0553\n",
      "Epoch 521/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0589 - val_loss: 0.0559\n",
      "Epoch 522/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0574 - val_loss: 0.0583\n",
      "Epoch 523/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0589 - val_loss: 0.0539\n",
      "Epoch 524/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0579 - val_loss: 0.0553\n",
      "Epoch 525/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0577 - val_loss: 0.0588\n",
      "Epoch 526/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0602 - val_loss: 0.0576\n",
      "Epoch 527/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0577 - val_loss: 0.0553\n",
      "Epoch 528/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0601 - val_loss: 0.0540\n",
      "Epoch 529/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0577 - val_loss: 0.0561\n",
      "Epoch 530/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0595 - val_loss: 0.0547\n",
      "Epoch 531/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0583 - val_loss: 0.0532\n",
      "Epoch 532/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0577 - val_loss: 0.0547\n",
      "Epoch 533/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0579 - val_loss: 0.0538\n",
      "Epoch 534/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0602 - val_loss: 0.0574\n",
      "Epoch 535/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0583 - val_loss: 0.0544\n",
      "Epoch 536/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0586 - val_loss: 0.0539\n",
      "Epoch 537/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0609 - val_loss: 0.0545\n",
      "Epoch 538/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0585 - val_loss: 0.0557\n",
      "Epoch 539/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0582 - val_loss: 0.0567\n",
      "Epoch 540/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0585 - val_loss: 0.0540\n",
      "Epoch 541/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0588 - val_loss: 0.0543\n",
      "Epoch 542/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0578 - val_loss: 0.0531\n",
      "Epoch 543/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0581 - val_loss: 0.0563\n",
      "Epoch 544/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0593 - val_loss: 0.0550\n",
      "Epoch 545/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0606 - val_loss: 0.0604\n",
      "Epoch 546/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0587 - val_loss: 0.0542\n",
      "Epoch 547/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0611 - val_loss: 0.0584\n",
      "Epoch 548/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0581 - val_loss: 0.0558\n",
      "Epoch 549/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0576 - val_loss: 0.0541\n",
      "Epoch 550/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0570 - val_loss: 0.0544\n",
      "Epoch 551/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0580 - val_loss: 0.0542\n",
      "Epoch 552/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0594 - val_loss: 0.0541\n",
      "Epoch 553/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0579 - val_loss: 0.0544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 554/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0591 - val_loss: 0.0547\n",
      "Epoch 555/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0599 - val_loss: 0.0610\n",
      "Epoch 556/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0600 - val_loss: 0.0540\n",
      "Epoch 557/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0581 - val_loss: 0.0539\n",
      "Epoch 558/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0581 - val_loss: 0.0548\n",
      "Epoch 559/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0594 - val_loss: 0.0548\n",
      "Epoch 560/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0601 - val_loss: 0.0558\n",
      "Epoch 561/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0581 - val_loss: 0.0587\n",
      "Epoch 562/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0575 - val_loss: 0.0548\n",
      "Epoch 563/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0584 - val_loss: 0.0549\n",
      "Epoch 564/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0619 - val_loss: 0.0542\n",
      "Epoch 565/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0578 - val_loss: 0.0570\n",
      "Epoch 566/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0585 - val_loss: 0.0532\n",
      "Epoch 567/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0582 - val_loss: 0.0542\n",
      "Epoch 568/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0588 - val_loss: 0.0539\n",
      "Epoch 569/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0574 - val_loss: 0.0564\n",
      "Epoch 570/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0577 - val_loss: 0.0537\n",
      "Epoch 571/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0569 - val_loss: 0.0576\n",
      "Epoch 572/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0588 - val_loss: 0.0540\n",
      "Epoch 573/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0586 - val_loss: 0.0539\n",
      "Epoch 574/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0585 - val_loss: 0.0534\n",
      "Epoch 575/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0573 - val_loss: 0.0559\n",
      "Epoch 576/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0571 - val_loss: 0.0550\n",
      "Epoch 577/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0579 - val_loss: 0.0658\n",
      "Epoch 578/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0582 - val_loss: 0.0550\n",
      "Epoch 579/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0579 - val_loss: 0.0565\n",
      "Epoch 580/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0574 - val_loss: 0.0565\n",
      "Epoch 581/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0568 - val_loss: 0.0539\n",
      "Epoch 582/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0591 - val_loss: 0.0543\n",
      "Epoch 583/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0571 - val_loss: 0.0560\n",
      "Epoch 584/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0584 - val_loss: 0.0541\n",
      "Epoch 585/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0584 - val_loss: 0.0556\n",
      "Epoch 586/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0580 - val_loss: 0.0532\n",
      "Epoch 587/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0566 - val_loss: 0.0541\n",
      "Epoch 588/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0566 - val_loss: 0.0538\n",
      "Epoch 589/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0579 - val_loss: 0.0554\n",
      "Epoch 590/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0581 - val_loss: 0.0553\n",
      "Epoch 591/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0594 - val_loss: 0.0537\n",
      "Epoch 592/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0577 - val_loss: 0.0539\n",
      "Epoch 593/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0583 - val_loss: 0.0539\n",
      "Epoch 594/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0578 - val_loss: 0.0542\n",
      "Epoch 595/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0579 - val_loss: 0.0532\n",
      "Epoch 596/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0579 - val_loss: 0.0559\n",
      "Epoch 597/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0577 - val_loss: 0.0555\n",
      "Epoch 598/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0573 - val_loss: 0.0538\n",
      "Epoch 599/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0576 - val_loss: 0.0560\n",
      "Epoch 600/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0578 - val_loss: 0.0600\n",
      "Epoch 601/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0580 - val_loss: 0.0547\n",
      "Epoch 602/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0576 - val_loss: 0.0556\n",
      "Epoch 603/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0576 - val_loss: 0.0638\n",
      "Epoch 604/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0578 - val_loss: 0.0537\n",
      "Epoch 605/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0591 - val_loss: 0.0578\n",
      "Epoch 606/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0588 - val_loss: 0.0560\n",
      "Epoch 607/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0574 - val_loss: 0.0563\n",
      "Epoch 608/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0587 - val_loss: 0.0553\n",
      "Epoch 609/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0585 - val_loss: 0.0593\n",
      "Epoch 610/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0572 - val_loss: 0.0570\n",
      "Epoch 611/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0581 - val_loss: 0.0548\n",
      "Epoch 612/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0565 - val_loss: 0.0537\n",
      "Epoch 613/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0625 - val_loss: 0.0637\n",
      "Epoch 614/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0655 - val_loss: 0.0607\n",
      "Epoch 615/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0651 - val_loss: 0.0635\n",
      "Epoch 616/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0646 - val_loss: 0.0620\n",
      "Epoch 617/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0641 - val_loss: 0.0615\n",
      "Epoch 618/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0640 - val_loss: 0.0617\n",
      "Epoch 619/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0636 - val_loss: 0.0621\n",
      "Epoch 620/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0640 - val_loss: 0.0597\n",
      "Epoch 621/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0631 - val_loss: 0.0571\n",
      "Epoch 622/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0601 - val_loss: 0.0556\n",
      "Epoch 623/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0616 - val_loss: 0.0557\n",
      "Epoch 624/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0590 - val_loss: 0.0597\n",
      "Epoch 625/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0575 - val_loss: 0.0572\n",
      "Epoch 626/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0581 - val_loss: 0.0563\n",
      "Epoch 627/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0571 - val_loss: 0.0534\n",
      "Epoch 628/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0587 - val_loss: 0.0539\n",
      "Epoch 629/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0576 - val_loss: 0.0544\n",
      "Epoch 630/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0570 - val_loss: 0.0547\n",
      "Epoch 631/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0577 - val_loss: 0.0538\n",
      "Epoch 632/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0566 - val_loss: 0.0539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 633/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0579 - val_loss: 0.0534\n",
      "Epoch 634/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0570 - val_loss: 0.0536\n",
      "Epoch 635/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0581 - val_loss: 0.0562\n",
      "Epoch 636/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0583 - val_loss: 0.0555\n",
      "Epoch 637/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0578 - val_loss: 0.0543\n",
      "Epoch 638/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0573 - val_loss: 0.0535\n",
      "Epoch 639/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0574 - val_loss: 0.0640\n",
      "Epoch 640/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0571 - val_loss: 0.0561\n",
      "Epoch 641/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0593 - val_loss: 0.0555\n",
      "Epoch 642/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0571 - val_loss: 0.0540\n",
      "Epoch 643/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0574 - val_loss: 0.0536\n",
      "Epoch 644/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0577 - val_loss: 0.0546\n",
      "Epoch 645/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0574 - val_loss: 0.0612\n",
      "Epoch 646/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0561 - val_loss: 0.0581\n",
      "Epoch 647/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0574 - val_loss: 0.0540\n",
      "Epoch 648/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0563 - val_loss: 0.0550\n",
      "Epoch 649/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0566 - val_loss: 0.0535\n",
      "Epoch 650/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0588 - val_loss: 0.0598\n",
      "Epoch 651/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0580 - val_loss: 0.0533\n",
      "Epoch 652/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0579 - val_loss: 0.0538\n",
      "Epoch 653/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0569 - val_loss: 0.0545\n",
      "Epoch 654/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0572 - val_loss: 0.0552\n",
      "Epoch 655/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0578 - val_loss: 0.0532\n",
      "Epoch 656/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0562 - val_loss: 0.0535\n",
      "Epoch 657/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0570 - val_loss: 0.0624\n",
      "Epoch 658/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0578 - val_loss: 0.0607\n",
      "Epoch 659/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0574 - val_loss: 0.0575\n",
      "Epoch 660/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0566 - val_loss: 0.0582\n",
      "Epoch 661/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0586 - val_loss: 0.0534\n",
      "Epoch 662/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0558 - val_loss: 0.0566\n",
      "Epoch 663/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0565 - val_loss: 0.0573\n",
      "Epoch 664/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0575 - val_loss: 0.0563\n",
      "Epoch 665/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0578 - val_loss: 0.0541\n",
      "Epoch 666/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0567 - val_loss: 0.0586\n",
      "Epoch 667/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0571 - val_loss: 0.0545\n",
      "Epoch 668/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0579 - val_loss: 0.0554\n",
      "Epoch 669/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0567 - val_loss: 0.0546\n",
      "Epoch 670/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0571 - val_loss: 0.0570\n",
      "Epoch 671/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0590 - val_loss: 0.0530\n",
      "Epoch 672/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0569 - val_loss: 0.0537\n",
      "Epoch 673/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0568 - val_loss: 0.0533\n",
      "Epoch 674/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0568 - val_loss: 0.0565\n",
      "Epoch 675/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0567 - val_loss: 0.0536\n",
      "Epoch 676/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0615 - val_loss: 0.0556\n",
      "Epoch 677/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0573 - val_loss: 0.0537\n",
      "Epoch 678/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0569 - val_loss: 0.0565\n",
      "Epoch 679/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0574 - val_loss: 0.0542\n",
      "Epoch 680/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0583 - val_loss: 0.0589\n",
      "Epoch 681/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0561 - val_loss: 0.0565\n",
      "Epoch 682/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0570 - val_loss: 0.0593\n",
      "Epoch 683/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0575 - val_loss: 0.0541\n",
      "Epoch 684/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0577 - val_loss: 0.0545\n",
      "Epoch 685/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0566 - val_loss: 0.0534\n",
      "Epoch 686/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0561 - val_loss: 0.0552\n",
      "Epoch 687/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0570 - val_loss: 0.0548\n",
      "Epoch 688/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0559 - val_loss: 0.0546\n",
      "Epoch 689/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0561 - val_loss: 0.0567\n",
      "Epoch 690/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0564 - val_loss: 0.0575\n",
      "Epoch 691/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0562 - val_loss: 0.0557\n",
      "Epoch 692/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0567 - val_loss: 0.0537\n",
      "Epoch 693/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0571 - val_loss: 0.0549\n",
      "Epoch 694/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0570 - val_loss: 0.0561\n",
      "Epoch 695/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0563 - val_loss: 0.0531\n",
      "Epoch 696/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0563 - val_loss: 0.0529\n",
      "Epoch 697/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0554 - val_loss: 0.0541\n",
      "Epoch 698/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0562 - val_loss: 0.0527\n",
      "Epoch 699/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0554 - val_loss: 0.0539\n",
      "Epoch 700/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0566 - val_loss: 0.0534\n",
      "Epoch 701/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0567 - val_loss: 0.0523\n",
      "Epoch 702/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0574 - val_loss: 0.0592\n",
      "Epoch 703/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0560 - val_loss: 0.0518\n",
      "Epoch 704/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0553 - val_loss: 0.0514\n",
      "Epoch 705/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0561 - val_loss: 0.0675\n",
      "Epoch 706/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0568 - val_loss: 0.0529\n",
      "Epoch 707/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0559 - val_loss: 0.0551\n",
      "Epoch 708/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0552 - val_loss: 0.0518\n",
      "Epoch 709/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0546 - val_loss: 0.0533\n",
      "Epoch 710/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0550 - val_loss: 0.0515\n",
      "Epoch 711/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0559 - val_loss: 0.0516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 712/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0557 - val_loss: 0.0528\n",
      "Epoch 713/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0553 - val_loss: 0.0513\n",
      "Epoch 714/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0539 - val_loss: 0.0515\n",
      "Epoch 715/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0542 - val_loss: 0.0527\n",
      "Epoch 716/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0548 - val_loss: 0.0519\n",
      "Epoch 717/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0544 - val_loss: 0.0565\n",
      "Epoch 718/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0553 - val_loss: 0.0524\n",
      "Epoch 719/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0590 - val_loss: 0.0601\n",
      "Epoch 720/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0572 - val_loss: 0.0524\n",
      "Epoch 721/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0553 - val_loss: 0.0558\n",
      "Epoch 722/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0542 - val_loss: 0.0602\n",
      "Epoch 723/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0545 - val_loss: 0.0533\n",
      "Epoch 724/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0529 - val_loss: 0.0519\n",
      "Epoch 725/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0567 - val_loss: 0.0526\n",
      "Epoch 726/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0539 - val_loss: 0.0499\n",
      "Epoch 727/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0537 - val_loss: 0.0511\n",
      "Epoch 728/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0544 - val_loss: 0.0502\n",
      "Epoch 729/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0545 - val_loss: 0.0498\n",
      "Epoch 730/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0534 - val_loss: 0.0554\n",
      "Epoch 731/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0537 - val_loss: 0.0501\n",
      "Epoch 732/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0538 - val_loss: 0.0506\n",
      "Epoch 733/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0539 - val_loss: 0.0504\n",
      "Epoch 734/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0546 - val_loss: 0.0508\n",
      "Epoch 735/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0538 - val_loss: 0.0483\n",
      "Epoch 736/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0536 - val_loss: 0.0495\n",
      "Epoch 737/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0537 - val_loss: 0.0496\n",
      "Epoch 738/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0541 - val_loss: 0.0500\n",
      "Epoch 739/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0536 - val_loss: 0.0526\n",
      "Epoch 740/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0557 - val_loss: 0.0480\n",
      "Epoch 741/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0547 - val_loss: 0.0487\n",
      "Epoch 742/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0587 - val_loss: 0.0502\n",
      "Epoch 743/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0542 - val_loss: 0.0546\n",
      "Epoch 744/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0538 - val_loss: 0.0505\n",
      "Epoch 745/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0529 - val_loss: 0.0498\n",
      "Epoch 746/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0532 - val_loss: 0.0543\n",
      "Epoch 747/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0539 - val_loss: 0.0483\n",
      "Epoch 748/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0541 - val_loss: 0.0508\n",
      "Epoch 749/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0537 - val_loss: 0.0543\n",
      "Epoch 750/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0542 - val_loss: 0.0484\n",
      "Epoch 751/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0528 - val_loss: 0.0500\n",
      "Epoch 752/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0581 - val_loss: 0.0482\n",
      "Epoch 753/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0549 - val_loss: 0.0510\n",
      "Epoch 754/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0538 - val_loss: 0.0507\n",
      "Epoch 755/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0532 - val_loss: 0.0527\n",
      "Epoch 756/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0539 - val_loss: 0.0493\n",
      "Epoch 757/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0542 - val_loss: 0.0571\n",
      "Epoch 758/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0545 - val_loss: 0.0619\n",
      "Epoch 759/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0549 - val_loss: 0.0525\n",
      "Epoch 760/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0539 - val_loss: 0.0483\n",
      "Epoch 761/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0528 - val_loss: 0.0478\n",
      "Epoch 762/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0540 - val_loss: 0.0500\n",
      "Epoch 763/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0536 - val_loss: 0.0480\n",
      "Epoch 764/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0576 - val_loss: 0.0496\n",
      "Epoch 765/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0544 - val_loss: 0.0504\n",
      "Epoch 766/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0540 - val_loss: 0.0487\n",
      "Epoch 767/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0538 - val_loss: 0.0506\n",
      "Epoch 768/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0531 - val_loss: 0.0492\n",
      "Epoch 769/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0531 - val_loss: 0.0524\n",
      "Epoch 770/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0527 - val_loss: 0.0488\n",
      "Epoch 771/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0527 - val_loss: 0.0557\n",
      "Epoch 772/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0546 - val_loss: 0.0503\n",
      "Epoch 773/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0534 - val_loss: 0.0516\n",
      "Epoch 774/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0523 - val_loss: 0.0529\n",
      "Epoch 775/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0538 - val_loss: 0.0487\n",
      "Epoch 776/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0544 - val_loss: 0.0543\n",
      "Epoch 777/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0536 - val_loss: 0.0500\n",
      "Epoch 778/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0529 - val_loss: 0.0491\n",
      "Epoch 779/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0524 - val_loss: 0.0502\n",
      "Epoch 780/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0538 - val_loss: 0.0486\n",
      "Epoch 781/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0530 - val_loss: 0.0478\n",
      "Epoch 782/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0528 - val_loss: 0.0476\n",
      "Epoch 783/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0531 - val_loss: 0.0494\n",
      "Epoch 784/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0535 - val_loss: 0.0507\n",
      "Epoch 785/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0536 - val_loss: 0.0538\n",
      "Epoch 786/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0532 - val_loss: 0.0472\n",
      "Epoch 787/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0523 - val_loss: 0.0511\n",
      "Epoch 788/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0532 - val_loss: 0.0485\n",
      "Epoch 789/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0528 - val_loss: 0.0487\n",
      "Epoch 790/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0530 - val_loss: 0.0481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 791/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0544 - val_loss: 0.0474\n",
      "Epoch 792/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0560 - val_loss: 0.0477\n",
      "Epoch 793/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0540 - val_loss: 0.0483\n",
      "Epoch 794/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0528 - val_loss: 0.0474\n",
      "Epoch 795/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0549 - val_loss: 0.0481\n",
      "Epoch 796/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0526 - val_loss: 0.0485\n",
      "Epoch 797/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0535 - val_loss: 0.0478\n",
      "Epoch 798/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0531 - val_loss: 0.0502\n",
      "Epoch 799/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0539 - val_loss: 0.0489\n",
      "Epoch 800/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0534 - val_loss: 0.0500\n",
      "Epoch 801/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0527 - val_loss: 0.0479\n",
      "Epoch 802/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0527 - val_loss: 0.0504\n",
      "Epoch 803/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0542 - val_loss: 0.0477\n",
      "Epoch 804/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0528 - val_loss: 0.0490\n",
      "Epoch 805/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0532 - val_loss: 0.0481\n",
      "Epoch 806/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0536 - val_loss: 0.0489\n",
      "Epoch 807/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0532 - val_loss: 0.0487\n",
      "Epoch 808/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0524 - val_loss: 0.0477\n",
      "Epoch 809/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0526 - val_loss: 0.0492\n",
      "Epoch 810/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0526 - val_loss: 0.0496\n",
      "Epoch 811/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0530 - val_loss: 0.0509\n",
      "Epoch 812/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0530 - val_loss: 0.0476\n",
      "Epoch 813/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0531 - val_loss: 0.0483\n",
      "Epoch 814/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0540 - val_loss: 0.0485\n",
      "Epoch 815/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0533 - val_loss: 0.0496\n",
      "Epoch 816/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0533 - val_loss: 0.0524\n",
      "Epoch 817/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0528 - val_loss: 0.0479\n",
      "Epoch 818/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0524 - val_loss: 0.0473\n",
      "Epoch 819/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0524 - val_loss: 0.0575\n",
      "Epoch 820/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0551 - val_loss: 0.0475\n",
      "Epoch 821/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0533 - val_loss: 0.0487\n",
      "Epoch 822/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0519 - val_loss: 0.0502\n",
      "Epoch 823/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0557 - val_loss: 0.0481\n",
      "Epoch 824/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0529 - val_loss: 0.0554\n",
      "Epoch 825/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0527 - val_loss: 0.0481\n",
      "Epoch 826/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0523 - val_loss: 0.0508\n",
      "Epoch 827/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0531 - val_loss: 0.0500\n",
      "Epoch 828/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0533 - val_loss: 0.0495\n",
      "Epoch 829/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0531 - val_loss: 0.0475\n",
      "Epoch 830/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0534 - val_loss: 0.0477\n",
      "Epoch 831/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0527 - val_loss: 0.0479\n",
      "Epoch 832/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0527 - val_loss: 0.0478\n",
      "Epoch 833/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0529 - val_loss: 0.0512\n",
      "Epoch 834/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0532 - val_loss: 0.0497\n",
      "Epoch 835/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0531 - val_loss: 0.0495\n",
      "Epoch 836/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0538 - val_loss: 0.0482\n",
      "Epoch 837/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0534 - val_loss: 0.0469\n",
      "Epoch 838/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0534 - val_loss: 0.0473\n",
      "Epoch 839/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0528 - val_loss: 0.0511\n",
      "Epoch 840/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0522 - val_loss: 0.0521\n",
      "Epoch 841/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0525 - val_loss: 0.0481\n",
      "Epoch 842/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0527 - val_loss: 0.0482\n",
      "Epoch 843/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0521 - val_loss: 0.0484\n",
      "Epoch 844/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0527 - val_loss: 0.0469\n",
      "Epoch 845/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0520 - val_loss: 0.0488\n",
      "Epoch 846/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0527 - val_loss: 0.0501\n",
      "Epoch 847/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0525 - val_loss: 0.0522\n",
      "Epoch 848/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0527 - val_loss: 0.0481\n",
      "Epoch 849/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0521 - val_loss: 0.0477\n",
      "Epoch 850/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0519 - val_loss: 0.0507\n",
      "Epoch 851/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0525 - val_loss: 0.0474\n",
      "Epoch 852/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0522 - val_loss: 0.0560\n",
      "Epoch 853/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0523 - val_loss: 0.0489\n",
      "Epoch 854/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0520 - val_loss: 0.0471\n",
      "Epoch 855/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0532 - val_loss: 0.0484\n",
      "Epoch 856/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0525 - val_loss: 0.0481\n",
      "Epoch 857/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0519 - val_loss: 0.0483\n",
      "Epoch 858/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0528 - val_loss: 0.0471\n",
      "Epoch 859/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0525 - val_loss: 0.0470\n",
      "Epoch 860/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0518 - val_loss: 0.0464\n",
      "Epoch 861/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0522 - val_loss: 0.0475\n",
      "Epoch 862/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0535 - val_loss: 0.0501\n",
      "Epoch 863/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0527 - val_loss: 0.0501\n",
      "Epoch 864/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0523 - val_loss: 0.0597\n",
      "Epoch 865/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0531 - val_loss: 0.0481\n",
      "Epoch 866/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0524 - val_loss: 0.0480\n",
      "Epoch 867/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0519 - val_loss: 0.0558\n",
      "Epoch 868/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0546 - val_loss: 0.0481\n",
      "Epoch 869/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0538 - val_loss: 0.0525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 870/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0529 - val_loss: 0.0475\n",
      "Epoch 871/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0532 - val_loss: 0.0478\n",
      "Epoch 872/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0523 - val_loss: 0.0477\n",
      "Epoch 873/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0527 - val_loss: 0.0470\n",
      "Epoch 874/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0520 - val_loss: 0.0475\n",
      "Epoch 875/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0521 - val_loss: 0.0485\n",
      "Epoch 876/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0525 - val_loss: 0.0470\n",
      "Epoch 877/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0527 - val_loss: 0.0477\n",
      "Epoch 878/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0521 - val_loss: 0.0467\n",
      "Epoch 879/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0526 - val_loss: 0.0480\n",
      "Epoch 880/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0524 - val_loss: 0.0477\n",
      "Epoch 881/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0516 - val_loss: 0.0474\n",
      "Epoch 882/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0528 - val_loss: 0.0485\n",
      "Epoch 883/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0528 - val_loss: 0.0503\n",
      "Epoch 884/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0531 - val_loss: 0.0496\n",
      "Epoch 885/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0524 - val_loss: 0.0525\n",
      "Epoch 886/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0538 - val_loss: 0.0477\n",
      "Epoch 887/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0526 - val_loss: 0.0613\n",
      "Epoch 888/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0538 - val_loss: 0.0482\n",
      "Epoch 889/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0522 - val_loss: 0.0481\n",
      "Epoch 890/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0531 - val_loss: 0.0481\n",
      "Epoch 891/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0521 - val_loss: 0.0497\n",
      "Epoch 892/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0526 - val_loss: 0.0519\n",
      "Epoch 893/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0521 - val_loss: 0.0482\n",
      "Epoch 894/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0520 - val_loss: 0.0527\n",
      "Epoch 895/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0538 - val_loss: 0.0477\n",
      "Epoch 896/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0518 - val_loss: 0.0498\n",
      "Epoch 897/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0518 - val_loss: 0.0531\n",
      "Epoch 898/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0537 - val_loss: 0.0495\n",
      "Epoch 899/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0526 - val_loss: 0.0486\n",
      "Epoch 900/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0514 - val_loss: 0.0495\n",
      "Epoch 901/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0540 - val_loss: 0.0502\n",
      "Epoch 902/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0522 - val_loss: 0.0509\n",
      "Epoch 903/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0517 - val_loss: 0.0484\n",
      "Epoch 904/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0522 - val_loss: 0.0572\n",
      "Epoch 905/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0555 - val_loss: 0.0488\n",
      "Epoch 906/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0514 - val_loss: 0.0480\n",
      "Epoch 907/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0522 - val_loss: 0.0481\n",
      "Epoch 908/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0519 - val_loss: 0.0502\n",
      "Epoch 909/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0520 - val_loss: 0.0519\n",
      "Epoch 910/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0523 - val_loss: 0.0467\n",
      "Epoch 911/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0539 - val_loss: 0.0487\n",
      "Epoch 912/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0520 - val_loss: 0.0493\n",
      "Epoch 913/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0515 - val_loss: 0.0494\n",
      "Epoch 914/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0521 - val_loss: 0.0509\n",
      "Epoch 915/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0522 - val_loss: 0.0468\n",
      "Epoch 916/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0526 - val_loss: 0.0465\n",
      "Epoch 917/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0521 - val_loss: 0.0472\n",
      "Epoch 918/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0535 - val_loss: 0.0518\n",
      "Epoch 919/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0524 - val_loss: 0.0498\n",
      "Epoch 920/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0521 - val_loss: 0.0510\n",
      "Epoch 921/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0516 - val_loss: 0.0481\n",
      "Epoch 922/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0532 - val_loss: 0.0528\n",
      "Epoch 923/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0530 - val_loss: 0.0483\n",
      "Epoch 924/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0516 - val_loss: 0.0470\n",
      "Epoch 925/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0524 - val_loss: 0.0491\n",
      "Epoch 926/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0523 - val_loss: 0.0480\n",
      "Epoch 927/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0517 - val_loss: 0.0494\n",
      "Epoch 928/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0515 - val_loss: 0.0485\n",
      "Epoch 929/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0519 - val_loss: 0.0497\n",
      "Epoch 930/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0526 - val_loss: 0.0582\n",
      "Epoch 931/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0530 - val_loss: 0.0488\n",
      "Epoch 932/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0523 - val_loss: 0.0495\n",
      "Epoch 933/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0514 - val_loss: 0.0496\n",
      "Epoch 934/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0522 - val_loss: 0.0473\n",
      "Epoch 935/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0532 - val_loss: 0.0507\n",
      "Epoch 936/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0528 - val_loss: 0.0534\n",
      "Epoch 937/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0517 - val_loss: 0.0484\n",
      "Epoch 938/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0527 - val_loss: 0.0586\n",
      "Epoch 939/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0527 - val_loss: 0.0477\n",
      "Epoch 940/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0522 - val_loss: 0.0545\n",
      "Epoch 941/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0522 - val_loss: 0.0476\n",
      "Epoch 942/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0522 - val_loss: 0.0500\n",
      "Epoch 943/2000\n",
      "126/126 [==============================] - 0s 4ms/step - loss: 0.0511 - val_loss: 0.0527\n",
      "Epoch 944/2000\n",
      "126/126 [==============================] - 0s 4ms/step - loss: 0.0517 - val_loss: 0.0497\n",
      "Epoch 945/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0529 - val_loss: 0.0520\n",
      "Epoch 946/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0515 - val_loss: 0.0490\n",
      "Epoch 947/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0514 - val_loss: 0.0481\n",
      "Epoch 948/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0513 - val_loss: 0.0477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 949/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0509 - val_loss: 0.0466\n",
      "Epoch 950/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0506 - val_loss: 0.0486\n",
      "Epoch 951/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0528 - val_loss: 0.0465\n",
      "Epoch 952/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0518 - val_loss: 0.0482\n",
      "Epoch 953/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0522 - val_loss: 0.0491\n",
      "Epoch 954/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0520 - val_loss: 0.0489\n",
      "Epoch 955/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0517 - val_loss: 0.0478\n",
      "Epoch 956/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0520 - val_loss: 0.0494\n",
      "Epoch 957/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0514 - val_loss: 0.0484\n",
      "Epoch 958/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0526 - val_loss: 0.0473\n",
      "Epoch 959/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0514 - val_loss: 0.0497\n",
      "Epoch 960/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0511 - val_loss: 0.0459\n",
      "Epoch 961/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0516 - val_loss: 0.0473\n",
      "Epoch 962/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0517 - val_loss: 0.0470\n",
      "Epoch 963/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0517 - val_loss: 0.0478\n",
      "Epoch 964/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0526 - val_loss: 0.0466\n",
      "Epoch 965/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0526 - val_loss: 0.0470\n",
      "Epoch 966/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0516 - val_loss: 0.0483\n",
      "Epoch 967/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0509 - val_loss: 0.0464\n",
      "Epoch 968/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0514 - val_loss: 0.0492\n",
      "Epoch 969/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0520 - val_loss: 0.0476\n",
      "Epoch 970/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0529 - val_loss: 0.0477\n",
      "Epoch 971/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0531 - val_loss: 0.0490\n",
      "Epoch 972/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0516 - val_loss: 0.0506\n",
      "Epoch 973/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0512 - val_loss: 0.0577\n",
      "Epoch 974/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0519 - val_loss: 0.0536\n",
      "Epoch 975/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0510 - val_loss: 0.0484\n",
      "Epoch 976/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0515 - val_loss: 0.0468\n",
      "Epoch 977/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0526 - val_loss: 0.0471\n",
      "Epoch 978/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0524 - val_loss: 0.0499\n",
      "Epoch 979/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0518 - val_loss: 0.0483\n",
      "Epoch 980/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0509 - val_loss: 0.0495\n",
      "Epoch 981/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0521 - val_loss: 0.0475\n",
      "Epoch 982/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0507 - val_loss: 0.0469\n",
      "Epoch 983/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0507 - val_loss: 0.0474\n",
      "Epoch 984/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0511 - val_loss: 0.0482\n",
      "Epoch 985/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0515 - val_loss: 0.0470\n",
      "Epoch 986/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0510 - val_loss: 0.0479\n",
      "Epoch 987/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0510 - val_loss: 0.0514\n",
      "Epoch 988/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0522 - val_loss: 0.0471\n",
      "Epoch 989/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0514 - val_loss: 0.0500\n",
      "Epoch 990/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0508 - val_loss: 0.0543\n",
      "Epoch 991/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0530 - val_loss: 0.0609\n",
      "Epoch 992/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0535 - val_loss: 0.0526\n",
      "Epoch 993/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0526 - val_loss: 0.0510\n",
      "Epoch 994/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0507 - val_loss: 0.0472\n",
      "Epoch 995/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0507 - val_loss: 0.0482\n",
      "Epoch 996/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0515 - val_loss: 0.0464\n",
      "Epoch 997/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0520 - val_loss: 0.0517\n",
      "Epoch 998/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0520 - val_loss: 0.0602\n",
      "Epoch 999/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0531 - val_loss: 0.0482\n",
      "Epoch 1000/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0515 - val_loss: 0.0471\n",
      "Epoch 1001/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0521 - val_loss: 0.0469\n",
      "Epoch 1002/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0514 - val_loss: 0.0484\n",
      "Epoch 1003/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0507 - val_loss: 0.0478\n",
      "Epoch 1004/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0507 - val_loss: 0.0477\n",
      "Epoch 1005/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0509 - val_loss: 0.0474\n",
      "Epoch 1006/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0517 - val_loss: 0.0503\n",
      "Epoch 1007/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0511 - val_loss: 0.0469\n",
      "Epoch 1008/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0513 - val_loss: 0.0479\n",
      "Epoch 1009/2000\n",
      "126/126 [==============================] - 0s 4ms/step - loss: 0.0513 - val_loss: 0.0470\n",
      "Epoch 1010/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0532 - val_loss: 0.0487\n",
      "Epoch 1011/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0520 - val_loss: 0.0506\n",
      "Epoch 1012/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0520 - val_loss: 0.0466\n",
      "Epoch 1013/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0507 - val_loss: 0.0508\n",
      "Epoch 1014/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0521 - val_loss: 0.0468\n",
      "Epoch 1015/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0515 - val_loss: 0.0478\n",
      "Epoch 1016/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0512 - val_loss: 0.0466\n",
      "Epoch 1017/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0519 - val_loss: 0.0465\n",
      "Epoch 1018/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0523 - val_loss: 0.0474\n",
      "Epoch 1019/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0510 - val_loss: 0.0464\n",
      "Epoch 1020/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0512 - val_loss: 0.0555\n",
      "Epoch 1021/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0507 - val_loss: 0.0478\n",
      "Epoch 1022/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0503 - val_loss: 0.0459\n",
      "Epoch 1023/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0513 - val_loss: 0.0469\n",
      "Epoch 1024/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0520 - val_loss: 0.0541\n",
      "Epoch 1025/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0508 - val_loss: 0.0470\n",
      "Epoch 1026/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0511 - val_loss: 0.0480\n",
      "Epoch 1027/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0519 - val_loss: 0.0469\n",
      "Epoch 1028/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0510 - val_loss: 0.0466\n",
      "Epoch 1029/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0510 - val_loss: 0.0480\n",
      "Epoch 1030/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0520 - val_loss: 0.0458\n",
      "Epoch 1031/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0530 - val_loss: 0.0462\n",
      "Epoch 1032/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0516 - val_loss: 0.0478\n",
      "Epoch 1033/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0519 - val_loss: 0.0465\n",
      "Epoch 1034/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0515 - val_loss: 0.0474\n",
      "Epoch 1035/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0519 - val_loss: 0.0532\n",
      "Epoch 1036/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0506 - val_loss: 0.0487\n",
      "Epoch 1037/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0510 - val_loss: 0.0469\n",
      "Epoch 1038/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0519 - val_loss: 0.0479\n",
      "Epoch 1039/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0514 - val_loss: 0.0469\n",
      "Epoch 1040/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0503 - val_loss: 0.0511\n",
      "Epoch 1041/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0503 - val_loss: 0.0461\n",
      "Epoch 1042/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0512 - val_loss: 0.0484\n",
      "Epoch 1043/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0525 - val_loss: 0.0539\n",
      "Epoch 1044/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0512 - val_loss: 0.0464\n",
      "Epoch 1045/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0537 - val_loss: 0.0471\n",
      "Epoch 1046/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0504 - val_loss: 0.0465\n",
      "Epoch 1047/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0501 - val_loss: 0.0493\n",
      "Epoch 1048/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0500 - val_loss: 0.0494\n",
      "Epoch 1049/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0508 - val_loss: 0.0474\n",
      "Epoch 1050/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0516 - val_loss: 0.0492\n",
      "Epoch 1051/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0504 - val_loss: 0.0475\n",
      "Epoch 1052/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0552 - val_loss: 0.0484\n",
      "Epoch 1053/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0515 - val_loss: 0.0483\n",
      "Epoch 1054/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0506 - val_loss: 0.0481\n",
      "Epoch 1055/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0516 - val_loss: 0.0479\n",
      "Epoch 1056/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0518 - val_loss: 0.0476\n",
      "Epoch 1057/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0514 - val_loss: 0.0468\n",
      "Epoch 1058/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0510 - val_loss: 0.0470\n",
      "Epoch 1059/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0508 - val_loss: 0.0489\n",
      "Epoch 1060/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0515 - val_loss: 0.0515\n",
      "Epoch 1061/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0507 - val_loss: 0.0473\n",
      "Epoch 1062/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0501 - val_loss: 0.0471\n",
      "Epoch 1063/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0509 - val_loss: 0.0516\n",
      "Epoch 1064/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0512 - val_loss: 0.0475\n",
      "Epoch 1065/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0502 - val_loss: 0.0467\n",
      "Epoch 1066/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0515 - val_loss: 0.0473\n",
      "Epoch 1067/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0509 - val_loss: 0.0487\n",
      "Epoch 1068/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0522 - val_loss: 0.0480\n",
      "Epoch 1069/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0507 - val_loss: 0.0475\n",
      "Epoch 1070/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0512 - val_loss: 0.0467\n",
      "Epoch 1071/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0508 - val_loss: 0.0523\n",
      "Epoch 1072/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0509 - val_loss: 0.0523\n",
      "Epoch 1073/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0526 - val_loss: 0.0551\n",
      "Epoch 1074/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0515 - val_loss: 0.0535\n",
      "Epoch 1075/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0506 - val_loss: 0.0469\n",
      "Epoch 1076/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0509 - val_loss: 0.0465\n",
      "Epoch 1077/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0501 - val_loss: 0.0533\n",
      "Epoch 1078/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0508 - val_loss: 0.0468\n",
      "Epoch 1079/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0505 - val_loss: 0.0469\n",
      "Epoch 1080/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0508 - val_loss: 0.0470\n",
      "Epoch 1081/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0515 - val_loss: 0.0473\n",
      "Epoch 1082/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0509 - val_loss: 0.0467\n",
      "Epoch 1083/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0500 - val_loss: 0.0519\n",
      "Epoch 1084/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0518 - val_loss: 0.0484\n",
      "Epoch 1085/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0511 - val_loss: 0.0462\n",
      "Epoch 1086/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0503 - val_loss: 0.0462\n",
      "Epoch 1087/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0511 - val_loss: 0.0472\n",
      "Epoch 1088/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0508 - val_loss: 0.0487\n",
      "Epoch 1089/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0499 - val_loss: 0.0488\n",
      "Epoch 1090/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0505 - val_loss: 0.0482\n",
      "Epoch 1091/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0508 - val_loss: 0.0457\n",
      "Epoch 1092/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0512 - val_loss: 0.0566\n",
      "Epoch 1093/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0509 - val_loss: 0.0473\n",
      "Epoch 1094/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0509 - val_loss: 0.0505\n",
      "Epoch 1095/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0518 - val_loss: 0.0466\n",
      "Epoch 1096/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0509 - val_loss: 0.0483\n",
      "Epoch 1097/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0510 - val_loss: 0.0482\n",
      "Epoch 1098/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0521 - val_loss: 0.0490\n",
      "Epoch 1099/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0502 - val_loss: 0.0490\n",
      "Epoch 1100/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0508 - val_loss: 0.0493\n",
      "Epoch 1101/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0508 - val_loss: 0.0469\n",
      "Epoch 1102/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0507 - val_loss: 0.0490\n",
      "Epoch 1103/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0502 - val_loss: 0.0472\n",
      "Epoch 1104/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0515 - val_loss: 0.0481\n",
      "Epoch 1105/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0499 - val_loss: 0.0495\n",
      "Epoch 1106/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0512 - val_loss: 0.0475\n",
      "Epoch 1107/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0516 - val_loss: 0.0515\n",
      "Epoch 1108/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0509 - val_loss: 0.0467\n",
      "Epoch 1109/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0497 - val_loss: 0.0478\n",
      "Epoch 1110/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0500 - val_loss: 0.0469\n",
      "Epoch 1111/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0504 - val_loss: 0.0464\n",
      "Epoch 1112/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0505 - val_loss: 0.0570\n",
      "Epoch 1113/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0502 - val_loss: 0.0472\n",
      "Epoch 1114/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0505 - val_loss: 0.0537\n",
      "Epoch 1115/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0513 - val_loss: 0.0471\n",
      "Epoch 1116/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0498 - val_loss: 0.0479\n",
      "Epoch 1117/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0504 - val_loss: 0.0483\n",
      "Epoch 1118/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0510 - val_loss: 0.0532\n",
      "Epoch 1119/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0507 - val_loss: 0.0509\n",
      "Epoch 1120/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0512 - val_loss: 0.0465\n",
      "Epoch 1121/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0495 - val_loss: 0.0514\n",
      "Epoch 1122/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0511 - val_loss: 0.0466\n",
      "Epoch 1123/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0504 - val_loss: 0.0460\n",
      "Epoch 1124/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0508 - val_loss: 0.0484\n",
      "Epoch 1125/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0504 - val_loss: 0.0466\n",
      "Epoch 1126/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0502 - val_loss: 0.0477\n",
      "Epoch 1127/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0516 - val_loss: 0.0471\n",
      "Epoch 1128/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0499 - val_loss: 0.0467\n",
      "Epoch 1129/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0516 - val_loss: 0.0529\n",
      "Epoch 1130/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0509 - val_loss: 0.0487\n",
      "Epoch 1131/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0514 - val_loss: 0.0487\n",
      "Epoch 1132/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0505 - val_loss: 0.0469\n",
      "Epoch 1133/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0502 - val_loss: 0.0557\n",
      "Epoch 1134/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0518 - val_loss: 0.0476\n",
      "Epoch 1135/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0529 - val_loss: 0.0551\n",
      "Epoch 1136/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0510 - val_loss: 0.0468\n",
      "Epoch 1137/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0503 - val_loss: 0.0494\n",
      "Epoch 1138/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0500 - val_loss: 0.0463\n",
      "Epoch 1139/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0500 - val_loss: 0.0472\n",
      "Epoch 1140/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0500 - val_loss: 0.0478\n",
      "Epoch 1141/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0512 - val_loss: 0.0478\n",
      "Epoch 1142/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0511 - val_loss: 0.0481\n",
      "Epoch 1143/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0498 - val_loss: 0.0467\n",
      "Epoch 1144/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0507 - val_loss: 0.0484\n",
      "Epoch 1145/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0499 - val_loss: 0.0467\n",
      "Epoch 1146/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0511 - val_loss: 0.0517\n",
      "Epoch 1147/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0506 - val_loss: 0.0467\n",
      "Epoch 1148/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0501 - val_loss: 0.0493\n",
      "Epoch 1149/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0505 - val_loss: 0.0466\n",
      "Epoch 1150/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0501 - val_loss: 0.0484\n",
      "Epoch 1151/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0505 - val_loss: 0.0470\n",
      "Epoch 1152/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0506 - val_loss: 0.0474\n",
      "Epoch 1153/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0507 - val_loss: 0.0473\n",
      "Epoch 1154/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0501 - val_loss: 0.0520\n",
      "Epoch 1155/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0511 - val_loss: 0.0497\n",
      "Epoch 1156/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0492 - val_loss: 0.0467\n",
      "Epoch 1157/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0495 - val_loss: 0.0461\n",
      "Epoch 1158/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0499 - val_loss: 0.0466\n",
      "Epoch 1159/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0502 - val_loss: 0.0486\n",
      "Epoch 1160/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0495 - val_loss: 0.0473\n",
      "Epoch 1161/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0513 - val_loss: 0.0495\n",
      "Epoch 1162/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0508 - val_loss: 0.0489\n",
      "Epoch 1163/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0506 - val_loss: 0.0474\n",
      "Epoch 1164/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0502 - val_loss: 0.0470\n",
      "Epoch 1165/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0503 - val_loss: 0.0485\n",
      "Epoch 1166/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0493 - val_loss: 0.0507\n",
      "Epoch 1167/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0506 - val_loss: 0.0506\n",
      "Epoch 1168/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0494 - val_loss: 0.0509\n",
      "Epoch 1169/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0499 - val_loss: 0.0473\n",
      "Epoch 1170/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0504 - val_loss: 0.0539\n",
      "Epoch 1171/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0499 - val_loss: 0.0475\n",
      "Epoch 1172/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0527 - val_loss: 0.0499\n",
      "Epoch 1173/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0508 - val_loss: 0.0471\n",
      "Epoch 1174/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0498 - val_loss: 0.0517\n",
      "Epoch 1175/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0504 - val_loss: 0.0482\n",
      "Epoch 1176/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0509 - val_loss: 0.0463\n",
      "Epoch 1177/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0494 - val_loss: 0.0472\n",
      "Epoch 1178/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0519 - val_loss: 0.0541\n",
      "Epoch 1179/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0505 - val_loss: 0.0466\n",
      "Epoch 1180/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0504 - val_loss: 0.0519\n",
      "Epoch 1181/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0503 - val_loss: 0.0523\n",
      "Epoch 1182/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0505 - val_loss: 0.0482\n",
      "Epoch 1183/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0512 - val_loss: 0.0468\n",
      "Epoch 1184/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0497 - val_loss: 0.0469\n",
      "Epoch 1185/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0499 - val_loss: 0.0473\n",
      "Epoch 1186/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0500 - val_loss: 0.0513\n",
      "Epoch 1187/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0493 - val_loss: 0.0470\n",
      "Epoch 1188/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0496 - val_loss: 0.0491\n",
      "Epoch 1189/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0495 - val_loss: 0.0466\n",
      "Epoch 1190/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0506 - val_loss: 0.0483\n",
      "Epoch 1191/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0501 - val_loss: 0.0476\n",
      "Epoch 1192/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0496 - val_loss: 0.0502\n",
      "Epoch 1193/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0517 - val_loss: 0.0458\n",
      "Epoch 1194/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0514 - val_loss: 0.0486\n",
      "Epoch 1195/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0497 - val_loss: 0.0475\n",
      "Epoch 1196/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0505 - val_loss: 0.0486\n",
      "Epoch 1197/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0505 - val_loss: 0.0470\n",
      "Epoch 1198/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0545\n",
      "Epoch 1199/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0506 - val_loss: 0.0479\n",
      "Epoch 1200/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0498 - val_loss: 0.0465\n",
      "Epoch 1201/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0492 - val_loss: 0.0472\n",
      "Epoch 1202/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0515 - val_loss: 0.0465\n",
      "Epoch 1203/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0499 - val_loss: 0.0475\n",
      "Epoch 1204/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0504 - val_loss: 0.0456\n",
      "Epoch 1205/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0505 - val_loss: 0.0475\n",
      "Epoch 1206/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0498 - val_loss: 0.0479\n",
      "Epoch 1207/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0500 - val_loss: 0.0455\n",
      "Epoch 1208/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0492 - val_loss: 0.0490\n",
      "Epoch 1209/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0505 - val_loss: 0.0476\n",
      "Epoch 1210/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0506 - val_loss: 0.0537\n",
      "Epoch 1211/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0498 - val_loss: 0.0571\n",
      "Epoch 1212/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0515 - val_loss: 0.0471\n",
      "Epoch 1213/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0509 - val_loss: 0.0463\n",
      "Epoch 1214/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0499 - val_loss: 0.0524\n",
      "Epoch 1215/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0500 - val_loss: 0.0475\n",
      "Epoch 1216/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0493 - val_loss: 0.0486\n",
      "Epoch 1217/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0501 - val_loss: 0.0474\n",
      "Epoch 1218/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0503 - val_loss: 0.0525\n",
      "Epoch 1219/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0491 - val_loss: 0.0478\n",
      "Epoch 1220/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0501 - val_loss: 0.0526\n",
      "Epoch 1221/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0495 - val_loss: 0.0468\n",
      "Epoch 1222/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0514 - val_loss: 0.0514\n",
      "Epoch 1223/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0508 - val_loss: 0.0476\n",
      "Epoch 1224/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0495 - val_loss: 0.0492\n",
      "Epoch 1225/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0496 - val_loss: 0.0472\n",
      "Epoch 1226/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0508 - val_loss: 0.0479\n",
      "Epoch 1227/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0494 - val_loss: 0.0486\n",
      "Epoch 1228/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0524 - val_loss: 0.0473\n",
      "Epoch 1229/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0502 - val_loss: 0.0473\n",
      "Epoch 1230/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0495 - val_loss: 0.0477\n",
      "Epoch 1231/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0453\n",
      "Epoch 1232/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0494 - val_loss: 0.0525\n",
      "Epoch 1233/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0500 - val_loss: 0.0557\n",
      "Epoch 1234/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0500 - val_loss: 0.0513\n",
      "Epoch 1235/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0501 - val_loss: 0.0526\n",
      "Epoch 1236/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0496 - val_loss: 0.0471\n",
      "Epoch 1237/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0496 - val_loss: 0.0496\n",
      "Epoch 1238/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0498 - val_loss: 0.0487\n",
      "Epoch 1239/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0496 - val_loss: 0.0481\n",
      "Epoch 1240/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0501 - val_loss: 0.0470\n",
      "Epoch 1241/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0503 - val_loss: 0.0483\n",
      "Epoch 1242/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0507 - val_loss: 0.0465\n",
      "Epoch 1243/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0494 - val_loss: 0.0466\n",
      "Epoch 1244/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0491 - val_loss: 0.0475\n",
      "Epoch 1245/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0497 - val_loss: 0.0474\n",
      "Epoch 1246/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0498 - val_loss: 0.0462\n",
      "Epoch 1247/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0521\n",
      "Epoch 1248/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0513 - val_loss: 0.0499\n",
      "Epoch 1249/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0497 - val_loss: 0.0473\n",
      "Epoch 1250/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0491 - val_loss: 0.0455\n",
      "Epoch 1251/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0501 - val_loss: 0.0461\n",
      "Epoch 1252/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0502 - val_loss: 0.0459\n",
      "Epoch 1253/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0495 - val_loss: 0.0488\n",
      "Epoch 1254/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0472\n",
      "Epoch 1255/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0488 - val_loss: 0.0478\n",
      "Epoch 1256/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0507 - val_loss: 0.0467\n",
      "Epoch 1257/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0501 - val_loss: 0.0508\n",
      "Epoch 1258/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0504 - val_loss: 0.0493\n",
      "Epoch 1259/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0494 - val_loss: 0.0466\n",
      "Epoch 1260/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0507 - val_loss: 0.0463\n",
      "Epoch 1261/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0493 - val_loss: 0.0507\n",
      "Epoch 1262/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0498 - val_loss: 0.0471\n",
      "Epoch 1263/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0500 - val_loss: 0.0467\n",
      "Epoch 1264/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0501 - val_loss: 0.0480\n",
      "Epoch 1265/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0499 - val_loss: 0.0501\n",
      "Epoch 1266/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0508 - val_loss: 0.0464\n",
      "Epoch 1267/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0501 - val_loss: 0.0514\n",
      "Epoch 1268/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0496 - val_loss: 0.0494\n",
      "Epoch 1269/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0501 - val_loss: 0.0501\n",
      "Epoch 1270/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0488 - val_loss: 0.0491\n",
      "Epoch 1271/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0500 - val_loss: 0.0571\n",
      "Epoch 1272/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0504 - val_loss: 0.0485\n",
      "Epoch 1273/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0495 - val_loss: 0.0511\n",
      "Epoch 1274/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0494 - val_loss: 0.0488\n",
      "Epoch 1275/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0542\n",
      "Epoch 1276/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0500 - val_loss: 0.0460\n",
      "Epoch 1277/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0500 - val_loss: 0.0476\n",
      "Epoch 1278/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0493 - val_loss: 0.0477\n",
      "Epoch 1279/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0497 - val_loss: 0.0472\n",
      "Epoch 1280/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0494 - val_loss: 0.0486\n",
      "Epoch 1281/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0514 - val_loss: 0.0481\n",
      "Epoch 1282/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0499 - val_loss: 0.0466\n",
      "Epoch 1283/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0498 - val_loss: 0.0460\n",
      "Epoch 1284/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0489 - val_loss: 0.0478\n",
      "Epoch 1285/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0489 - val_loss: 0.0466\n",
      "Epoch 1286/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0496 - val_loss: 0.0471\n",
      "Epoch 1287/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0502 - val_loss: 0.0470\n",
      "Epoch 1288/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0491 - val_loss: 0.0472\n",
      "Epoch 1289/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0502 - val_loss: 0.0474\n",
      "Epoch 1290/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0504 - val_loss: 0.0464\n",
      "Epoch 1291/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0493 - val_loss: 0.0497\n",
      "Epoch 1292/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0502 - val_loss: 0.0472\n",
      "Epoch 1293/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0496 - val_loss: 0.0480\n",
      "Epoch 1294/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0498 - val_loss: 0.0463\n",
      "Epoch 1295/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0486 - val_loss: 0.0487\n",
      "Epoch 1296/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0497 - val_loss: 0.0509\n",
      "Epoch 1297/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0524 - val_loss: 0.0462\n",
      "Epoch 1298/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0489 - val_loss: 0.0462\n",
      "Epoch 1299/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0495 - val_loss: 0.0456\n",
      "Epoch 1300/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0494 - val_loss: 0.0474\n",
      "Epoch 1301/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0505 - val_loss: 0.0481\n",
      "Epoch 1302/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0494 - val_loss: 0.0455\n",
      "Epoch 1303/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0522 - val_loss: 0.0476\n",
      "Epoch 1304/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0510 - val_loss: 0.0464\n",
      "Epoch 1305/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0489 - val_loss: 0.0452\n",
      "Epoch 1306/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0492 - val_loss: 0.0490\n",
      "Epoch 1307/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0497 - val_loss: 0.0466\n",
      "Epoch 1308/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0485\n",
      "Epoch 1309/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0499 - val_loss: 0.0468\n",
      "Epoch 1310/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0482 - val_loss: 0.0504\n",
      "Epoch 1311/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0489 - val_loss: 0.0483\n",
      "Epoch 1312/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0519\n",
      "Epoch 1313/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0497 - val_loss: 0.0467\n",
      "Epoch 1314/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0497 - val_loss: 0.0486\n",
      "Epoch 1315/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0495 - val_loss: 0.0486\n",
      "Epoch 1316/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0498 - val_loss: 0.0509\n",
      "Epoch 1317/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0494 - val_loss: 0.0474\n",
      "Epoch 1318/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0491 - val_loss: 0.0473\n",
      "Epoch 1319/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0492 - val_loss: 0.0448\n",
      "Epoch 1320/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0505 - val_loss: 0.0476\n",
      "Epoch 1321/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0491 - val_loss: 0.0471\n",
      "Epoch 1322/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0486 - val_loss: 0.0504\n",
      "Epoch 1323/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0462\n",
      "Epoch 1324/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0489 - val_loss: 0.0480\n",
      "Epoch 1325/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0611\n",
      "Epoch 1326/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0526 - val_loss: 0.0489\n",
      "Epoch 1327/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0501 - val_loss: 0.0491\n",
      "Epoch 1328/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0493 - val_loss: 0.0477\n",
      "Epoch 1329/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0501 - val_loss: 0.0472\n",
      "Epoch 1330/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0470\n",
      "Epoch 1331/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0488 - val_loss: 0.0524\n",
      "Epoch 1332/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0503 - val_loss: 0.0474\n",
      "Epoch 1333/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0494 - val_loss: 0.0501\n",
      "Epoch 1334/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0499 - val_loss: 0.0551\n",
      "Epoch 1335/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0496 - val_loss: 0.0474\n",
      "Epoch 1336/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0499 - val_loss: 0.0462\n",
      "Epoch 1337/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0489 - val_loss: 0.0475\n",
      "Epoch 1338/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0503 - val_loss: 0.0483\n",
      "Epoch 1339/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0494 - val_loss: 0.0465\n",
      "Epoch 1340/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0494 - val_loss: 0.0464\n",
      "Epoch 1341/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0492 - val_loss: 0.0469\n",
      "Epoch 1342/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0519\n",
      "Epoch 1343/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0495 - val_loss: 0.0490\n",
      "Epoch 1344/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0495 - val_loss: 0.0477\n",
      "Epoch 1345/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0493 - val_loss: 0.0488\n",
      "Epoch 1346/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0498 - val_loss: 0.0467\n",
      "Epoch 1347/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0496 - val_loss: 0.0466\n",
      "Epoch 1348/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0484 - val_loss: 0.0505\n",
      "Epoch 1349/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0496 - val_loss: 0.0491\n",
      "Epoch 1350/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0498 - val_loss: 0.0469\n",
      "Epoch 1351/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0496 - val_loss: 0.0462\n",
      "Epoch 1352/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0488 - val_loss: 0.0459\n",
      "Epoch 1353/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0505 - val_loss: 0.0463\n",
      "Epoch 1354/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0494 - val_loss: 0.0502\n",
      "Epoch 1355/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0520 - val_loss: 0.0513\n",
      "Epoch 1356/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0479 - val_loss: 0.0475\n",
      "Epoch 1357/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0491 - val_loss: 0.0510\n",
      "Epoch 1358/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0506 - val_loss: 0.0464\n",
      "Epoch 1359/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0497 - val_loss: 0.0478\n",
      "Epoch 1360/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0496 - val_loss: 0.0474\n",
      "Epoch 1361/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0469\n",
      "Epoch 1362/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0476\n",
      "Epoch 1363/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0495 - val_loss: 0.0478\n",
      "Epoch 1364/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0471\n",
      "Epoch 1365/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0491 - val_loss: 0.0485\n",
      "Epoch 1366/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0495 - val_loss: 0.0486\n",
      "Epoch 1367/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0467\n",
      "Epoch 1368/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0495 - val_loss: 0.0490\n",
      "Epoch 1369/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0492 - val_loss: 0.0466\n",
      "Epoch 1370/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0493 - val_loss: 0.0500\n",
      "Epoch 1371/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0493 - val_loss: 0.0496\n",
      "Epoch 1372/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0491 - val_loss: 0.0471\n",
      "Epoch 1373/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0483\n",
      "Epoch 1374/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0451\n",
      "Epoch 1375/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0486\n",
      "Epoch 1376/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0495 - val_loss: 0.0485\n",
      "Epoch 1377/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0455\n",
      "Epoch 1378/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0494 - val_loss: 0.0466\n",
      "Epoch 1379/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0495 - val_loss: 0.0531\n",
      "Epoch 1380/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0493 - val_loss: 0.0467\n",
      "Epoch 1381/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0498 - val_loss: 0.0507\n",
      "Epoch 1382/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0489 - val_loss: 0.0477\n",
      "Epoch 1383/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0529\n",
      "Epoch 1384/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0498 - val_loss: 0.0488\n",
      "Epoch 1385/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0491 - val_loss: 0.0557\n",
      "Epoch 1386/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0493 - val_loss: 0.0459\n",
      "Epoch 1387/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0505 - val_loss: 0.0487\n",
      "Epoch 1388/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0489 - val_loss: 0.0469\n",
      "Epoch 1389/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0476\n",
      "Epoch 1390/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0500 - val_loss: 0.0483\n",
      "Epoch 1391/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0502 - val_loss: 0.0465\n",
      "Epoch 1392/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0501 - val_loss: 0.0488\n",
      "Epoch 1393/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0486 - val_loss: 0.0486\n",
      "Epoch 1394/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0488 - val_loss: 0.0473\n",
      "Epoch 1395/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0470\n",
      "Epoch 1396/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0494 - val_loss: 0.0493\n",
      "Epoch 1397/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0493 - val_loss: 0.0482\n",
      "Epoch 1398/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0486 - val_loss: 0.0478\n",
      "Epoch 1399/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0488 - val_loss: 0.0471\n",
      "Epoch 1400/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0498 - val_loss: 0.0474\n",
      "Epoch 1401/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0490\n",
      "Epoch 1402/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0504 - val_loss: 0.0501\n",
      "Epoch 1403/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0498 - val_loss: 0.0474\n",
      "Epoch 1404/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0485\n",
      "Epoch 1405/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0477\n",
      "Epoch 1406/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0488\n",
      "Epoch 1407/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0492 - val_loss: 0.0506\n",
      "Epoch 1408/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0499 - val_loss: 0.0468\n",
      "Epoch 1409/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0492 - val_loss: 0.0493\n",
      "Epoch 1410/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0488 - val_loss: 0.0468\n",
      "Epoch 1411/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0486\n",
      "Epoch 1412/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0469\n",
      "Epoch 1413/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0487\n",
      "Epoch 1414/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0494 - val_loss: 0.0517\n",
      "Epoch 1415/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0504 - val_loss: 0.0490\n",
      "Epoch 1416/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0491 - val_loss: 0.0476\n",
      "Epoch 1417/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0497 - val_loss: 0.0476\n",
      "Epoch 1418/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0491 - val_loss: 0.0482\n",
      "Epoch 1419/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0488 - val_loss: 0.0539\n",
      "Epoch 1420/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0500 - val_loss: 0.0460\n",
      "Epoch 1421/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0475\n",
      "Epoch 1422/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0477\n",
      "Epoch 1423/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0498 - val_loss: 0.0485\n",
      "Epoch 1424/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0493 - val_loss: 0.0466\n",
      "Epoch 1425/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0488 - val_loss: 0.0464\n",
      "Epoch 1426/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0488 - val_loss: 0.0517\n",
      "Epoch 1427/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0473\n",
      "Epoch 1428/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0487\n",
      "Epoch 1429/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0492 - val_loss: 0.0473\n",
      "Epoch 1430/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0542\n",
      "Epoch 1431/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0495 - val_loss: 0.0501\n",
      "Epoch 1432/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0497 - val_loss: 0.0515\n",
      "Epoch 1433/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0511\n",
      "Epoch 1434/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0501 - val_loss: 0.0456\n",
      "Epoch 1435/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0466\n",
      "Epoch 1436/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0493 - val_loss: 0.0467\n",
      "Epoch 1437/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0491 - val_loss: 0.0465\n",
      "Epoch 1438/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0481 - val_loss: 0.0476\n",
      "Epoch 1439/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0491 - val_loss: 0.0493\n",
      "Epoch 1440/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0499\n",
      "Epoch 1441/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0498 - val_loss: 0.0548\n",
      "Epoch 1442/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0489 - val_loss: 0.0464\n",
      "Epoch 1443/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0489 - val_loss: 0.0466\n",
      "Epoch 1444/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0489 - val_loss: 0.0508\n",
      "Epoch 1445/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0494 - val_loss: 0.0480\n",
      "Epoch 1446/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0484 - val_loss: 0.0588\n",
      "Epoch 1447/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0511 - val_loss: 0.0483\n",
      "Epoch 1448/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0513\n",
      "Epoch 1449/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0496 - val_loss: 0.0478\n",
      "Epoch 1450/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0491 - val_loss: 0.0458\n",
      "Epoch 1451/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0495 - val_loss: 0.0472\n",
      "Epoch 1452/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0473\n",
      "Epoch 1453/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0472\n",
      "Epoch 1454/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0491 - val_loss: 0.0480\n",
      "Epoch 1455/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0491 - val_loss: 0.0474\n",
      "Epoch 1456/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0486 - val_loss: 0.0530\n",
      "Epoch 1457/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0491 - val_loss: 0.0480\n",
      "Epoch 1458/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0501\n",
      "Epoch 1459/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0501 - val_loss: 0.0463\n",
      "Epoch 1460/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0476\n",
      "Epoch 1461/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0489 - val_loss: 0.0468\n",
      "Epoch 1462/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0475\n",
      "Epoch 1463/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0485\n",
      "Epoch 1464/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0484\n",
      "Epoch 1465/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0486 - val_loss: 0.0482\n",
      "Epoch 1466/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0488 - val_loss: 0.0476\n",
      "Epoch 1467/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0478\n",
      "Epoch 1468/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0467\n",
      "Epoch 1469/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0489 - val_loss: 0.0452\n",
      "Epoch 1470/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0493 - val_loss: 0.0477\n",
      "Epoch 1471/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0457\n",
      "Epoch 1472/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0486 - val_loss: 0.0471\n",
      "Epoch 1473/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0484 - val_loss: 0.0484\n",
      "Epoch 1474/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0474\n",
      "Epoch 1475/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0448\n",
      "Epoch 1476/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0479 - val_loss: 0.0467\n",
      "Epoch 1477/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0482 - val_loss: 0.0513\n",
      "Epoch 1478/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0482 - val_loss: 0.0462\n",
      "Epoch 1479/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0489 - val_loss: 0.0493\n",
      "Epoch 1480/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0479 - val_loss: 0.0472\n",
      "Epoch 1481/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0492 - val_loss: 0.0475\n",
      "Epoch 1482/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0469\n",
      "Epoch 1483/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0491 - val_loss: 0.0481\n",
      "Epoch 1484/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0492\n",
      "Epoch 1485/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0488 - val_loss: 0.0485\n",
      "Epoch 1486/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0482 - val_loss: 0.0481\n",
      "Epoch 1487/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0496\n",
      "Epoch 1488/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0483\n",
      "Epoch 1489/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0486 - val_loss: 0.0483\n",
      "Epoch 1490/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0500\n",
      "Epoch 1491/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0500\n",
      "Epoch 1492/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0494 - val_loss: 0.0482\n",
      "Epoch 1493/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0489 - val_loss: 0.0463\n",
      "Epoch 1494/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0528 - val_loss: 0.0502\n",
      "Epoch 1495/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0465\n",
      "Epoch 1496/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0489 - val_loss: 0.0467\n",
      "Epoch 1497/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0464\n",
      "Epoch 1498/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0484 - val_loss: 0.0495\n",
      "Epoch 1499/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0486 - val_loss: 0.0493\n",
      "Epoch 1500/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0495 - val_loss: 0.0496\n",
      "Epoch 1501/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0496 - val_loss: 0.0488\n",
      "Epoch 1502/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0488 - val_loss: 0.0465\n",
      "Epoch 1503/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0478\n",
      "Epoch 1504/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0471\n",
      "Epoch 1505/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0480 - val_loss: 0.0471\n",
      "Epoch 1506/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0489 - val_loss: 0.0475\n",
      "Epoch 1507/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0493 - val_loss: 0.0464\n",
      "Epoch 1508/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0493 - val_loss: 0.0473\n",
      "Epoch 1509/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0478 - val_loss: 0.0505\n",
      "Epoch 1510/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0486 - val_loss: 0.0485\n",
      "Epoch 1511/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0482 - val_loss: 0.0472\n",
      "Epoch 1512/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0498 - val_loss: 0.0493\n",
      "Epoch 1513/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0500\n",
      "Epoch 1514/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0509 - val_loss: 0.0491\n",
      "Epoch 1515/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0489 - val_loss: 0.0476\n",
      "Epoch 1516/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0484 - val_loss: 0.0552\n",
      "Epoch 1517/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0488 - val_loss: 0.0506\n",
      "Epoch 1518/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0495 - val_loss: 0.0484\n",
      "Epoch 1519/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0486 - val_loss: 0.0485\n",
      "Epoch 1520/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0486 - val_loss: 0.0478\n",
      "Epoch 1521/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0493 - val_loss: 0.0607\n",
      "Epoch 1522/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0510 - val_loss: 0.0482\n",
      "Epoch 1523/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0478 - val_loss: 0.0469\n",
      "Epoch 1524/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0481 - val_loss: 0.0473\n",
      "Epoch 1525/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0466\n",
      "Epoch 1526/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0482 - val_loss: 0.0460\n",
      "Epoch 1527/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0488 - val_loss: 0.0460\n",
      "Epoch 1528/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0492\n",
      "Epoch 1529/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0491 - val_loss: 0.0468\n",
      "Epoch 1530/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0488 - val_loss: 0.0504\n",
      "Epoch 1531/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0493 - val_loss: 0.0473\n",
      "Epoch 1532/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0495 - val_loss: 0.0504\n",
      "Epoch 1533/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0484 - val_loss: 0.0486\n",
      "Epoch 1534/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0498 - val_loss: 0.0469\n",
      "Epoch 1535/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0497\n",
      "Epoch 1536/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0496 - val_loss: 0.0477\n",
      "Epoch 1537/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0494 - val_loss: 0.0487\n",
      "Epoch 1538/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0499\n",
      "Epoch 1539/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0480 - val_loss: 0.0476\n",
      "Epoch 1540/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0510\n",
      "Epoch 1541/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0475\n",
      "Epoch 1542/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0479 - val_loss: 0.0507\n",
      "Epoch 1543/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0484 - val_loss: 0.0492\n",
      "Epoch 1544/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0492 - val_loss: 0.0470\n",
      "Epoch 1545/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0480 - val_loss: 0.0486\n",
      "Epoch 1546/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0480\n",
      "Epoch 1547/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0493 - val_loss: 0.0508\n",
      "Epoch 1548/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0489 - val_loss: 0.0495\n",
      "Epoch 1549/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0493\n",
      "Epoch 1550/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0489 - val_loss: 0.0464\n",
      "Epoch 1551/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0507\n",
      "Epoch 1552/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0482 - val_loss: 0.0518\n",
      "Epoch 1553/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0473\n",
      "Epoch 1554/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0497 - val_loss: 0.0482\n",
      "Epoch 1555/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0491 - val_loss: 0.0504\n",
      "Epoch 1556/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0565\n",
      "Epoch 1557/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0497 - val_loss: 0.0551\n",
      "Epoch 1558/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0492 - val_loss: 0.0478\n",
      "Epoch 1559/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0474\n",
      "Epoch 1560/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0492 - val_loss: 0.0489\n",
      "Epoch 1561/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0496\n",
      "Epoch 1562/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0476\n",
      "Epoch 1563/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0480 - val_loss: 0.0525\n",
      "Epoch 1564/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0497 - val_loss: 0.0458\n",
      "Epoch 1565/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0500 - val_loss: 0.0625\n",
      "Epoch 1566/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0494 - val_loss: 0.0492\n",
      "Epoch 1567/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0513\n",
      "Epoch 1568/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0476 - val_loss: 0.0471\n",
      "Epoch 1569/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0480 - val_loss: 0.0492\n",
      "Epoch 1570/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0476\n",
      "Epoch 1571/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0477\n",
      "Epoch 1572/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0491 - val_loss: 0.0485\n",
      "Epoch 1573/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0494 - val_loss: 0.0462\n",
      "Epoch 1574/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0475\n",
      "Epoch 1575/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0481 - val_loss: 0.0500\n",
      "Epoch 1576/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0492 - val_loss: 0.0494\n",
      "Epoch 1577/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0503\n",
      "Epoch 1578/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0489 - val_loss: 0.0518\n",
      "Epoch 1579/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0474\n",
      "Epoch 1580/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0489\n",
      "Epoch 1581/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0476\n",
      "Epoch 1582/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0461\n",
      "Epoch 1583/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0479 - val_loss: 0.0517\n",
      "Epoch 1584/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0508\n",
      "Epoch 1585/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0482 - val_loss: 0.0518\n",
      "Epoch 1586/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0482 - val_loss: 0.0489\n",
      "Epoch 1587/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0484 - val_loss: 0.0463\n",
      "Epoch 1588/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0494 - val_loss: 0.0495\n",
      "Epoch 1589/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0481 - val_loss: 0.0473\n",
      "Epoch 1590/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0480 - val_loss: 0.0466\n",
      "Epoch 1591/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0534\n",
      "Epoch 1592/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0563\n",
      "Epoch 1593/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0486 - val_loss: 0.0470\n",
      "Epoch 1594/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0488 - val_loss: 0.0476\n",
      "Epoch 1595/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0480 - val_loss: 0.0492\n",
      "Epoch 1596/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0491 - val_loss: 0.0472\n",
      "Epoch 1597/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0472\n",
      "Epoch 1598/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0476 - val_loss: 0.0502\n",
      "Epoch 1599/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0484 - val_loss: 0.0473\n",
      "Epoch 1600/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0495 - val_loss: 0.0488\n",
      "Epoch 1601/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0486 - val_loss: 0.0476\n",
      "Epoch 1602/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0479 - val_loss: 0.0471\n",
      "Epoch 1603/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0484 - val_loss: 0.0485\n",
      "Epoch 1604/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0475\n",
      "Epoch 1605/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0480 - val_loss: 0.0508\n",
      "Epoch 1606/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0480 - val_loss: 0.0592\n",
      "Epoch 1607/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0492 - val_loss: 0.0512\n",
      "Epoch 1608/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0479\n",
      "Epoch 1609/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0480 - val_loss: 0.0473\n",
      "Epoch 1610/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0489 - val_loss: 0.0631\n",
      "Epoch 1611/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0522 - val_loss: 0.0480\n",
      "Epoch 1612/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0494 - val_loss: 0.0478\n",
      "Epoch 1613/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0475\n",
      "Epoch 1614/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0476 - val_loss: 0.0568\n",
      "Epoch 1615/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0496 - val_loss: 0.0481\n",
      "Epoch 1616/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0494 - val_loss: 0.0480\n",
      "Epoch 1617/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0493 - val_loss: 0.0496\n",
      "Epoch 1618/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0482 - val_loss: 0.0478\n",
      "Epoch 1619/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0497 - val_loss: 0.0472\n",
      "Epoch 1620/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0470\n",
      "Epoch 1621/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0482 - val_loss: 0.0483\n",
      "Epoch 1622/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0500 - val_loss: 0.0508\n",
      "Epoch 1623/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0491 - val_loss: 0.0496\n",
      "Epoch 1624/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0488 - val_loss: 0.0478\n",
      "Epoch 1625/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0471\n",
      "Epoch 1626/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0481 - val_loss: 0.0481\n",
      "Epoch 1627/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0497 - val_loss: 0.0486\n",
      "Epoch 1628/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0500 - val_loss: 0.0477\n",
      "Epoch 1629/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0478 - val_loss: 0.0492\n",
      "Epoch 1630/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0479 - val_loss: 0.0523\n",
      "Epoch 1631/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0494 - val_loss: 0.0451\n",
      "Epoch 1632/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0486 - val_loss: 0.0461\n",
      "Epoch 1633/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0519\n",
      "Epoch 1634/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0486 - val_loss: 0.0501\n",
      "Epoch 1635/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0480 - val_loss: 0.0471\n",
      "Epoch 1636/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0481 - val_loss: 0.0475\n",
      "Epoch 1637/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0479 - val_loss: 0.0476\n",
      "Epoch 1638/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0478 - val_loss: 0.0467\n",
      "Epoch 1639/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0486 - val_loss: 0.0471\n",
      "Epoch 1640/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0485\n",
      "Epoch 1641/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0499 - val_loss: 0.0500\n",
      "Epoch 1642/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0482 - val_loss: 0.0511\n",
      "Epoch 1643/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0491 - val_loss: 0.0476\n",
      "Epoch 1644/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0486 - val_loss: 0.0480\n",
      "Epoch 1645/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0488 - val_loss: 0.0498\n",
      "Epoch 1646/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0481 - val_loss: 0.0471\n",
      "Epoch 1647/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0512 - val_loss: 0.0520\n",
      "Epoch 1648/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0488 - val_loss: 0.0471\n",
      "Epoch 1649/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0482 - val_loss: 0.0481\n",
      "Epoch 1650/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0473\n",
      "Epoch 1651/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0488 - val_loss: 0.0458\n",
      "Epoch 1652/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0459\n",
      "Epoch 1653/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0481 - val_loss: 0.0466\n",
      "Epoch 1654/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0486\n",
      "Epoch 1655/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0481 - val_loss: 0.0474\n",
      "Epoch 1656/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0477 - val_loss: 0.0473\n",
      "Epoch 1657/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0478 - val_loss: 0.0481\n",
      "Epoch 1658/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0491 - val_loss: 0.0522\n",
      "Epoch 1659/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0485\n",
      "Epoch 1660/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0482\n",
      "Epoch 1661/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0479 - val_loss: 0.0478\n",
      "Epoch 1662/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0493\n",
      "Epoch 1663/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0493 - val_loss: 0.0471\n",
      "Epoch 1664/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0477\n",
      "Epoch 1665/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0484 - val_loss: 0.0495\n",
      "Epoch 1666/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0476 - val_loss: 0.0484\n",
      "Epoch 1667/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0466\n",
      "Epoch 1668/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0479 - val_loss: 0.0502\n",
      "Epoch 1669/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0494\n",
      "Epoch 1670/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0482 - val_loss: 0.0476\n",
      "Epoch 1671/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0497\n",
      "Epoch 1672/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0486 - val_loss: 0.0479\n",
      "Epoch 1673/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0479\n",
      "Epoch 1674/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0477 - val_loss: 0.0515\n",
      "Epoch 1675/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0480 - val_loss: 0.0477\n",
      "Epoch 1676/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0480 - val_loss: 0.0490\n",
      "Epoch 1677/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0508 - val_loss: 0.0468\n",
      "Epoch 1678/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0482 - val_loss: 0.0471\n",
      "Epoch 1679/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0480 - val_loss: 0.0544\n",
      "Epoch 1680/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0477 - val_loss: 0.0583\n",
      "Epoch 1681/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0489 - val_loss: 0.0478\n",
      "Epoch 1682/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0481 - val_loss: 0.0462\n",
      "Epoch 1683/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0477\n",
      "Epoch 1684/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0498\n",
      "Epoch 1685/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0478\n",
      "Epoch 1686/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0478\n",
      "Epoch 1687/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0481 - val_loss: 0.0463\n",
      "Epoch 1688/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0484 - val_loss: 0.0466\n",
      "Epoch 1689/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0487\n",
      "Epoch 1690/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0488 - val_loss: 0.0481\n",
      "Epoch 1691/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0484 - val_loss: 0.0477\n",
      "Epoch 1692/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0486 - val_loss: 0.0467\n",
      "Epoch 1693/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0479 - val_loss: 0.0534\n",
      "Epoch 1694/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0482 - val_loss: 0.0494\n",
      "Epoch 1695/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0479\n",
      "Epoch 1696/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0488 - val_loss: 0.0490\n",
      "Epoch 1697/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0480 - val_loss: 0.0469\n",
      "Epoch 1698/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0489 - val_loss: 0.0502\n",
      "Epoch 1699/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0506\n",
      "Epoch 1700/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0470\n",
      "Epoch 1701/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0492 - val_loss: 0.0489\n",
      "Epoch 1702/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0563\n",
      "Epoch 1703/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0488 - val_loss: 0.0469\n",
      "Epoch 1704/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0479 - val_loss: 0.0478\n",
      "Epoch 1705/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0511 - val_loss: 0.0470\n",
      "Epoch 1706/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0484 - val_loss: 0.0483\n",
      "Epoch 1707/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0482 - val_loss: 0.0480\n",
      "Epoch 1708/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0478 - val_loss: 0.0479\n",
      "Epoch 1709/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0495 - val_loss: 0.0477\n",
      "Epoch 1710/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0480 - val_loss: 0.0468\n",
      "Epoch 1711/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0480 - val_loss: 0.0474\n",
      "Epoch 1712/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0479 - val_loss: 0.0476\n",
      "Epoch 1713/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0499 - val_loss: 0.0568\n",
      "Epoch 1714/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0472\n",
      "Epoch 1715/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0479 - val_loss: 0.0487\n",
      "Epoch 1716/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0481 - val_loss: 0.0486\n",
      "Epoch 1717/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0480 - val_loss: 0.0495\n",
      "Epoch 1718/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0496 - val_loss: 0.0468\n",
      "Epoch 1719/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0486 - val_loss: 0.0540\n",
      "Epoch 1720/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0468\n",
      "Epoch 1721/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0476 - val_loss: 0.0484\n",
      "Epoch 1722/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0467\n",
      "Epoch 1723/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0479\n",
      "Epoch 1724/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0473\n",
      "Epoch 1725/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0486 - val_loss: 0.0469\n",
      "Epoch 1726/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0587\n",
      "Epoch 1727/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0483\n",
      "Epoch 1728/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0480 - val_loss: 0.0473\n",
      "Epoch 1729/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0479 - val_loss: 0.0489\n",
      "Epoch 1730/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0469\n",
      "Epoch 1731/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0492 - val_loss: 0.0497\n",
      "Epoch 1732/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0478 - val_loss: 0.0486\n",
      "Epoch 1733/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0489 - val_loss: 0.0481\n",
      "Epoch 1734/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0486\n",
      "Epoch 1735/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0484 - val_loss: 0.0487\n",
      "Epoch 1736/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0484 - val_loss: 0.0478\n",
      "Epoch 1737/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0482 - val_loss: 0.0475\n",
      "Epoch 1738/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0477 - val_loss: 0.0476\n",
      "Epoch 1739/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0479 - val_loss: 0.0486\n",
      "Epoch 1740/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0471\n",
      "Epoch 1741/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0496 - val_loss: 0.0489\n",
      "Epoch 1742/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0476 - val_loss: 0.0477\n",
      "Epoch 1743/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0471\n",
      "Epoch 1744/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0497 - val_loss: 0.0523\n",
      "Epoch 1745/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0478 - val_loss: 0.0487\n",
      "Epoch 1746/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0473 - val_loss: 0.0470\n",
      "Epoch 1747/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0481 - val_loss: 0.0491\n",
      "Epoch 1748/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0485\n",
      "Epoch 1749/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0505 - val_loss: 0.0651\n",
      "Epoch 1750/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0505 - val_loss: 0.0471\n",
      "Epoch 1751/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0477 - val_loss: 0.0470\n",
      "Epoch 1752/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0484 - val_loss: 0.0470\n",
      "Epoch 1753/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0474\n",
      "Epoch 1754/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0488 - val_loss: 0.0479\n",
      "Epoch 1755/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0477 - val_loss: 0.0467\n",
      "Epoch 1756/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0488\n",
      "Epoch 1757/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0472\n",
      "Epoch 1758/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0482 - val_loss: 0.0485\n",
      "Epoch 1759/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0479 - val_loss: 0.0477\n",
      "Epoch 1760/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0478 - val_loss: 0.0471\n",
      "Epoch 1761/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0479 - val_loss: 0.0474\n",
      "Epoch 1762/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0493\n",
      "Epoch 1763/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0472\n",
      "Epoch 1764/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0491 - val_loss: 0.0467\n",
      "Epoch 1765/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0466\n",
      "Epoch 1766/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0475 - val_loss: 0.0476\n",
      "Epoch 1767/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0481\n",
      "Epoch 1768/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0478 - val_loss: 0.0491\n",
      "Epoch 1769/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0476 - val_loss: 0.0519\n",
      "Epoch 1770/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0495 - val_loss: 0.0470\n",
      "Epoch 1771/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0484 - val_loss: 0.0470\n",
      "Epoch 1772/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0492\n",
      "Epoch 1773/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0475 - val_loss: 0.0468\n",
      "Epoch 1774/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0479 - val_loss: 0.0481\n",
      "Epoch 1775/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0477 - val_loss: 0.0469\n",
      "Epoch 1776/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0475\n",
      "Epoch 1777/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0503 - val_loss: 0.0496\n",
      "Epoch 1778/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0467\n",
      "Epoch 1779/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0481 - val_loss: 0.0468\n",
      "Epoch 1780/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0481 - val_loss: 0.0472\n",
      "Epoch 1781/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0476 - val_loss: 0.0478\n",
      "Epoch 1782/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0484 - val_loss: 0.0482\n",
      "Epoch 1783/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0484 - val_loss: 0.0491\n",
      "Epoch 1784/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0494\n",
      "Epoch 1785/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0480 - val_loss: 0.0484\n",
      "Epoch 1786/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0486 - val_loss: 0.0474\n",
      "Epoch 1787/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0537\n",
      "Epoch 1788/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0484 - val_loss: 0.0476\n",
      "Epoch 1789/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0480 - val_loss: 0.0559\n",
      "Epoch 1790/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0492 - val_loss: 0.0480\n",
      "Epoch 1791/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0499\n",
      "Epoch 1792/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0482 - val_loss: 0.0489\n",
      "Epoch 1793/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0473\n",
      "Epoch 1794/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0493 - val_loss: 0.0480\n",
      "Epoch 1795/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0477 - val_loss: 0.0474\n",
      "Epoch 1796/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0520\n",
      "Epoch 1797/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0491 - val_loss: 0.0465\n",
      "Epoch 1798/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0479 - val_loss: 0.0481\n",
      "Epoch 1799/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0479 - val_loss: 0.0475\n",
      "Epoch 1800/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0479 - val_loss: 0.0472\n",
      "Epoch 1801/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0474 - val_loss: 0.0493\n",
      "Epoch 1802/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0481\n",
      "Epoch 1803/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0459\n",
      "Epoch 1804/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0479 - val_loss: 0.0474\n",
      "Epoch 1805/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0484 - val_loss: 0.0476\n",
      "Epoch 1806/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0480 - val_loss: 0.0488\n",
      "Epoch 1807/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0491 - val_loss: 0.0483\n",
      "Epoch 1808/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0482 - val_loss: 0.0472\n",
      "Epoch 1809/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0478 - val_loss: 0.0476\n",
      "Epoch 1810/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0478 - val_loss: 0.0519\n",
      "Epoch 1811/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0476 - val_loss: 0.0497\n",
      "Epoch 1812/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0490\n",
      "Epoch 1813/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0481 - val_loss: 0.0509\n",
      "Epoch 1814/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0481 - val_loss: 0.0475\n",
      "Epoch 1815/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0471 - val_loss: 0.0476\n",
      "Epoch 1816/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0531\n",
      "Epoch 1817/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0478 - val_loss: 0.0502\n",
      "Epoch 1818/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0486 - val_loss: 0.0475\n",
      "Epoch 1819/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0493 - val_loss: 0.0467\n",
      "Epoch 1820/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0468\n",
      "Epoch 1821/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0475 - val_loss: 0.0475\n",
      "Epoch 1822/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0482 - val_loss: 0.0500\n",
      "Epoch 1823/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0486 - val_loss: 0.0470\n",
      "Epoch 1824/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0471\n",
      "Epoch 1825/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0479 - val_loss: 0.0466\n",
      "Epoch 1826/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0484 - val_loss: 0.0500\n",
      "Epoch 1827/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0470\n",
      "Epoch 1828/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0486 - val_loss: 0.0503\n",
      "Epoch 1829/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0475 - val_loss: 0.0494\n",
      "Epoch 1830/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0467\n",
      "Epoch 1831/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0525\n",
      "Epoch 1832/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0475 - val_loss: 0.0505\n",
      "Epoch 1833/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0476 - val_loss: 0.0501\n",
      "Epoch 1834/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0484 - val_loss: 0.0465\n",
      "Epoch 1835/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0480 - val_loss: 0.0479\n",
      "Epoch 1836/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0493 - val_loss: 0.0491\n",
      "Epoch 1837/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0496 - val_loss: 0.0510\n",
      "Epoch 1838/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0497 - val_loss: 0.0469\n",
      "Epoch 1839/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0481 - val_loss: 0.0473\n",
      "Epoch 1840/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0465\n",
      "Epoch 1841/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0475 - val_loss: 0.0485\n",
      "Epoch 1842/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0469\n",
      "Epoch 1843/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0476 - val_loss: 0.0509\n",
      "Epoch 1844/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0476 - val_loss: 0.0516\n",
      "Epoch 1845/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0469\n",
      "Epoch 1846/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0488 - val_loss: 0.0508\n",
      "Epoch 1847/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0484\n",
      "Epoch 1848/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0473 - val_loss: 0.0488\n",
      "Epoch 1849/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0482 - val_loss: 0.0551\n",
      "Epoch 1850/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0474\n",
      "Epoch 1851/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0478 - val_loss: 0.0470\n",
      "Epoch 1852/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0479 - val_loss: 0.0500\n",
      "Epoch 1853/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0477 - val_loss: 0.0476\n",
      "Epoch 1854/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0540\n",
      "Epoch 1855/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0478 - val_loss: 0.0471\n",
      "Epoch 1856/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0482\n",
      "Epoch 1857/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0474 - val_loss: 0.0487\n",
      "Epoch 1858/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0476 - val_loss: 0.0471\n",
      "Epoch 1859/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0480 - val_loss: 0.0480\n",
      "Epoch 1860/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0482 - val_loss: 0.0474\n",
      "Epoch 1861/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0486 - val_loss: 0.0480\n",
      "Epoch 1862/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0476 - val_loss: 0.0479\n",
      "Epoch 1863/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0492 - val_loss: 0.0498\n",
      "Epoch 1864/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0522\n",
      "Epoch 1865/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0487\n",
      "Epoch 1866/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0473 - val_loss: 0.0458\n",
      "Epoch 1867/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0476 - val_loss: 0.0476\n",
      "Epoch 1868/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0475 - val_loss: 0.0491\n",
      "Epoch 1869/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0475 - val_loss: 0.0473\n",
      "Epoch 1870/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0475 - val_loss: 0.0524\n",
      "Epoch 1871/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0489 - val_loss: 0.0482\n",
      "Epoch 1872/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0484 - val_loss: 0.0458\n",
      "Epoch 1873/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0493\n",
      "Epoch 1874/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0491 - val_loss: 0.0473\n",
      "Epoch 1875/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0493 - val_loss: 0.0482\n",
      "Epoch 1876/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0480 - val_loss: 0.0473\n",
      "Epoch 1877/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0481 - val_loss: 0.0522\n",
      "Epoch 1878/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0480 - val_loss: 0.0483\n",
      "Epoch 1879/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0478 - val_loss: 0.0517\n",
      "Epoch 1880/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0480 - val_loss: 0.0473\n",
      "Epoch 1881/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0512\n",
      "Epoch 1882/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0481 - val_loss: 0.0498\n",
      "Epoch 1883/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0482 - val_loss: 0.0542\n",
      "Epoch 1884/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0481 - val_loss: 0.0468\n",
      "Epoch 1885/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0481 - val_loss: 0.0482\n",
      "Epoch 1886/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0484 - val_loss: 0.0471\n",
      "Epoch 1887/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0479 - val_loss: 0.0474\n",
      "Epoch 1888/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0476 - val_loss: 0.0470\n",
      "Epoch 1889/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0480 - val_loss: 0.0492\n",
      "Epoch 1890/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0474 - val_loss: 0.0472\n",
      "Epoch 1891/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0472\n",
      "Epoch 1892/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0482 - val_loss: 0.0463\n",
      "Epoch 1893/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0479 - val_loss: 0.0511\n",
      "Epoch 1894/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0479 - val_loss: 0.0478\n",
      "Epoch 1895/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0480 - val_loss: 0.0563\n",
      "Epoch 1896/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0478 - val_loss: 0.0465\n",
      "Epoch 1897/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0476 - val_loss: 0.0503\n",
      "Epoch 1898/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0476 - val_loss: 0.0478\n",
      "Epoch 1899/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0477 - val_loss: 0.0467\n",
      "Epoch 1900/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0473 - val_loss: 0.0477\n",
      "Epoch 1901/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0527 - val_loss: 0.0540\n",
      "Epoch 1902/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0484 - val_loss: 0.0485\n",
      "Epoch 1903/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0480 - val_loss: 0.0508\n",
      "Epoch 1904/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0481 - val_loss: 0.0482\n",
      "Epoch 1905/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0481 - val_loss: 0.0500\n",
      "Epoch 1906/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0498 - val_loss: 0.0463\n",
      "Epoch 1907/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0495 - val_loss: 0.0520\n",
      "Epoch 1908/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0487 - val_loss: 0.0480\n",
      "Epoch 1909/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0477 - val_loss: 0.0498\n",
      "Epoch 1910/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0474 - val_loss: 0.0467\n",
      "Epoch 1911/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0477 - val_loss: 0.0478\n",
      "Epoch 1912/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0476 - val_loss: 0.0514\n",
      "Epoch 1913/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0490\n",
      "Epoch 1914/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0493 - val_loss: 0.0516\n",
      "Epoch 1915/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0481 - val_loss: 0.0505\n",
      "Epoch 1916/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0474 - val_loss: 0.0583\n",
      "Epoch 1917/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0479 - val_loss: 0.0483\n",
      "Epoch 1918/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0475 - val_loss: 0.0475\n",
      "Epoch 1919/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0484 - val_loss: 0.0480\n",
      "Epoch 1920/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0482 - val_loss: 0.0464\n",
      "Epoch 1921/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0478 - val_loss: 0.0499\n",
      "Epoch 1922/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0480 - val_loss: 0.0482\n",
      "Epoch 1923/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0476 - val_loss: 0.0471\n",
      "Epoch 1924/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0476 - val_loss: 0.0466\n",
      "Epoch 1925/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0499 - val_loss: 0.0484\n",
      "Epoch 1926/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0472 - val_loss: 0.0479\n",
      "Epoch 1927/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0479 - val_loss: 0.0482\n",
      "Epoch 1928/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0484 - val_loss: 0.0504\n",
      "Epoch 1929/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0478 - val_loss: 0.0483\n",
      "Epoch 1930/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0467 - val_loss: 0.0487\n",
      "Epoch 1931/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0477 - val_loss: 0.0509\n",
      "Epoch 1932/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0486 - val_loss: 0.0585\n",
      "Epoch 1933/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0484 - val_loss: 0.0461\n",
      "Epoch 1934/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0496 - val_loss: 0.0460\n",
      "Epoch 1935/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0484 - val_loss: 0.0470\n",
      "Epoch 1936/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0477 - val_loss: 0.0480\n",
      "Epoch 1937/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0506\n",
      "Epoch 1938/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0475 - val_loss: 0.0487\n",
      "Epoch 1939/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0475 - val_loss: 0.0511\n",
      "Epoch 1940/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0474 - val_loss: 0.0494\n",
      "Epoch 1941/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0475 - val_loss: 0.0478\n",
      "Epoch 1942/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0471 - val_loss: 0.0477\n",
      "Epoch 1943/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0469 - val_loss: 0.0481\n",
      "Epoch 1944/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0476 - val_loss: 0.0484\n",
      "Epoch 1945/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0472 - val_loss: 0.0470\n",
      "Epoch 1946/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0477 - val_loss: 0.0484\n",
      "Epoch 1947/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0476 - val_loss: 0.0561\n",
      "Epoch 1948/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0492 - val_loss: 0.0481\n",
      "Epoch 1949/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0477 - val_loss: 0.0471\n",
      "Epoch 1950/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0470 - val_loss: 0.0476\n",
      "Epoch 1951/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0478 - val_loss: 0.0489\n",
      "Epoch 1952/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0515\n",
      "Epoch 1953/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0473 - val_loss: 0.0462\n",
      "Epoch 1954/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0483 - val_loss: 0.0487\n",
      "Epoch 1955/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0481 - val_loss: 0.0501\n",
      "Epoch 1956/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0484 - val_loss: 0.0468\n",
      "Epoch 1957/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0477 - val_loss: 0.0477\n",
      "Epoch 1958/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0480 - val_loss: 0.0488\n",
      "Epoch 1959/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0475 - val_loss: 0.0511\n",
      "Epoch 1960/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0491 - val_loss: 0.0467\n",
      "Epoch 1961/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0473 - val_loss: 0.0464\n",
      "Epoch 1962/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0471 - val_loss: 0.0466\n",
      "Epoch 1963/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0477 - val_loss: 0.0503\n",
      "Epoch 1964/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0488 - val_loss: 0.0487\n",
      "Epoch 1965/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0492 - val_loss: 0.0506\n",
      "Epoch 1966/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0495 - val_loss: 0.0470\n",
      "Epoch 1967/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0491 - val_loss: 0.0478\n",
      "Epoch 1968/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0473 - val_loss: 0.0480\n",
      "Epoch 1969/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0471 - val_loss: 0.0465\n",
      "Epoch 1970/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0471 - val_loss: 0.0463\n",
      "Epoch 1971/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0493 - val_loss: 0.0489\n",
      "Epoch 1972/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0486 - val_loss: 0.0472\n",
      "Epoch 1973/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0470 - val_loss: 0.0512\n",
      "Epoch 1974/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0466 - val_loss: 0.0596\n",
      "Epoch 1975/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0489 - val_loss: 0.0498\n",
      "Epoch 1976/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0482 - val_loss: 0.0467\n",
      "Epoch 1977/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0467 - val_loss: 0.0510\n",
      "Epoch 1978/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0481 - val_loss: 0.0490\n",
      "Epoch 1979/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0468 - val_loss: 0.0479\n",
      "Epoch 1980/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0474 - val_loss: 0.0490\n",
      "Epoch 1981/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0468 - val_loss: 0.0476\n",
      "Epoch 1982/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0474 - val_loss: 0.0473\n",
      "Epoch 1983/2000\n",
      "126/126 [==============================] - 1s 5ms/step - loss: 0.0476 - val_loss: 0.0494\n",
      "Epoch 1984/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0473 - val_loss: 0.0478\n",
      "Epoch 1985/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0478 - val_loss: 0.0477\n",
      "Epoch 1986/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0471 - val_loss: 0.0530\n",
      "Epoch 1987/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0485 - val_loss: 0.0476\n",
      "Epoch 1988/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0470 - val_loss: 0.0474\n",
      "Epoch 1989/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0492 - val_loss: 0.0472\n",
      "Epoch 1990/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0472 - val_loss: 0.0496\n",
      "Epoch 1991/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0484 - val_loss: 0.0477\n",
      "Epoch 1992/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0479 - val_loss: 0.0472\n",
      "Epoch 1993/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0470 - val_loss: 0.0496\n",
      "Epoch 1994/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0480 - val_loss: 0.0550\n",
      "Epoch 1995/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0471 - val_loss: 0.0484\n",
      "Epoch 1996/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0489 - val_loss: 0.0498\n",
      "Epoch 1997/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0476 - val_loss: 0.0474\n",
      "Epoch 1998/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0469 - val_loss: 0.0475\n",
      "Epoch 1999/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0476 - val_loss: 0.0552\n",
      "Epoch 2000/2000\n",
      "126/126 [==============================] - 1s 4ms/step - loss: 0.0473 - val_loss: 0.0475\n"
     ]
    }
   ],
   "source": [
    "h = autoencoder.fit(x_dae_tra, y_dae_tra,\n",
    "                epochs=2000,\n",
    "                batch_size=8,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_dae_val, y_dae_val)).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1882990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "rebuilt_train = autoencoder.predict(dae_train)\n",
    "\n",
    "sp = \"spectrum_\"\n",
    "c = []\n",
    "for i in range(331):\n",
    "    c.append(sp + str(i))\n",
    "\n",
    "rebuilt_train = pd.DataFrame(rebuilt_train, columns =c)\n",
    "\n",
    "rebuilt_label = data1[[\"materials\", \"names\"]]\n",
    "rebuilt_data = pd.concat([rebuilt_label, rebuilt_train], axis = 1)\n",
    "rebuilt_data.to_csv(\"rebuilt_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb541f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>materials</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Cardboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Cardboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Cardboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Cardboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Cardboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>8</td>\n",
       "      <td>Wood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>8</td>\n",
       "      <td>Wood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>8</td>\n",
       "      <td>Wood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>8</td>\n",
       "      <td>Wood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>8</td>\n",
       "      <td>Wood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1260 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      materials      names\n",
       "0             0  Cardboard\n",
       "1             0  Cardboard\n",
       "2             0  Cardboard\n",
       "3             0  Cardboard\n",
       "4             0  Cardboard\n",
       "...         ...        ...\n",
       "1255          8       Wood\n",
       "1256          8       Wood\n",
       "1257          8       Wood\n",
       "1258          8       Wood\n",
       "1259          8       Wood\n",
       "\n",
       "[1260 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rebuilt_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ae1c48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "encoded_train = encoder.predict(dae_train)\n",
    "sp = \"spectrum_\"\n",
    "c = []\n",
    "for i in range(encoding_dim):\n",
    "    c.append(sp + str(i))\n",
    "encoded_train = pd.DataFrame(encoded_train, columns =c)\n",
    "encoded_data = pd.concat([rebuilt_label, encoded_train], axis = 1)\n",
    "f_name = \"encoded_data_\" + str(encoding_dim) + \".csv\"\n",
    "encoded_data.to_csv(f_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c77750a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>materials</th>\n",
       "      <th>names</th>\n",
       "      <th>spectrum_0</th>\n",
       "      <th>spectrum_1</th>\n",
       "      <th>spectrum_2</th>\n",
       "      <th>spectrum_3</th>\n",
       "      <th>spectrum_4</th>\n",
       "      <th>spectrum_5</th>\n",
       "      <th>spectrum_6</th>\n",
       "      <th>spectrum_7</th>\n",
       "      <th>...</th>\n",
       "      <th>spectrum_54</th>\n",
       "      <th>spectrum_55</th>\n",
       "      <th>spectrum_56</th>\n",
       "      <th>spectrum_57</th>\n",
       "      <th>spectrum_58</th>\n",
       "      <th>spectrum_59</th>\n",
       "      <th>spectrum_60</th>\n",
       "      <th>spectrum_61</th>\n",
       "      <th>spectrum_62</th>\n",
       "      <th>spectrum_63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Cardboard</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>0.001230</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>0.013542</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.001062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Cardboard</td>\n",
       "      <td>0.069635</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.001591</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>0.002366</td>\n",
       "      <td>0.013688</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>0.001240</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>0.001065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Cardboard</td>\n",
       "      <td>0.069555</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>0.001230</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.013689</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.001664</td>\n",
       "      <td>0.001067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Cardboard</td>\n",
       "      <td>0.068797</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>0.001241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>0.002347</td>\n",
       "      <td>0.013557</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>0.001231</td>\n",
       "      <td>0.001649</td>\n",
       "      <td>0.001058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Cardboard</td>\n",
       "      <td>0.069200</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.001614</td>\n",
       "      <td>0.001203</td>\n",
       "      <td>0.001403</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>0.013690</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.001674</td>\n",
       "      <td>0.001075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>8</td>\n",
       "      <td>Wood</td>\n",
       "      <td>0.177916</td>\n",
       "      <td>0.001669</td>\n",
       "      <td>0.002065</td>\n",
       "      <td>0.002501</td>\n",
       "      <td>0.001866</td>\n",
       "      <td>0.002422</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001998</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.005113</td>\n",
       "      <td>0.031733</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.003430</td>\n",
       "      <td>0.002144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>8</td>\n",
       "      <td>Wood</td>\n",
       "      <td>0.171001</td>\n",
       "      <td>0.001768</td>\n",
       "      <td>0.002182</td>\n",
       "      <td>0.002713</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>0.002403</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.002215</td>\n",
       "      <td>0.002454</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>0.005292</td>\n",
       "      <td>0.031593</td>\n",
       "      <td>0.002209</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.003582</td>\n",
       "      <td>0.002268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>8</td>\n",
       "      <td>Wood</td>\n",
       "      <td>0.068658</td>\n",
       "      <td>0.018290</td>\n",
       "      <td>0.019366</td>\n",
       "      <td>0.061013</td>\n",
       "      <td>0.049947</td>\n",
       "      <td>0.036245</td>\n",
       "      <td>0.025003</td>\n",
       "      <td>0.067426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078777</td>\n",
       "      <td>0.044815</td>\n",
       "      <td>0.018668</td>\n",
       "      <td>0.021073</td>\n",
       "      <td>0.024119</td>\n",
       "      <td>0.041496</td>\n",
       "      <td>0.015430</td>\n",
       "      <td>0.019119</td>\n",
       "      <td>0.020862</td>\n",
       "      <td>0.021492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>8</td>\n",
       "      <td>Wood</td>\n",
       "      <td>0.042997</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>0.014174</td>\n",
       "      <td>0.054635</td>\n",
       "      <td>0.044808</td>\n",
       "      <td>0.029736</td>\n",
       "      <td>0.019006</td>\n",
       "      <td>0.063586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077216</td>\n",
       "      <td>0.038426</td>\n",
       "      <td>0.013364</td>\n",
       "      <td>0.015166</td>\n",
       "      <td>0.016858</td>\n",
       "      <td>0.027898</td>\n",
       "      <td>0.010784</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>0.014934</td>\n",
       "      <td>0.015921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>8</td>\n",
       "      <td>Wood</td>\n",
       "      <td>0.033415</td>\n",
       "      <td>0.011559</td>\n",
       "      <td>0.011936</td>\n",
       "      <td>0.051234</td>\n",
       "      <td>0.042073</td>\n",
       "      <td>0.026621</td>\n",
       "      <td>0.016336</td>\n",
       "      <td>0.061270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076010</td>\n",
       "      <td>0.035204</td>\n",
       "      <td>0.011117</td>\n",
       "      <td>0.012640</td>\n",
       "      <td>0.013839</td>\n",
       "      <td>0.022488</td>\n",
       "      <td>0.008854</td>\n",
       "      <td>0.011695</td>\n",
       "      <td>0.012428</td>\n",
       "      <td>0.013483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1260 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      materials      names  spectrum_0  spectrum_1  spectrum_2  spectrum_3  \\\n",
       "0             0  Cardboard    0.068472    0.000798    0.001004    0.001597   \n",
       "1             0  Cardboard    0.069635    0.000800    0.001007    0.001591   \n",
       "2             0  Cardboard    0.069555    0.000802    0.001009    0.001596   \n",
       "3             0  Cardboard    0.068797    0.000795    0.001000    0.001586   \n",
       "4             0  Cardboard    0.069200    0.000808    0.001017    0.001614   \n",
       "...         ...        ...         ...         ...         ...         ...   \n",
       "1255          8       Wood    0.177916    0.001669    0.002065    0.002501   \n",
       "1256          8       Wood    0.171001    0.001768    0.002182    0.002713   \n",
       "1257          8       Wood    0.068658    0.018290    0.019366    0.061013   \n",
       "1258          8       Wood    0.042997    0.013600    0.014174    0.054635   \n",
       "1259          8       Wood    0.033415    0.011559    0.011936    0.051234   \n",
       "\n",
       "      spectrum_4  spectrum_5  spectrum_6  spectrum_7  ...  spectrum_54  \\\n",
       "0       0.001190    0.001387    0.001140    0.001251  ...     0.001410   \n",
       "1       0.001185    0.001386    0.001142    0.001244  ...     0.001401   \n",
       "2       0.001189    0.001389    0.001144    0.001248  ...     0.001405   \n",
       "3       0.001182    0.001379    0.001135    0.001241  ...     0.001398   \n",
       "4       0.001203    0.001403    0.001154    0.001265  ...     0.001424   \n",
       "...          ...         ...         ...         ...  ...          ...   \n",
       "1255    0.001866    0.002422    0.002268    0.001885  ...     0.001998   \n",
       "1256    0.002029    0.002593    0.002403    0.002062  ...     0.002193   \n",
       "1257    0.049947    0.036245    0.025003    0.067426  ...     0.078777   \n",
       "1258    0.044808    0.029736    0.019006    0.063586  ...     0.077216   \n",
       "1259    0.042073    0.026621    0.016336    0.061270  ...     0.076010   \n",
       "\n",
       "      spectrum_55  spectrum_56  spectrum_57  spectrum_58  spectrum_59  \\\n",
       "0        0.001230     0.001109     0.001239     0.002353     0.013542   \n",
       "1        0.001227     0.001113     0.001243     0.002366     0.013688   \n",
       "2        0.001230     0.001115     0.001245     0.002369     0.013689   \n",
       "3        0.001222     0.001105     0.001234     0.002347     0.013557   \n",
       "4        0.001244     0.001123     0.001254     0.002381     0.013690   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "1255     0.002049     0.002333     0.002529     0.005113     0.031733   \n",
       "1256     0.002215     0.002454     0.002665     0.005292     0.031593   \n",
       "1257     0.044815     0.018668     0.021073     0.024119     0.041496   \n",
       "1258     0.038426     0.013364     0.015166     0.016858     0.027898   \n",
       "1259     0.035204     0.011117     0.012640     0.013839     0.022488   \n",
       "\n",
       "      spectrum_60  spectrum_61  spectrum_62  spectrum_63  \n",
       "0        0.000959     0.001235     0.001654     0.001062  \n",
       "1        0.000963     0.001240     0.001661     0.001065  \n",
       "2        0.000965     0.001242     0.001664     0.001067  \n",
       "3        0.000956     0.001231     0.001649     0.001058  \n",
       "4        0.000971     0.001250     0.001674     0.001075  \n",
       "...           ...          ...          ...          ...  \n",
       "1255     0.002108     0.002574     0.003430     0.002144  \n",
       "1256     0.002209     0.002700     0.003582     0.002268  \n",
       "1257     0.015430     0.019119     0.020862     0.021492  \n",
       "1258     0.010784     0.013917     0.014934     0.015921  \n",
       "1259     0.008854     0.011695     0.012428     0.013483  \n",
       "\n",
       "[1260 rows x 66 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d225e871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>materials</th>\n",
       "      <th>names</th>\n",
       "      <th>spectrum_0</th>\n",
       "      <th>spectrum_1</th>\n",
       "      <th>spectrum_2</th>\n",
       "      <th>spectrum_3</th>\n",
       "      <th>spectrum_4</th>\n",
       "      <th>spectrum_5</th>\n",
       "      <th>spectrum_6</th>\n",
       "      <th>spectrum_7</th>\n",
       "      <th>...</th>\n",
       "      <th>spectrum_321</th>\n",
       "      <th>spectrum_322</th>\n",
       "      <th>spectrum_323</th>\n",
       "      <th>spectrum_324</th>\n",
       "      <th>spectrum_325</th>\n",
       "      <th>spectrum_326</th>\n",
       "      <th>spectrum_327</th>\n",
       "      <th>spectrum_328</th>\n",
       "      <th>spectrum_329</th>\n",
       "      <th>spectrum_330</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Cardboard</td>\n",
       "      <td>0.453542</td>\n",
       "      <td>0.453829</td>\n",
       "      <td>0.454067</td>\n",
       "      <td>0.454253</td>\n",
       "      <td>0.454569</td>\n",
       "      <td>0.454962</td>\n",
       "      <td>0.455277</td>\n",
       "      <td>0.455573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505698</td>\n",
       "      <td>0.506256</td>\n",
       "      <td>0.506581</td>\n",
       "      <td>0.506565</td>\n",
       "      <td>0.506565</td>\n",
       "      <td>0.506516</td>\n",
       "      <td>0.506758</td>\n",
       "      <td>0.507238</td>\n",
       "      <td>0.507656</td>\n",
       "      <td>0.507608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Cardboard</td>\n",
       "      <td>0.453549</td>\n",
       "      <td>0.453836</td>\n",
       "      <td>0.454075</td>\n",
       "      <td>0.454260</td>\n",
       "      <td>0.454576</td>\n",
       "      <td>0.454969</td>\n",
       "      <td>0.455284</td>\n",
       "      <td>0.455580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505707</td>\n",
       "      <td>0.506265</td>\n",
       "      <td>0.506590</td>\n",
       "      <td>0.506574</td>\n",
       "      <td>0.506574</td>\n",
       "      <td>0.506525</td>\n",
       "      <td>0.506767</td>\n",
       "      <td>0.507246</td>\n",
       "      <td>0.507665</td>\n",
       "      <td>0.507617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Cardboard</td>\n",
       "      <td>0.453549</td>\n",
       "      <td>0.453836</td>\n",
       "      <td>0.454074</td>\n",
       "      <td>0.454260</td>\n",
       "      <td>0.454576</td>\n",
       "      <td>0.454969</td>\n",
       "      <td>0.455284</td>\n",
       "      <td>0.455580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505706</td>\n",
       "      <td>0.506264</td>\n",
       "      <td>0.506590</td>\n",
       "      <td>0.506573</td>\n",
       "      <td>0.506574</td>\n",
       "      <td>0.506524</td>\n",
       "      <td>0.506766</td>\n",
       "      <td>0.507246</td>\n",
       "      <td>0.507665</td>\n",
       "      <td>0.507616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Cardboard</td>\n",
       "      <td>0.453543</td>\n",
       "      <td>0.453831</td>\n",
       "      <td>0.454069</td>\n",
       "      <td>0.454254</td>\n",
       "      <td>0.454570</td>\n",
       "      <td>0.454963</td>\n",
       "      <td>0.455278</td>\n",
       "      <td>0.455574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505700</td>\n",
       "      <td>0.506258</td>\n",
       "      <td>0.506583</td>\n",
       "      <td>0.506567</td>\n",
       "      <td>0.506567</td>\n",
       "      <td>0.506518</td>\n",
       "      <td>0.506760</td>\n",
       "      <td>0.507240</td>\n",
       "      <td>0.507658</td>\n",
       "      <td>0.507610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Cardboard</td>\n",
       "      <td>0.453547</td>\n",
       "      <td>0.453834</td>\n",
       "      <td>0.454073</td>\n",
       "      <td>0.454258</td>\n",
       "      <td>0.454574</td>\n",
       "      <td>0.454967</td>\n",
       "      <td>0.455282</td>\n",
       "      <td>0.455578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505705</td>\n",
       "      <td>0.506262</td>\n",
       "      <td>0.506588</td>\n",
       "      <td>0.506572</td>\n",
       "      <td>0.506572</td>\n",
       "      <td>0.506522</td>\n",
       "      <td>0.506764</td>\n",
       "      <td>0.507244</td>\n",
       "      <td>0.507663</td>\n",
       "      <td>0.507614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>8</td>\n",
       "      <td>Wood</td>\n",
       "      <td>0.638507</td>\n",
       "      <td>0.638823</td>\n",
       "      <td>0.638717</td>\n",
       "      <td>0.639095</td>\n",
       "      <td>0.639332</td>\n",
       "      <td>0.640137</td>\n",
       "      <td>0.640317</td>\n",
       "      <td>0.640360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.695023</td>\n",
       "      <td>0.695785</td>\n",
       "      <td>0.696565</td>\n",
       "      <td>0.696220</td>\n",
       "      <td>0.696576</td>\n",
       "      <td>0.696234</td>\n",
       "      <td>0.696157</td>\n",
       "      <td>0.697397</td>\n",
       "      <td>0.698092</td>\n",
       "      <td>0.697660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>8</td>\n",
       "      <td>Wood</td>\n",
       "      <td>0.628627</td>\n",
       "      <td>0.628931</td>\n",
       "      <td>0.628832</td>\n",
       "      <td>0.629251</td>\n",
       "      <td>0.629497</td>\n",
       "      <td>0.630245</td>\n",
       "      <td>0.630444</td>\n",
       "      <td>0.630531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686886</td>\n",
       "      <td>0.687683</td>\n",
       "      <td>0.688441</td>\n",
       "      <td>0.688106</td>\n",
       "      <td>0.688470</td>\n",
       "      <td>0.688111</td>\n",
       "      <td>0.688059</td>\n",
       "      <td>0.689303</td>\n",
       "      <td>0.689971</td>\n",
       "      <td>0.689566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>8</td>\n",
       "      <td>Wood</td>\n",
       "      <td>0.564518</td>\n",
       "      <td>0.564603</td>\n",
       "      <td>0.564640</td>\n",
       "      <td>0.565392</td>\n",
       "      <td>0.565692</td>\n",
       "      <td>0.565423</td>\n",
       "      <td>0.565834</td>\n",
       "      <td>0.566454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623338</td>\n",
       "      <td>0.624651</td>\n",
       "      <td>0.624958</td>\n",
       "      <td>0.624916</td>\n",
       "      <td>0.625200</td>\n",
       "      <td>0.624777</td>\n",
       "      <td>0.625247</td>\n",
       "      <td>0.626284</td>\n",
       "      <td>0.626556</td>\n",
       "      <td>0.626631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>8</td>\n",
       "      <td>Wood</td>\n",
       "      <td>0.554015</td>\n",
       "      <td>0.554148</td>\n",
       "      <td>0.554102</td>\n",
       "      <td>0.554763</td>\n",
       "      <td>0.555165</td>\n",
       "      <td>0.555225</td>\n",
       "      <td>0.555559</td>\n",
       "      <td>0.556019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.619033</td>\n",
       "      <td>0.620162</td>\n",
       "      <td>0.620730</td>\n",
       "      <td>0.620487</td>\n",
       "      <td>0.620963</td>\n",
       "      <td>0.620333</td>\n",
       "      <td>0.620601</td>\n",
       "      <td>0.621859</td>\n",
       "      <td>0.622235</td>\n",
       "      <td>0.622115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>8</td>\n",
       "      <td>Wood</td>\n",
       "      <td>0.521402</td>\n",
       "      <td>0.521588</td>\n",
       "      <td>0.521633</td>\n",
       "      <td>0.522144</td>\n",
       "      <td>0.522523</td>\n",
       "      <td>0.522701</td>\n",
       "      <td>0.523030</td>\n",
       "      <td>0.523438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583178</td>\n",
       "      <td>0.584136</td>\n",
       "      <td>0.584643</td>\n",
       "      <td>0.584462</td>\n",
       "      <td>0.584799</td>\n",
       "      <td>0.584340</td>\n",
       "      <td>0.584596</td>\n",
       "      <td>0.585630</td>\n",
       "      <td>0.586028</td>\n",
       "      <td>0.585925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1260 rows × 333 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      materials      names  spectrum_0  spectrum_1  spectrum_2  spectrum_3  \\\n",
       "0             0  Cardboard    0.453542    0.453829    0.454067    0.454253   \n",
       "1             0  Cardboard    0.453549    0.453836    0.454075    0.454260   \n",
       "2             0  Cardboard    0.453549    0.453836    0.454074    0.454260   \n",
       "3             0  Cardboard    0.453543    0.453831    0.454069    0.454254   \n",
       "4             0  Cardboard    0.453547    0.453834    0.454073    0.454258   \n",
       "...         ...        ...         ...         ...         ...         ...   \n",
       "1255          8       Wood    0.638507    0.638823    0.638717    0.639095   \n",
       "1256          8       Wood    0.628627    0.628931    0.628832    0.629251   \n",
       "1257          8       Wood    0.564518    0.564603    0.564640    0.565392   \n",
       "1258          8       Wood    0.554015    0.554148    0.554102    0.554763   \n",
       "1259          8       Wood    0.521402    0.521588    0.521633    0.522144   \n",
       "\n",
       "      spectrum_4  spectrum_5  spectrum_6  spectrum_7  ...  spectrum_321  \\\n",
       "0       0.454569    0.454962    0.455277    0.455573  ...      0.505698   \n",
       "1       0.454576    0.454969    0.455284    0.455580  ...      0.505707   \n",
       "2       0.454576    0.454969    0.455284    0.455580  ...      0.505706   \n",
       "3       0.454570    0.454963    0.455278    0.455574  ...      0.505700   \n",
       "4       0.454574    0.454967    0.455282    0.455578  ...      0.505705   \n",
       "...          ...         ...         ...         ...  ...           ...   \n",
       "1255    0.639332    0.640137    0.640317    0.640360  ...      0.695023   \n",
       "1256    0.629497    0.630245    0.630444    0.630531  ...      0.686886   \n",
       "1257    0.565692    0.565423    0.565834    0.566454  ...      0.623338   \n",
       "1258    0.555165    0.555225    0.555559    0.556019  ...      0.619033   \n",
       "1259    0.522523    0.522701    0.523030    0.523438  ...      0.583178   \n",
       "\n",
       "      spectrum_322  spectrum_323  spectrum_324  spectrum_325  spectrum_326  \\\n",
       "0         0.506256      0.506581      0.506565      0.506565      0.506516   \n",
       "1         0.506265      0.506590      0.506574      0.506574      0.506525   \n",
       "2         0.506264      0.506590      0.506573      0.506574      0.506524   \n",
       "3         0.506258      0.506583      0.506567      0.506567      0.506518   \n",
       "4         0.506262      0.506588      0.506572      0.506572      0.506522   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "1255      0.695785      0.696565      0.696220      0.696576      0.696234   \n",
       "1256      0.687683      0.688441      0.688106      0.688470      0.688111   \n",
       "1257      0.624651      0.624958      0.624916      0.625200      0.624777   \n",
       "1258      0.620162      0.620730      0.620487      0.620963      0.620333   \n",
       "1259      0.584136      0.584643      0.584462      0.584799      0.584340   \n",
       "\n",
       "      spectrum_327  spectrum_328  spectrum_329  spectrum_330  \n",
       "0         0.506758      0.507238      0.507656      0.507608  \n",
       "1         0.506767      0.507246      0.507665      0.507617  \n",
       "2         0.506766      0.507246      0.507665      0.507616  \n",
       "3         0.506760      0.507240      0.507658      0.507610  \n",
       "4         0.506764      0.507244      0.507663      0.507614  \n",
       "...            ...           ...           ...           ...  \n",
       "1255      0.696157      0.697397      0.698092      0.697660  \n",
       "1256      0.688059      0.689303      0.689971      0.689566  \n",
       "1257      0.625247      0.626284      0.626556      0.626631  \n",
       "1258      0.620601      0.621859      0.622235      0.622115  \n",
       "1259      0.584596      0.585630      0.586028      0.585925  \n",
       "\n",
       "[1260 rows x 333 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rebuilt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50378137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098e3686",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
